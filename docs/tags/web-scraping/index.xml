<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" 
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>Web Scraping auf Nicky Reinert</title>
    <link>https://nickyreinert.de/tags/web-scraping/</link>
    <description>Blog &amp; Projekte von Nicky Reinert (Institut für digitale Herausforderungen): Webentwicklung &amp; Software Development, SEO &amp; Analytics, Hosting &amp; DevOps, WordPress &amp; Hugo, Tools &amp; Projekte, Datenschutz und digitale Kultur – plus Texte zu KI sowie Autismus &amp; Gesellschaft.</description>
    <generator>Hugo 0.148.2</generator>
    <language>de</language>
    <managingEditor></managingEditor>
    <webMaster></webMaster>
    <copyright></copyright>
    <lastBuildDate>Tue, 05 Nov 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://nickyreinert.de/tags/web-scraping/index.xml" rel="self" type="application/rss+xml" /><item>
      <title>Fefes Blog - Eine Analyse</title>
      <link>https://nickyreinert.de/2019/2019-11-05-fefes-blog-eine-analyse/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      <author></author>
      <guid>https://nickyreinert.de/2019/2019-11-05-fefes-blog-eine-analyse/</guid>
      <description>Nach der gar nicht mal so großen öffentlichen Wahrnehmung meiner laienhaften statistischen Analyse des Flirtportals der BVG &ldquo;Augenblicke&rdquo;, habe ich …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Dieser Artikel bietet eine statistische Analyse von Fefes Blog, einem bekannten deutschen IT-Sicherheits- und Politik-Blog. Er untersucht die Entwicklung der Beitragsfrequenz, die Häufigkeit von Wörtern und externen Quellen, sowie die Blog-Zeiten. Zudem werden technische Aspekte des Web Scrapings und die Interpretation des Blog-eigenen Zeitstempelformats beleuchtet.</p>
          
          
          <p><strong>Hauptthemen:</strong> Web Analyse, Datenanalyse, Blog Analyse, Web Scraping, Python, Tableau, IT Sicherheit, Fefes Blog, Statistik</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> advanced</p>
          
        </div>
        
        
        <p>Nach der gar nicht mal so großen öffentlichen Wahrnehmung meiner laienhaften <a href="https://www.nickyreinert.de/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/">statistischen Analyse des Flirtportals der BVG &ldquo;Augenblicke&rdquo;</a>, habe ich mich mal einem anderem Projekt gewidmet. Es geht um <a href="http://blog.fefe.de">Fefes Blog</a>, einer meiner ersten Anlaufstellen, wenn ich mir die tägliche Nachrichtendosis gebe. Inspiriert wurde ich dazu durch eine <a href="https://www.netaction.de/datenvisualisierung-von-fefes-blogzeiten/">Analyse der Blogzeiten von Fefe</a>, die allerdings schon acht Jahre zurück liegt.<br>
Für meine Analyse des BVG-Portal hatte ich damals noch PHP gewählt, um die Seiten auszulesen und in eine Datenbank zu hauen. Das war ziemlich aufwendig. Diesmal wollte ich es mit Python probieren und damit auch gleich mein erstes Projekt in dieser Sprache realisieren (der Quellcode steht <a href="https://github.com/nickyreinert/fefeScrape">auf Github</a> zur Verfügung).</p>
<p>Die ersten Schritte mit Python waren etwas holprig. Mit der Zeit zeigt sich aber, dass das Scraping hier weitaus bequemer ist als mit PHP. Außerdem ist Fefes Blog eine ziemlich angenehme Datenquelle, da Fefe seit Anbeginn auf eine wirklich saubere und konsistente Seitenstruktur setzt. Pures HTML. Es ist ein Traum. Danke, Fefe. Ein paar Hintergründe zur Datenerfassung gibt es am Ende.</p>
<h2 id="auswertung">Auswertung</h2>
<p>Insgesamt habe ich 43.908 Einträge im Zeitraum von Ende März 2005 bis Anfang November 2019 ausgewertet. Nach meiner Zählung hat Fefe einen sehr reichen Wortschatz: ich konnte 141.048 verschiedene &ldquo;Wörter&rdquo; ausfindig machen. Außerdem verweißt Fefe auf 8.862 externe Quellen. Auf sich selber hat Fefe innerhalb des Zeitraums 2.661 mal verlinkt. Auch wenn Fefe den Spiegel oft als &ldquo;ehemaliges Nachrichtenmagazin&rdquo; bezeichnet: Der Spiegel ist mit 4.447 Verlinkungen die meist genutzt Quelle, gefolgt von heise.de (3.252). Man muss aber auch eingestehen, dass die Verlinkung zum Spiegel seit 2010 stark abnimmt.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/fefe_words-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/fefe_words-1-700x339.png" alt="Fefes Quellen - Spiegel Online, Heise und… er selbst ;)"></a></p>
<p>Fefes Quellen - Spiegel Online, Heise und&hellip; er selbst ;)</p>
<p>Insgesamt kann man einen Abwärtstrend der Nachrichtenfrequenz bei Fefe feststellen. Seinen Höhepunkt hatte Fefe gleich zu Beginn: Im Juli 2005 gab es 528 Einträge. Den zweiten Höhepunkt erreichte Fefes Blog knapp 10 Jahre später. Im April 2015 gab es 440 Einträge. Ansonsten zeigt der Trend leider nach unten. Im Schnitt gibt es jeden Monat 244 Beiträge (Median 238). Für November 2019 sagt das Prognosemodul von Tableau übrigens 182 Einträge voraus.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/monthly.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/monthly-700x361.png" alt="Anzahl der Einträge pro Monat im Jahresverlauf"></a></p>
<p>Anzahl der Einträge pro Monat im Jahresverlauf</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/blogging-times.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/blogging-times-62x300.png" alt="Anzahl der Nachrichten je Tageszeit im Jahresverlauf"></a></p>
<p>Anzahl der Nachrichten je Tageszeit im Jahresverlauf</p>
<p>In Anlehnung an mein Vorbild, habe ich mir natürlich auch angeschaut, zu welcher Tagszeit Fefe aktiv ist. Zunächst erkennt man, dass Fefe bevorzugt nachmittags aktiv ist. Aber scheinbar gibt es auch hier saisonale Unterschiede. So ist er im Januar bis Juli 2006, den März ausgeschlossen, eher ab 17 Uhr aktiv, danach aber wieder über den ganzen Tag verteilt (Nachtstunden ausgeschlossen). Im April und Mai 2007 konzentrieren sich die Nachrichten wieder auf den späten Nachmittag. In den folgenden Jahren, bis 2015, sind es immer wieder die Frühsommer / Frühlingsmonate, in denen sich die Beiträge zu dieser Tageszeit konzentrieren. Entweder ist Fefe ist ein ausgesprochener Frühlingsmensch. Eine andere Erklärung sind Projekte, die in diesen Monaten stattfinden und ein Bloggen erst zum Nachmittag zulassen. Denkbar ist auch, dass Fefe aufgrund seiner (zyklischen?) Reisetätigkeit und dem damit verbundenen Zeitzonenwechsel zu unterschiedlichen Zeiten bloggt.</p>
<p>Kreuzt man den Wochentag mit der Tageszeit, zeigt sich, wann Fefe die meisten Beiträge absetzt. Mittwochs um 17 Uhr. Das Wochenende ist Fefe heilig, die Beitragsfrequenz ist hier sehr niedrig. Auch zu den typischen Nachtzeiten gibt es nur sehr wenige Einträge. Hier gibt es öfter auffällige Konzentrationen, wie z.B. im Frühling 2015, die ich auch auf Zeitzonenwechsel - sprich Reisen - schiebe.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-nachrichten-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-nachrichten-1.png" alt="Anzahl der Nachrichten je Wochentag und Tageszeit"></a></p>
<p>Anzahl der Nachrichten je Wochentag und Tageszeit</p>
<p>Die längsten Nachrichten entstehen übrigens zur Nachtzeit (oder je nach Sichtweise, während den Reisen in andere Zeitzonen). Montags, um 5 Uhr, ist die durchschnittliche Wortzahl am höchsten. Der Median weist dazu übrigens den Sonntag um 2 Uhr nachts aus.</p>
<ul>
<li>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-avg-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-avg-1.png" alt=""></a></p>
<p>Wortanzahl (Mittelwert) je Wochentag und Tageszeit</p>
</li>
<li>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-median-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-median-1.png" alt=""></a></p>
<p>Wortanzahl (Median) je Wochentag und Tageszeit</p>
</li>
</ul>
<p>Eine Wortwolke, analog der Wolke der externen Quellen, ist aufgrund der schieren Menge etwas zu aufwendig und hätte auch nur wenig Informationsgehalt, weshalb ich darauf mal verzichte. Hier nur eine Darstellung der häufigsten Wörter, weil es so schön aussieht:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/woerter.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/woerter-700x387.png" alt="Spektakuläre Topliste der verwendeten Wörter"></a></p>
<p>Spektakuläre Topliste der verwendeten Wörter</p>
<p>Was ich allerdings liefern kann, ist eine Liste der Fefe-Kunstwörter, wie z.B. &ldquo;<a href="https://blog.fefe.de/?ts=a27615a6">Notfall-Soforthilfe-Klopapier&rdquo;</a>. Das längste dieser Art ist &ldquo;<a href="https://blog.fefe.de/?ts=b293636b">Webforen-Besserwisser-Klugscheißer-Korinthenkacker-Sockenpuppen-Grabenkriegen&rdquo;</a>. Das folgende Diagramm zeigt die Top 33 der Fef&rsquo;schen Wortschöpfungen:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-700x368.png" alt="Fefes Wortschöpfungen Top 33"></a></p>
<p>Fefes Wortschöpfungen Top 33</p>
<p>Kommen wir zu den Verweisen auf externe Quellen. Der Spiegel (Online) gehört wie gesagt zu den favorisierten Quellen von Fefe. Ansonsten ist Fefe nicht wählerisch, was Quellen angeht. Die Auswahl ist immens. Interessant ist, wie z.B. <em>Twitter</em> seit 2009 immer öfter zu den verlinkten Quellen gehört. Auf <em>The Guardian</em> hingegen wurde von Fefe 2013 zum letzten Mal verwiesen. Auf sich selber verweist Fefe natürlich auch hin und wieder. Am häufigsten in 2008, mit abnemender Tendenz.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/jahr-quellen-ab-50.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/jahr-quellen-ab-50-700x391.png" alt="Verwendete Quellen / Domains"></a></p>
<p>Verwendete Quellen / Domains</p>
<h2 id="fazit">Fazit</h2>
<p>Und was ist jetzt Fefes WLAN-Passwort? Wir wissen es nicht. Und wir werden es auch nicht erfahren, wenn wir seinen Blog noch drölf mal parsen. Vielleicht sind die zahlreichen zusammengesetzen Substantive als Indiz hilfreich? Egal.</p>
<p>Also gibt es kein Fazit, mit Ausnahme der Feststellung, dass es zeitliche Muster gibt, Fefe ein außerordentliche fleißiger Autor ist aber sonst, leider, die Tendenz der Nachrichtenanzahl in den letzten Jahren zurück gegangen ist.</p>
<h2 id="fehlerquellen-und-technische-hintergründe">Fehlerquellen und technische Hintergründe</h2>
<p>Auch wenn der HTML-Code sehr aufgeräumt ist, vor Fehlern ist auch Fefe nicht gefeit. So gibt es zum Beispiel 110 nicht bzw. falsch geschlossene <A>-Tags. Hier musste ich per Script stumpf ein schließendes </a> setzen, was die Auswertung der Quellen / Domains ein wenig, aber kaum merklich, verfälscht.</p>
<p>Auch bei den Wörtern musste ich etwas aufräumen, um so z.B. alle möglichen Nicht-Buchstaben entfernen. Danach musste ich die Liste noch ein wenig von Hand sortieren, un so z.B. ein paar verirrte URL zu entfernen.</p>
<p>Die verlinkten Quellen war recht einfach zu handhaben. Hier habe ich lediglich die Präfixe entfernt, wenn diese mit www und ggf. einer Ziffer beginnen. Trotzdem muss bei dieser Liste berücksichtigt werden, dass manche Quellen über mehrere Domains erreichbar sind. So verweist Fefe z.B. auf das Angebot der BBC mit zehn verschiedenen Varianten:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-1-700x341.png" alt="Varianten für den Verweis zur BBC"></a></p>
<p>Varianten für den Verweis zur BBC</p>
<p>Der Fefe-Timestamp ist eine Geschichte für sich. Alleine wäre ich vermutlich kaum auf die Idee gekommen, dass hinter der eindeutigen Id, mit der jeder Beitrag erreichbar ist, tatsächlich eine Zeitangabe steckt. <a href="https://www.netaction.de/datenvisualisierung-von-fefes-blogzeiten/">Meine Inspirationsvorlage</a> hat hier zum Glück sehr gute Vorarbeit geleistet und erklärt, wie sich der alphanumerische Wert in ein lesbares Datum umwandeln lässt. Es handelt sich bei dem Wert nämlich um einen Hexadezimalangabe, die zunächst in eine Dezimalziffer umgewandelt werden muss. Danach erfolgt eine bitweise XOR-Operation um einen bestimmten Schlüssel: <strong>0xFEFEC0DE</strong>. Das ergibt schließlich einen Unix-Zeitstempel, der sich in ein lesbares Datum umwandeln lässt.</p>
<p>Zuletzt noch ein Hinweis zu den Daten aus den Anfangszeiten, also März bis Juni 2005. Vermutlich hat Fefe diese nachträglich eingefügt, da dort der Zeitstempel jeweils auf 12 bis 13 Uhr zeigt. Diese Monate habe ich aus den Analysen mit den Tageszeiten ausgeschlossen.</p>
<p>Zuletzt noch ein Hinweis zu den verwendeten Tools:</p>
<p>Einerseits nutze ich für die Auswertung und Darstellung <a href="https://public.tableau.com/en-us/s/">Tableau Public</a>, dass es auch als kostenlose Variante gibt. Für die Wordcloud nutze ich <a href="http://www.wordle.net/">Wordle</a>. Wordle gab es eine zeitlang nur als WebApp, mittlerweile läuft Wordle aber auch als native OSX- oder Windows-Anwendung. Das Python-Script habe ich mit <a href="https://code.visualstudio.com/">Visual Studio Code</a> geschrieben, das im Begriff ist, Notepad++ als Allround-IDE abzulösen. Und mit Excel habe ich die Daten etwas bereinigt, das klappt damit immer noch fixer als mit Tableau.</p>
<h2 id="update">UPDATE</h2>
<p>Durch Zufall bin ich eben noch auf <a href="https://weltliteratur.net/Fefe-Research-Institute/">eine etwas tiefere Textanalyse</a> gestoßen, die auch sehr interessant ist.</p>

        
        
        <div class="tags">
          <p><strong>Tags:</strong> Fefes Blog, Datenanalyse, Web Scraping, Python, Statistik</p>
        </div>
        
      ]]></content:encoded>
      
      
      
      <category>blog</category>
      
      
      
      
      <media:content url="https://nickyreinert.de/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Fefes Blog - Eine Analyse - Titelbild</media:title>
      </media:content>
      
      
      
      
      <dc:subject>Lesezeit: 5 Minuten</dc:subject>
      
      
      
      <dc:type>data_analysis</dc:type>
      
      
    </item><item>
      <title>Tutorial: Web-Scraping mit VBA - Teil 1</title>
      <link>https://nickyreinert.de/2010/2010-09-16-tutorial-web-scraping-mit-vba-teil-1/</link>
      <pubDate>Thu, 16 Sep 2010 00:00:00 +0000</pubDate>
      <author></author>
      <guid>https://nickyreinert.de/2010/2010-09-16-tutorial-web-scraping-mit-vba-teil-1/</guid>
      <description>In dieser kleinen Tutorial-Serie will ich anhand einer Online-Handy-Datenbank zeigen, wie man mit VBA Seiten aus dem Internet abruft und nach Informationen …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Dies ist der erste Teil einer Tutorial-Reihe, die zeigt, wie man mit VBA in Excel Web-Scraping betreibt. Der Artikel erklärt die Grundlagen des Abrufens von Webseiten-Inhalten mittels &#39;WinHttpRequest&#39; und des Parsens von HTML, um eine Liste von Hersteller-Links von einer Handy-Datenbank-Website zu extrahieren.</p>
          
          
          <p><strong>Hauptthemen:</strong> VBA, Web-Scraping, Excel, HTML-Parsing, Automatisierung</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> advanced</p>
          
        </div>
        
        
        <p>In dieser kleinen Tutorial-Serie will ich anhand einer Online-Handy-Datenbank zeigen, wie man mit VBA Seiten aus dem Internet abruft und nach Informationen sucht, die sich dann in einer Tabelle abspeichern lassen. Warum VBA? Es gibt vermutlich elegantere Lösungen, doch Excel ist eine Software, die die meisten zuhause nutzen. Man benötigt also keine zusätzliche Entwicklungsumgebung. Außerdem hat diese Methode den  Vorteil, dass die Daten sofort zur weiteren Verarbeitung verfügbar sind. VBA ist vielleicht nicht die performanteste Programmiersprache, dafür aber relativ leicht zu beherrschen.</p>
<p><a href="http://www.rechtzweinull.de/archives/100-screen-scraping-wann-ist-das-auslesen-und-die-veroeffentlichung-fremder-daten-zulaessig.html">(FYI: Rechtliches zum Thema Web- oder Screen-Scraping)</a></p>
<p> 
Diese Artikelserie richtet sich an den fortgeschrittenen Nutzer. Für den Einsteiger gehe ich nicht auf grundlegendes Programmierwissen ein (was sind Klassen, welche Variablen-Typen bietet Excel, etc.pp.) und für den professionellen Softwareentwickler sind meine Codebeispiele vermutlich zu infantil. Ich habe aber die Erfahrung gemacht, dass VBA und Excel für kurzfristige und kleine Projekte dieser Art recht nützliche Hilfsmittel sind. Außerdem bin ich kein &ldquo;ausgebildeter Softwareentwickler&rdquo;, weshalb ich an der Stelle auch gleich darauf Hinweise, dass Verbesserungsvorschläge sehr gerne gesehen sind!</p>
<p>Welches wissen solltest du also mitbringen?  Da es um das Parsen von HTML-Code geht, solltest du zumindest Bescheid wissen, wenn ich von div- und a-Elementen und css-Klassen rede. Du solltest auch wissen, wie man in VBA Variablen deklariert oder was eine if-Abfrage ist.</p>
<p>Das Endergebnis ist eine Tabelle mit technischen Spezifikationen zu den Mobiltelefonen, die inside-handy.de listet. Insgesamt werden drei Routinen genutzt, die - in umgekehrter Reihenfolge des Vorgehens - folgende Aufgabe haben:</p>
<p>Die letzte Routine greift auf eine Liste von URL zu, die auf die Datenblätter der Geräte verweisen. Von dort wird der HTML-Quellcode nach den  technischen Informationen durchsucht.</p>
<p>Auf inside-handy.de sind die Geräte nach Herstellern sortiert. Jede Herstellerseite verweist auf die entsprechenden Geräte. Wir werden also jede Herstellerseite (bzw. den entsprechenden HTML-Code) zunächst nach den URL zu den Geräten durchsuchen. Diese Aufgabe übernimmt die zweite Routine bzw. Prozedur.</p>
<p>Die erste Routine schließlich liefert die Liste aller URL zu den Herstellern, die wir uns aus dem HTML-Code der Herstellerübersicht auf inside-handy.de laden. Und damit geht es nun los:</p>
<p>1. Die URL zu den Hersteller-Unterseiten auslesen - sub getManufacturer</p>
<p>1.1 Datei per HTTP von einem Server laden</p>
<p>Im ersten Schritt laden wir die komplette HTML-Datei in den Zwischenspeicher. Dazu gibt es mindesten zwei Methoden, die gängigste ist vermutlich die über <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa384106%28v=vs.85%29.aspx">WinHttpRequest</a>. Bevor du das nutzen kannst, musst du bei VBA unter Extras - Verweise jedoch erst die Microsoft HTML Object Library einbinden.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Dim url As String
</span></span><span class="line"><span class="ln">2</span><span class="cl">Dim result As String
</span></span><span class="line"><span class="ln">3</span><span class="cl">Dim winHttpReq As Object
</span></span><span class="line"><span class="ln">4</span><span class="cl">url = &#34;http://www.inside-handy.de/hersteller/handys&#34;
</span></span><span class="line"><span class="ln">5</span><span class="cl">
</span></span><span class="line"><span class="ln">6</span><span class="cl">Set winHttpReq = CreateObject(&#34;WinHttp.WinHttpRequest.5.1&#34;)
</span></span><span class="line"><span class="ln">7</span><span class="cl">winHttpReq.Open &#34;GET&#34;, url, False
</span></span><span class="line"><span class="ln">8</span><span class="cl">winHttpReq.send
</span></span><span class="line"><span class="ln">9</span><span class="cl">result = winHttpReq.responseText
</span></span></code></pre></div><p>Die Deklaration der Variablen erklärt sich von selbst. Nachdem ich eine Instanz vom WinHTTP-Objekt erzeugt habe, kann ich die Parameter übergeben. Dazu gehört neben der URL auch die Bestimmung des HTTP-Requests - nämlich GET. Der letzte, booleansche, Paramter gibt an, ob die Verbindung im asynchronen Modus geöffnet werden soll. Mit .send wird der Request tatsächlich ausgelöst und das Ergebni dann an die String-Variable result zurückgegeben. Dort befindet sich nun unser HTML-Code</p>
<p>Wir können unseren Request natürlich auch per POST absetzen und noch andere Header-Informationen anhängen:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Set winHttpReq = CreateObject(&#34;WinHttp.WinHttpRequest.5.1&#34;)
</span></span><span class="line"><span class="ln">2</span><span class="cl">
</span></span><span class="line"><span class="ln">3</span><span class="cl">winHttpReq.Open = &#34;Post&#34;, url, False
</span></span><span class="line"><span class="ln">4</span><span class="cl">winHttpReq.setRequestHeader &#34;User-Agent&#34;, &#34;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)&#34;
</span></span><span class="line"><span class="ln">5</span><span class="cl">winHttpReq.setRequestHeader &#34;Content-type&#34;, &#34;application/x-www-form-urlencoded&#34;
</span></span><span class="line"><span class="ln">6</span><span class="cl">winHttpReq.send (URLEncode(&#34;username=user1&amp;password=secret&#34;) )
</span></span><span class="line"><span class="ln">7</span><span class="cl">
</span></span><span class="line"><span class="ln">8</span><span class="cl">result = winHttpReq.responseText
</span></span></code></pre></div><p>So ist es z.B. möglich, Formulardaten zu übermitteln, um an eine passwortgeschützte Seite oder die Ergebnisseite einer Suche zu gelangen. Dabei werden die POST-Daten als weiterer Parameter beim Senden mitgegeben. Eine weitere Möglichkeit ist die Durchführung einer HTTP-Authentifizierung:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Dim HTTPREQUEST\_SETCREDENTIALS\_FOR\_SERVER As Boolean
</span></span><span class="line"><span class="ln">2</span><span class="cl">
</span></span><span class="line"><span class="ln">3</span><span class="cl">winHttpReq.Open &#34;GET&#34;, url, False
</span></span><span class="line"><span class="ln">4</span><span class="cl">winHttpReq.SetCredentials &#34;user&#34;, &#34;password&#34;, HTTPREQUEST\_SETCREDENTIALS\_FOR\_SERVER
</span></span><span class="line"><span class="ln">5</span><span class="cl">winHttpReq.send
</span></span></code></pre></div><p>Neben dem winHttpRequest-Objekt gibt es noch eine weniger elegante Methoden, in dem direkt eine Instanz des Internet Explorers erzeugt wird:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl">Dim sPostData As String
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">Dim bPostData() As Byte
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">Dim WebBrowser: Set WebBrowser = CreateObject(&#34;InternetExplorer.Application&#34;)
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">WebBrowser.Visible = True
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">sPostData = URLEncode(&#34;username=user1&amp;password=secret&#34;)
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">ReDim bPostData(Len(sPostData) - 1)
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">bPostData = StrConv(sPostDataData, vbFromUnicode)
</span></span><span class="line"><span class="ln">10</span><span class="cl">
</span></span><span class="line"><span class="ln">11</span><span class="cl">WebBrowser.navigate url, 2 + 4 + 8, , bPostData, &#34;Content-type: application/x-www-form-urlencoded&#34;
</span></span><span class="line"><span class="ln">12</span><span class="cl">Do While WebBrowser.Busy
</span></span><span class="line"><span class="ln">13</span><span class="cl">    DoEvents
</span></span><span class="line"><span class="ln">14</span><span class="cl">Loop
</span></span><span class="line"><span class="ln">15</span><span class="cl">result = WebBrowser.document.body.innerHTML 
</span></span><span class="line"><span class="ln">16</span><span class="cl">WebBrowser.Quit
</span></span></code></pre></div><p>Da diese Methode - wie gesagt - nicht sonderlich elegant ist, werde ich aber nicht weiter darauf eingehen.</p>
<p>Nun zurück zu unserem Skript. Den HTML-Code der Seite haben wir nun erstmal in einen String gelegt. Damit wir das HTML-Dokument bequem lesen können, erzeugen wir ein HTML-Document, an das wir den HTML-Code übergeben:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Set HTMLDoc = New HTMLDocument
</span></span><span class="line"><span class="ln">2</span><span class="cl">Set HTMLDoc = CreateObject(&#34;htmlfile&#34;)
</span></span><span class="line"><span class="ln">3</span><span class="cl">HTMLDoc.Open
</span></span><span class="line"><span class="ln">4</span><span class="cl">HTMLDoc.write (CStr(result))
</span></span><span class="line"><span class="ln">5</span><span class="cl">HTMLDoc.Close
</span></span></code></pre></div><p>Auch hier erklärt sich der Code fast von selber: Eine Instanz des Objektes erzeugen, diese Instanz zum &ldquo;Befüllen&rdquo; vorbereiten, den String übergebne und die Instanz wieder &ldquo;schließen&rdquo;. Soweit, so unkompliziert. Im nächsten Schritt geht es nun direkt an das Parsen des Quellcodes um die Links zu den Herstellerseiten zu erhalten. Die Schleife dazu ist nicht sehr aufwendig:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl">    Dim oneElement1, allElements1 As IHTMLElementCollection
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">    Dim oneElement2, allElements2 As IHTMLElementCollection
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">    Dim oneElement3, allElements3 As IHTMLElementCollection
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">    
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">    Worksheets(&#34;srcURL&#34;).Range(&#34;a2&#34;).Select
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">    i = 0
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">    Set allElements1 = HTMLDoc.getElementsByTagName(&#34;a&#34;)
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">          
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">    i = 0
</span></span><span class="line"><span class="ln">10</span><span class="cl">    For Each oneElement1 In allElements1
</span></span><span class="line"><span class="ln">11</span><span class="cl">        If oneElement1.parentElement.className = &#34;h\_img&#34; Then
</span></span><span class="line"><span class="ln">12</span><span class="cl">            If oneElement1.parentElement.parentElement.ID = &#34;h\_alle&#34; Then
</span></span><span class="line"><span class="ln">13</span><span class="cl">                If InStr(1, oneElement1.getAttribute(&#34;href&#34;), &#34;/tablets&#34;) &lt;= 0 Then
</span></span><span class="line"><span class="ln">14</span><span class="cl">                    Selection.Offset(i, 0).Value = Replace(oneElement1.getAttribute(&#34;href&#34;), &#34;about:&#34;, &#34;http://www.inside-handy.de&#34;)
</span></span><span class="line"><span class="ln">15</span><span class="cl">                    i = i + 1
</span></span><span class="line"><span class="ln">16</span><span class="cl">                End If
</span></span><span class="line"><span class="ln">17</span><span class="cl">            End If
</span></span><span class="line"><span class="ln">18</span><span class="cl">            
</span></span><span class="line"><span class="ln">19</span><span class="cl">        End If    
</span></span><span class="line"><span class="ln">20</span><span class="cl">    Next oneElement1
</span></span><span class="line"><span class="ln">21</span><span class="cl">End Sub
</span></span></code></pre></div><p>Wie bin ich vorgegangen? Ich habe mir zunächst den Quellcode der Seite angeschaut. Die Liste der Hersteller ist dort eine Tabelle mit den Logos der Unternehmen. Die gewünschte Information befindet sich in a-Elementen, die wiederum innerhalb eines div-Elements liegen. Das gemeinsame &ldquo;Oberelement&rdquo; ist ein div-Container mit der CSS-Klasse &ldquo;h_img&rdquo; bzw. einem weiterne div-Container (&ldquo;h_alle&rdquo;). Außerdem gibt es einen ausgeblendeten div-Container mit einer Liste von Tablet-Herstellern, diese haben den Begriff &ldquo;/tablet&rdquo; in der href-Angabe und müssen ignoriert werden.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="line"><span class="ln">1</span><span class="cl"><span class="p">&lt;</span><span class="nt">div</span> <span class="na">id</span><span class="o">=</span><span class="s">&#34;h\_alle&#34;</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">	<span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;h\_img&#34;</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl">		<span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/hersteller/xyz&#34;</span> <span class="na">title</span><span class="o">=</span><span class="s">&#34;Handys Hersteller: XYZ&#34;</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl">			<span class="p">&lt;</span><span class="nt">img</span> <span class="p">/&gt;</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">		<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="ln">6</span><span class="cl">	<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</span></span></code></pre></div><p>Mit &ldquo;Set allElements1 = HTMLDoc.getElementsByTagName(&ldquo;a&rdquo;)&rdquo; lasse ich mir also erst alle a-Elemente aus dem Quellcode in meinen &ldquo;Container&rdquo; legen.</p>
<p>Mit der ersten for-each-Schleife durchlaufe ich nun diesen Container und prüfe mit den ersten zwei if-Abfragen, ob sich das a-Element unterhalb der erwähnten div-Container befindet. Da auf der Seite noch ein weitere identische div-Container mit diesen css-Klassen für die Liste der Tablet-Hersteller existiert, muss ich mit einer dritten if-Abfrage die URL des a-Elements überprüfen. Erst dann kann ich das Attribut des a-Elements auslesen und in mein Excel-Worksheet schreiben.</p>
<p>Fertig ist der erste Schritt - eine Liste der URL zu den jeweiligen Herstellern. Im nächsten Teil werde ich diese Liste durchgehen und von den jeweiligen Seiten die URL zu den Geräten auslesen.</p>

        
        
        <div class="tags">
          <p><strong>Tags:</strong> VBA, Excel, Web-Scraping, Tutorial</p>
        </div>
        
      ]]></content:encoded>
      
      
      
      <category>development</category>
      
      <category>office</category>
      
      <category>anleitungen</category>
      
      
      
      
      <media:content url="https://nickyreinert.de/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Tutorial: Web-Scraping mit VBA - Teil 1 - Titelbild</media:title>
      </media:content>
      
      
      
      
      <dc:subject>Lesezeit: 5 Minuten</dc:subject>
      
      
      
      <dc:type>tutorial</dc:type>
      
      
    </item>
  </channel>
</rss>