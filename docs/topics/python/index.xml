<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" 
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>Python auf Nicky Reinert</title>
    <link>http://localhost:1313/topics/python/</link>
    <description>Blog &amp; Projekte von Nicky Reinert (Institut für digitale Herausforderungen): Webentwicklung &amp; Software Development, SEO &amp; Analytics, Hosting &amp; DevOps, WordPress &amp; Hugo, Tools &amp; Projekte, Datenschutz und digitale Kultur – plus Texte zu KI sowie Autismus &amp; Gesellschaft.</description>
    <generator>Hugo 0.148.2</generator>
    <language>de</language>
    <managingEditor></managingEditor>
    <webMaster></webMaster>
    <copyright></copyright>
    <lastBuildDate>Tue, 12 Aug 2025 19:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/topics/python/index.xml" rel="self" type="application/rss+xml" /><item>
      <title>Der Schmale Grat zwischen Scam und eifrigem Unternehmertum</title>
      <link>http://localhost:1313/2025/2025-08-06-schmaler-grat-scam-und-unternehmertum/</link>
      <pubDate>Tue, 12 Aug 2025 19:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2025/2025-08-06-schmaler-grat-scam-und-unternehmertum/</guid>
      <description>English Version
Ich bin kein Fan von Handyspielen Nicht, weil ich nicht gerne spiele, sondern weil sich rund um Handyspiele ein aus meiner Sicht fragwürdiges …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>*[English Version](https://nickyreinert.de/en/blog/2025/08/12/the-thin-line-between-scam-and-ambitious-entrepreneurship/)*&#39; reading_time: 23 content_type: &#39;project</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Mac, Git, Mobile, Ai, Automation</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p><em><a href="https://nickyreinert.de/en/blog/2025/08/12/the-thin-line-between-scam-and-ambitious-entrepreneurship/">English Version</a></em></p>
<h2 id="ich-bin-kein-fan-von-handyspielen">Ich bin kein Fan von Handyspielen</h2>
<p>Nicht, weil ich nicht gerne spiele, sondern weil sich rund um Handyspiele ein aus meiner Sicht fragwürdiges Geschäftsmodell entwickelt hat und es sehr schwer ist, die wahren Perlen zu finden. Es scheint, als ginge es nur noch darum entweder Werbeplätze zu vertreiben oder mit einfachen Spiel-Mechaniken In-App Käufe zu generieren. Sicher gibt es Ausnahmen, aber diese gehen in der schieren Menge des Angebots unter.</p>
<p>Auf eines dieser Spiele bin ich neulich durch Zufall gestoßen und es repräsentiert genau diese Vorwürfe hervorragend: <strong><a href="https://play.google.com/store/apps/details?id=com.EternalStudio.DozerDemolish&amp;hl=en_US">Dozer Demolish</a></strong>.</p>
<p>Auf Google Play wird das Spiel <strong>ohne Altersfreigabe</strong> beworben, im AppStore von Apple sind es <strong>4 Jahre</strong>. Im android&rsquo;schen Geschäft ist die Rede von über <strong>10 Millionen Downloads</strong>, <a href="https://www.eternalgamestudio.com/">laut Developer Eternal Studio sind es mehr als 15 Mio</a>.</p>
<p align="center">
  <a href="screenshot-playstore-usk.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-playstore-usk.png" alt="alt text" width="500"/>
  </a>
</p>
<center><small>Ohne Altersbeschränkung und In-Game-Käufe. Klingt nach einem Widerspruch *hust* Geschäftsfähigkeit *hust*</small></center>
<br />
<br />
<p>Der Vertrieb erfolgt durch <strong><a href="https://www.homagames.com/">HOMA</a></strong>, wo wohl auch andere EntwicklerInnen unter Vertrag stehen. Sitz: Frankreich. Also innerhalb der Jurisdiktion der DSGVO. Das Motto von <strong>HOMA</strong> lautet:</p>
<p align="center">
  <a href="https://play.google.com/store/apps/dev?id=4656343638685426415&hl=en&gl=US" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-playstore-motto.png" alt="HOMA Motto - Quelle Android Play Store https://play.google.com/store/apps/dev?id=4656343638685426415&hl=en&gl=US" width="700"/>
  </a>
</p>
<center><small>HOMA Motto - Quelle Android Play Store <a href="https://play.google.com/store/apps/dev?id=4656343638685426415&hl=en&gl=US">https://play.google.com/store/apps/dev?id=4656343638685426415&hl=en&gl=US</a></small></center>
<br />
<br />
<p>&ldquo;Amazing Content&rdquo; - Naja, <em>schau&rsquo;mer mal</em>!</p>
<p>Die Spiele aus der Kategorie &ldquo;Convenience Gaming&rdquo; funktionieren nach dem selben Prinzip: Es gibt kaum Tiefgang, die Regeln sind schnell erklärt, die Steuerung ist intuitiv und oft ist nicht mal viel Geschick oder Nachdenken erforderlich. Alles ist auf die kurzfristige Dopamin-Ausschüttung ausgelegt. Das muss nicht abwertend sein, es ist eine Form der Unterhaltung, die immerhin Millionen von SpielerInnen anzieht.</p>
<p>Das Spielprinzip von <strong>Dozer Demolish</strong> bleibt dem Branchenprinzip treu. Man <em>schlawinert</em> mit schwerem Gerät über wechselnde Landschaften, zerstört Gebäude, sammelt deren Reste ein und bekommt dafür Geld, mit dem man neue Fahrzeuge kaufen oder vorhandene aufrüsten kann. Einhändig und nebenbei. Auf dem Klo. Im Bett. Im Zug. Während des Meetings. &ldquo;Convenience Gaming&rdquo; eben.</p>
<h1 id="die-sache-mit-dem-datenschutz">Die Sache mit dem Datenschutz</h1>
<p>Soweit. So unspektakulär. Interessant wird es, vorausgesetzt man hat ein Faible für diese Art von Details, beim <strong>Datenschutz</strong>.</p>
<p align="center">
  <a href="meme-datenschutz.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="meme-datenschutz.png" alt="alt text" width="500"/>
  </a>
</p>
<br />
<br />
<p>Laut Selbstauskunft teilt die App Daten der folgenden Kategorien mit anderen Unternehmen:</p>
<ul>
<li>Finanzdaten</li>
<li>Personenbezogene Daten wie E-Mail-Adressen und Nutzer-IDs</li>
<li>App-Aktivitäten</li>
</ul>
<p>Nicht weiter verwerflich, da das beim In-App-Kauf und der Werbung durchaus Sinn macht.</p>
<p>Aber Standortdaten? (Hinweis: Standortbasierte Werbung&hellip;)</p>
<p align="center">
  <a href="screenshot-playstore-dataprivacy.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-playstore-dataprivacy.png" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Standortdaten. Warum?</small></center>
<br />
<br />
<p>Schwierig. Aber das ist noch nicht alles. Denn unter den Sicherheitsmaßnahmen heißt es:</p>
<blockquote>
<p>Daten werden nicht verschlüsselt.
Daten können nicht gelöscht werden.</p></blockquote>
<p>Ok. Immerhin ehrlich, wenn auch nicht mehr zeitgemäß. Im PlayStore von Google wird auf die Datenschutzerklärung des Entwicklers verwiesen, die dem Namen &ldquo;Datenschutzerklärung&rdquo; zu Unrecht trägt. Eine Google-Mail-Adresse, ein Absatz zu Google Analytics und dann ein Hinweis zu &ldquo;Minderjährigen&rdquo;:</p>
<p align="center">
  <a href="screenshot-eternal-dataprivacy.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-eternal-dataprivacy.png" alt="alt text" width="700"/>
  </a>
</p>
<center><small>Die Datenschutzerklärung von Eternal Studio</small></center>
<br />
<br />
<blockquote>
<p>&ldquo;Eternal Studio does not knowingly collect personal information from children under the age of 13.&rdquo;</p></blockquote>
<p>Natürlich nicht. Blöd nur, dass das Spiel ohne Altersfreigabe angeboten wird.</p>
<blockquote>
<p>&ldquo;If Eternal Studio learns that Eternal Studio has inadvertently gathered personal information from children under 13 years of age, Eternal Studio will take reasonable measures to promptly delete such personal data from Eternal Studio’s records.&rdquo;</p></blockquote>
<p>&ldquo;inadvertently&rdquo; (&ldquo;aus Versehen&rdquo;) - das klingt ein bisschen nach &ldquo;aus der Verantwortung ziehen&rdquo;.</p>
<p>Übertroffen wird das dann nur noch durch diesen Hinweis:</p>
<blockquote>
<p>&ldquo;If you are under the age of 13 or a minor in your county of residence, please ask your legal guardian’s permission to access and use our services.&rdquo;</p></blockquote>
<p>Das 4-jährige Kind soll sich also, nach Lektüre der englischen Datenschutzerklärung, an seine Eltern wenden, und um Erlaubnis bitten. Genau mein Humor. Zur Erinnerung: Das Spiel hat mit 15 Mio. Downloads eine enorme Reichweite. Etwas mehr Professionalität ist nicht zu viel verlangt, oder?</p>
<p>Unnötig zu erwähnen, dass die Seite keine Auskunft darüber gibt, mit wem man es hier tatsächlich zu tun hat. Laut &ldquo;Impressum&rdquo; kann man über <em><a href="mailto:xxx@eternalgamestudio.com">xxx@eternalgamestudio.com</a></em> Kontakt aufnehmen. In der Datenschutzerklärung selbst ist es wiederum <em><a href="mailto:xxx@gmail.com">xxx@gmail.com</a></em>. <a href="https://www.facebook.com/EternalApps/about_contact_and_basic_info">Die Facebook-Seite</a> verweist auf <em><a href="mailto:xxx@gmail.com">xxx@gmail.com</a></em>. <a href="https://x.com/eternalgamebros">Auf X/Twitter</a> erfährt man zumindest, dass das Entwicklerstudio vermutlich aus Michigan (USA) stammt.</p>
<p><em>(E-Mail-Adressen durch mich anonymisiert, sie sind zwar öffentlich zugänglich, aber wer weiß&hellip;)</em></p>
<p>Genug genörgelt, vielleicht - und das sage ich ganz unironisch - wurde der oder die EntwicklerIn ja vom Erfolg überrascht und ich bin nur durch Zufall auf eine seltene Ausnahme gestoßen. Dennoch: Hinter dem Spiel steht ein ein durchaus großer Publisher. Ein Produkt mit 15 Mio. NutzerInnen und einer derart aggressiven Werbestrategie, da darf man wohl etwas genauer hinschauen.</p>
<p>(Der AppStore von Apple verweist übrigens auf <a href="https://www.homagames.com/privacy-policy">die Datenschutzerklärung des Publishers</a>. Diese ist kumpelhaft aufgesetzt und durchaus ausführlich.)</p>
<p>Beim ersten Eindruck fällt der formelle Datenschutz also schon mal durch. Wie sieht es denn in der App aus?</p>
<p>Los geht es mit dem üblichen Consent Dialog. Hier hat man die Möglichkeit, alles ungesehen zu akzeptieren, oder per Detailauswahl Einfluss auf die erhobenen Daten zu nehmen. Problematisch: Einen Button für &ldquo;alles ablehnen&rdquo; gibt es nicht. Die Detailauswahl verbirgt sich in einer zweiten Ansicht und ist nicht sofort zugänglich.</p>
<p>Die Liste der eingesetzten Technologien ist für ein Spiel beeindruckend lang. <strong>69 Vendoren</strong> messen die Performance der Werbung, 24 die der App selber. 33 Anbieter zur Analyse von Zielgruppen, 57 um die Dienste zu verbessern. 7 Anbieter für das Targeting.</p>
<p>Jede Kategorie wird hier optimistisch als &ldquo;legitimate interest&rdquo; deklariert, also &ldquo;legitimes Interesse&rdquo;. Zur Erinnerung: Das Spiel kommt ohne Altersfreigabe aus. Bei Minderjährigen gelten laut DSGVO besondere Schutzbedürfnisse.</p>
<p>Auch die einzelnen Verarbeitungskategorien müssen händisch abgewählt werden. Unnötig zu erwähnen, dass die Erklärungen für eine<em>n normalsterbliche</em>n Nutzer<em>in, geschweige denn Minderjährige</em>n, alles andere als verständlich sind. (Hier hat übrigens der Branchenverband <strong>IAB</strong> ganze Arbeit geleistet, der diese Art von Überspezifikation namens <strong>TCF</strong> (Transparency and Consent Framework) allen Ernstes als &ldquo;Transparenz&rdquo; verkauft.)</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <a href="screenshot-consent-dialog-1.png" target="_blank">
        <img src="screenshot-consent-dialog-1.png" alt="alt text" width="250"/>
      </a>
      <br />
      <small>Berechtigtes Interesse? Bitte händisch abwählen!</small>
    </td>
    <td align="center">
      <a href="screenshot-consent-dialog-2.png" target="_blank">
        <img src="screenshot-consent-dialog-2.png" alt="alt text" width="250"/>
      </a>
      <br />
      <small>Transparenz heißt nicht Verständlichkeit</small>
    </td>
  </tr>
</table>
</div>
<br />
<br />
<p>Das ist aber noch nicht alles: In der App kann man seine Auswahl nicht nachträglich korrigieren, es gibt dafür schlicht keinen Menüpunkt. Auch das ist mit den Vorgaben der DSGVO schwer vereinbar.</p>
<p>Beim Datenschutz hinterlässt die App also nicht den besten Eindruck. Aber das ist ja nicht alles geschweige denn das, was ein Spiel ausmacht.</p>
<blockquote>
<p>(Und da sind wir wieder bei meiner allgemeinen Kritik zum Thema Datenschutz: Die meisten NutzerInnen sind vermutlich eher genervt von den ewig langen Consent-Bannern, anstatt sich informiert zu fühlen. Ganz ohne Datenerhebung geht es aber auch nicht, als Daten Analyst bin ich mir dessen bewusst. Doch gerade kleinere Studios und Unternehmen sind mit den rechtlichen Vorgaben wohl eher überfordert.)</p></blockquote>
<p>Egal. Wie sieht es mit dem Inhalt aus?</p>
<h2 id="die-sache-mit-der-werbung">Die Sache mit der Werbung</h2>
<p>Wie oben schon erwähnt, hat sich hier ein Geschäftsmodell etabliert, bei dem kostenlose Spiele scheinbar nur als Plattform dienen, Werbung mit einer - Achtung, subjektive Übertreibung zum Zwecke der Dramatisierung - maßlosen Mangel an Feingefühl auf die Endgeräte zu drücken. Mich erinnert das an ein nicht ganz so berühmte Zitat, <a href="https://nickyreinert.de/2020/2020-10-24-marketing-killed-the-internet-star/">dass ich schon einmal passend rezitieren durfte</a>:</p>
<blockquote>
<p>Journalistische Inhalte sind das Vehikel, um die Aufmerksamkeit des Publikums für die werblichen Inhalte zu erreichen</p>
<p><em>Springer-Anwälte in 2015</em></p></blockquote>
<p>Und hier scheint es leider nicht anders zu sein. Aus unternehmerischer Sicht zolle ich dem Erfolg Respekt. Aus Sicht eines Nutzers ist diese Praxis nur einen Hauch von Scam entfernt.</p>
<p>Das Spiel wird kostenlos angeboten. Für <strong>1,99 Euro</strong> kann man ein Werbe-Frei-Paket erstehen. Das ist mindestens irreführend - dazu kommen wir gleich - und technisch auch schlecht umgesetzt:</p>
<p>Ich habe das Paket auf einem Gerät gekauft, auf einem zweiten Gerät werden weiterhin Werbebanner am unteren Rand des Spiels angezeigt.</p>
<p align="center">
  <a href="screenshot-dozer-unlocked.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-dozer-unlocked.png" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Das klappt ja gut mit dem Werbefrei-Paket.</small></center>
<br />
<br />
<p>Die ganze Werbung soll damit auch gar nicht deaktiviert werden. Man bekommt <em>drei Dutzend</em> &ldquo;Upgrade-Tickets&rdquo;, mit denen bestimmte In-Game-Aktionen finanziert werden. Nach etwa 1 Stunde Spielzeit sind diese auch schon wieder aufgebraucht. Und dann werden für Upgrades und andere Spielmechaniken sporadisch, aber auch mit einer aufdringlichen Regelmäßigkeit, Werbe-Videos fällig.</p>
<p>Und die haben es in sich. Wir reden hier nicht von kleinen Einspielern für 30 Sekunden - wie man es von YouTube gewöhnt ist.</p>
<p>&ldquo;Dozer Demolish&rdquo; spielt meist zwei Spots aus, die insgesamt erstmal fast 2 Minuten dauern. Manche der beworbenen Spiele lassen sich dann sogar für etwa 15 Sekunden direkt spielen und ausprobieren. Darf man den Werbe-Overlay jetzt wieder schließen? Nein. Zunächst wird man zum PlayStore geführt. Von dort geht es wieder zum Werbe-Overlay, mit einer abschließenden Werbe-Botschaft, die nun final geschlossen werden kann.</p>
<p>Wow.</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <a href="screenshot-dozer-temu-ad.png" target="_blank">
        <img src="screenshot-dozer-temu-ad.png" alt="Der erste Einspieler dauert in der Regel 60 Sekunden." width="250"/>
      </a>
      <br />
      <small>Der erste Einspieler dauert in der Regel 60 Sekunden.</small>
    </td>
    <td align="center">
      <a href="screenshot-dozer-lastwar-ad.png" target="_blank">
        <img src="screenshot-dozer-lastwar-ad.png" alt="Danach noch mal etwa genau so lange." width="250"/>
      </a>
      <br />
      <small>Danach noch mal etwa genau so lange.</small>
    </td>
  </tr>
</table>
</div>
<p>Da grundlegende Mechaniken des Spiels von diesen Einblendungen betroffen sind, kommen auf 2 Minuten Spielen locker auch 2 Minuten Werbedruck. Wer das nicht will, kann das Kontingent an Upgrade-Tickets erneut aufstocken. 10 Tickets kosten z.B. 6,99 Euro. Das entspricht bei normalem Spielverlauf etwa 10 Minuten Spielzeit. Da teuerste Paket kostet 9,99 Euro und enthält 60 Tickets.</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <a href="screenshot-dozer-pricelist.png" target="_blank">
        <img src="screenshot-dozer-pricelist.png" alt="In-App Käufe in 'Dozer Demolish'" width="220"/>
      </a>
      <br />
      <small>In-App Käufe in "Dozer Demolish" (Quelle: <a href="https://apps.apple.com/de/app/dozer-demolish-stadtabriss/id6447895913">iOS App Store</a>)</small>
    </td>
    <td align="center">
      <a href="screenshot-dozer-store-1.png" target="_blank">
        <img src="screenshot-dozer-store-1.png" alt='"Best Value": 60 Tickets für 9,99 Euro' width="220"/>
      </a>
      <br />
      <small>Das beste Preis-Leistungs-Verhältnis: 60 Tickets für 9,99 Euro - 2 Minuten deiner Lebenszeit kosten dich 0,16 Euro.</small>
    </td>
    <td align="center">
      <a href="screenshot-dozer-store-2.png" target="_blank">
        <img src="screenshot-dozer-store-2.png" alt="Sonderangebot! 6,99 Euro für 10 Tickets" width="220"/>
      </a>
      <br />
      <small>Sonderangebot! 6,99 Euro für 10 Tickets und ein paar Upgrades. Der Preis deiner Lebenszeit erhöht sich auf 0,69 Euro!</small>
    </td>
  </tr>
</table>
</div>
<h2 id="wo-problem">Wo Problem?</h2>
<p>&ldquo;Ja gut, kann ja jeder selber entscheiden!&rdquo; könnte man jetzt meinen. Wo ist das Problem? Wie gesagt, das ist ein brilliantes Geschäftsmodell. Das Problem ist in erster Linie die Altersfreigabe und der Umgang mit den Vorgaben zum Datenschutz. Und in zweiter Linie aus persönlicher Sicht die völlig übertriebene Kopplung der Spiel-Mechanik an die Werbung-Ausspielung.</p>
<p><strong>Will man Spiele programmieren oder Werbung ausliefern?</strong></p>
<p align="center">
  <a href="meme-wo-problem.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="meme-wo-problem.png" alt="alt text" width="500"/>
  </a>
</p>
<br />
<br />
<h3 id="problem-1-geschäftsfähigkeit-von-minderjährigen">Problem 1: Geschäftsfähigkeit von Minderjährigen</h3>
<p>Bei einer <strong>Altersfreigabe</strong> von 0 (respektive 4 Jahren auf iOS), ist dieses Spiel auch einen Personenkreis zugänglich, der zumindest nach deutschem Recht nicht geschäftsfähig ist. Erst mit 7 Jahre ist man beschränkt geschäftsfähig und kann <strong>kleinere Einkäufe</strong> (&ldquo;Taschengeldparagraph&rdquo;) ohne Einwilligung der Eltern tätigen. Wie passt das mit den mitunter sehr teuren In-App Käufen zusammen?</p>
<p>Google beschreibt die Altersfreigabe im PlayStore so:</p>
<p align="center">
  <a href="usk-0-description-long.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="usk-0-description-long.png" alt="alt text" width="500"/>
  </a>
</p> 
<center><small>USK 0 - Begründung, Quelle: https://play.google.com/store/apps/details?id=com.farmadventure.global</small></center>
<br />
<br />
<p>bzw. etwas weniger ausführlich:</p>
<p align="center">
  <a href="usk-0-description-brief.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="usk-0-description-brief.png" alt="alt text" width="500"/>
  </a>
</p>
<center><small>USK 0 - Kurze Begründung, Quelle: https://play.google.com/store/apps/details?id=com.farmadventure.global</small></center>
<br />
<br />
<h3 id="problem-2-dark-pattern">Problem 2: Dark Pattern</h3>
<p>Das Spiel nutzt <strong>Dark-Pattern</strong>, um die Werbung zu platzieren, wie z.B. beim Übergang zu einem neuen Tag. Ein großer grüner Button startet einen Werbeblock und belohnt mit In-Game-Währung. Der kleine Text darunter überspringt das. Viele Upgrades werden als &ldquo;Free&rdquo; beworben, dahinter steckt in der Regel eine Werbeeinblendung. Schlägt da nur mein moralischer Kompass Alarm, wenn diese Praxis bei Minderjährigen angewendet wird?</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <a href="screenshot-dozer-earned.png" target="_blank">
        <img src="screenshot-dozer-earned.png" alt="Collect Double" width="250"/>
      </a>
      <br />
      <small>Bitte den großen, grünen Button drücken, es soll zu Ihrem Nachteil nicht sein!</small>
    </td>
    <td align="center">
      <a href="screenshot-dozer-upgrade.png" target="_blank">
        <img src="screenshot-dozer-upgrade.png" alt="alt text" width="250"/>
      </a>
      <br />
      <small>Hinter diesem Button verbirgt sich eine Werbe-Einblendung. Hätten Sie es erkannt?</small>
    </td>
  </tr>
</table>
</div>
<h3 id="problem-3-zugänglichmachung-von-spielen-mit-höherer-altersfreigabe">Problem 3: Zugänglichmachung von Spielen mit höherer Altersfreigabe</h3>
<p>Die Werbung ist aber nicht nur aufdringlich, sie ist oft alles andere als altersgerecht! Und das ist vor allem dort schwierig, wo eine minderjährige Person die Möglichkeit hat (um nicht zu sagen &ldquo;gezwungen wird&rdquo;), ein Spiel für 15 Sekunden zu testen und das beworbene Spiel eine andere Altersfreigabe hat! Stell dir vor du gehst mit deinem Kind ins Kino um Cars 7 zu schauen und vor dem Film gibt es einen Trailer zu Texas Chainsave Massacre.</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <img src="screenshot-dozer-kingshot-ad.png" alt="Testspiel" width="220"/>
      <br />
      <small>Hey Kind, noch unsicher? Teste unser Spiel doch noch mal. Jetzt. Oder widerstehe der Versuchung für 15 Sekunden.</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-kingshot-store.png" alt="Ab 12 Jahren" width="220"/>
      <br />
      <small>Das Spiel ist ab 12 Jahren. Aber das musst du deinen Eltern ja nicht erzählen.</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-tophereos-ad.png" alt="Werbepausen-Test" width="220"/>
      <br />
      <small>Auch dieses Spiel darf man im Rahmen der Werbepause einmal testen.</small>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="screenshot-dozer-tophereos-store.png" alt="Freigabe 12 Jahre" width="220"/>
      <br />
      <small>Freigabe auch hier: 12 Jahre.</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-lastwar-ad-1.png" alt="Schießen" width="220"/>
      <br />
      <small>Macht jedes 4-jährige Kind gerne. Schießen.</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-lastwar-ad-2.png" alt="Selber schießen" width="220"/>
      <br />
      <small>Und damit es nicht beim Gucken bleibt: Selber schießen macht Bock auf mehr!</small>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="screenshot-dozer-lastwar-store.png" alt="Freigabe 12 Jahre" width="220"/>
      <br />
      <small>Freigabe auch hier: 12 Jahre.</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-monopoly-ad.png" alt="Monopoly-Klon" width="220"/>
      <br />
      <small>Ein Monopoly-Klon wird auch beworben. Freigabe hier: 16 Jahre (wtf?)</small>
    </td>
    <td align="center">
      <img src="screenshot-dozer-zombie-ad.png" alt="Zombie-Spiel" width="220"/>
      <br />
      <small>Darf als Werbeunterhaltung auch nicht fehlen: Ein Zombie-Spiel, ab 16. Träum was Schönes heute Nacht, kleiner Prinz.</small>
    </td>
  </tr>
</table>
</div>
<p>Moment mal: Warum hat Monopoly eine Einstufung von 16 erhalten? Sicher nicht wegen expliziter Gewaltdarstellung, sondern den <strong>erhöhten Kaufanreizen</strong>:</p>
<p align="center">
  <a href="monopoly-rating.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="monopoly-rating.png" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Monopoly und In-Game-Käufe: Freigabe ab 16 Jahren</small></center>
<br />
<br />
<h2 id="trauriger-einzelfall">Trauriger Einzelfall?</h2>
<p>Auf Dozer Demolish bin ich durch Zufall gestoßen. Homa bietet zur Zeit 50 Spiele im Google PlayStore an. Ich habe mir vier andere Spiele angeschaut.</p>
<p><a href="https://play.google.com/store/apps/details?id=com.homagames.studio.allinhole&amp;hl=gsw">All in Hole!</a>. Hier ist die Werbeausspielung weitaus weniger aggressiv. Nach 15 Minuten Spielzeit gab es keine Werbeanzeigen, auch nicht als Overlay am unteren Bildschirmrand. Dafür haben es die In-Game-Käufe in sich. 99 Euro kostet das größte Paket. Auf Konsolen &amp; PC bekommt man dafür hochwertige Triple-A-Titel. Interessant: Die <strong>Altersfreigabe ist 12 Jahre</strong>. Das ergibt nicht wirklich Sinn, da ich hier keine Werbung gesehen habe und das Spielprinzip alles andere als irgendwie &ldquo;nicht jugendfrei&rdquo; ist.</p>
<p align="center">
  <a href="screenshot-allinhole-prices.jpg" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-allinhole-prices.jpg" alt="alt text" width="250"/>
  </a>
</p>
<center><small>99,99 Euro - das ist kaum noch mit Entwicklungskosten zu rechtfertigen.
</small></center>
<br />
<br />
<p><a href="https://play.google.com/store/apps/details?id=com.happykamp.aquariumland">Aquarium Land</a> (ab 0 Jahre, 50 Mio. Downloads). Hier gibts die erste Werbeeinblendung nach 5 Minuten. Auch hier wird ein Spiel aus einer anderen Alterskategorie beworben.</p>
<p><a href="https://play.google.com/store/apps/details?id=com.cosmo.cube.blast.adventure.free&amp;hl=de">Cube Blast Journey</a> (0 Jahre, 1 Mio.): Dieses Spiel kommt ohne Consent Dialog aus. Das ist ungewöhnlich. Und tatsächlich: das Monitoring zeichnet eifrig Requests auf, von denen einige deutlich zu den Tracking und Analytics-Requests zählen dürften. Zum Beispiel die zu gameanalytics.com, amazon-adsystem.com, applovin.com, adjust.com oder doubleclick.net.</p>
<p align="center">
  <a href="screenshot-cube-requests.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-cube-requests.png" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Tracking- und Analytics-Requests bei Cube Blaster Journey</small></center>
<br />
<br />
<p><a href="https://play.google.com/store/apps/details?id=com.homa.free.solitaire.card.game&amp;hl=de">Solitaire Klondike Classic</a> (0 Jahre, &gt;5 Mio.). Das Spiel wird zwar von Homa vertrieben, nach kurzer Zeit wird man hier in gebrochenem Deutsch auf &ldquo;<a href="https://play.google.com/store/apps/details?id=solitaire.klondike.classic.card.games">die neue Version</a> (0 Jahre, &gt;1 Mio.)&rdquo; verwiesen, vertrieben durch <strong><a href="https://www.freelaxgame.com/about.html">Freelax</a></strong>. Auch aufgrund des Banners am oberen Bildschirmrand ist aber nicht so recht klar, ob das ein legitimer Verweis oder schlicht Werbung ist.</p>
<p align="center">
  <a href="screenshot-solitaire-solitaire-ad.jpg" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-solitaire-solitaire-ad.jpg" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Seltsame Art, um um ein "Update" zu bieten</small></center>
<br />
<br />
<p>Bei Solitaire Classic gibt es gleich nach dem bekannten TCF-Consent-Dialog noch eine weitere Abfrage der Einwilligung - diesmal vorausgewählt. Seit DSGVO nicht mehr zulässig, da das kein &ldquo;explizites Einverständnis&rdquo; darstellt.</p>
<p align="center">
  <a href="screenshot-solitaire-consent.jpg" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-solitaire-consent.jpg" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Einwilligung vorausgewählt - das ist nicht DSGVO-konform.</small></center>
<br />
<br />
<p>Der angebliche Nachfolger ist noch etwas dreister, was die Einwilligung angeht. Hier wird der Start des Spiels an die Einwilligung gekoppelt - auch das rechtlich fragwürdig.</p>
<p align="center">
  <a href="screenshot-solitaire-start.jpg" target="_blank" style="margin: 0 auto; display: block;">
    <img src="screenshot-solitaire-start.jpg" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Noch weniger DSGVO-konform: Start des Spiels an die Einwilligung gekoppelt.</small></center>
<br />
<br />
<p><a href="https://play.google.com/store/apps/details?id=com.germanicus.cmioo&amp;hl=de">Cat &amp; Mouse</a> (6 Jahre, 10 Mio.). Auch hier wird fleißig Werbung eingeblendet, die auf nicht altersgerechte Apps und Spiele verweist.</p>
<h2 id="und-die-anderen-publisher">Und die anderen Publisher?</h2>
<p>Bemerkenswert: Die oben genannten beworbenen Spiele sind weniger aggressiv, was die Ausspielung von Werbung angeht - einige kommen ganz ohne Werbung aus. Das heißt jedoch nicht, dass der dahinterstehende Publisher nicht auch Titel im Portfolio hat, die nach dem gleichen Prinzip funktionieren.</p>
<p>Schauen wir uns <a href="https://play.google.com/store/apps/dev?id=6832375891198423999">Century Games PTE. LTD.</a> an, den Publisher hinter <strong>Kingshot</strong>. Hier gibt es 23 Spiele im Angebot, davon laut Google PlayStore 12 mit In-Game-Werbung, 5 davon ohne Altersbeschränkung. Ich habe mir drei davon angesehen:</p>
<p><a href="https://play.google.com/store/apps/details?id=com.fatmerge.global">Tasty Travels: Merge Game</a> kommt ohne gültigen Consent-Dialog aus, laut Datenschutzerklärung werden jedoch Daten zu verschiedenen Zwecken, u.a. Marketing, erhoben. Nach einiger Spielzeit wurde mir schließlich eine spielbare Demo von <a href="https://play.google.com/store/apps/details?id=com.gof.global">Whiteout Survival</a> (<a href="https://www.centurygames.com/">Century Game PTE LTD</a>, Altersfreigabe 12+) angezeigt.</p>
<div align="center">
<table>
  <tr>
    <td align="center">
      <a href="free-energy.png" target="_blank">
        <img src="free-energy.png" alt="alt text" width="250"/>
      </a>
      <br />
      <small>Spielbare Werbung für Family Farm Adventure</small>
    </td>
    <td align="center">
      <a href="whiteout.survival.png" target="_blank">
        <img src="whiteout.survival.png" alt="alt text" width="250"/>
      </a>
      <br />
      <small>Spielbare Werbung für Idle Courier</small>
    </td>
  </tr>
</table>
</div>
<p><a href="https://play.google.com/store/apps/details?id=com.farmadventure.global">Family Farm Adventure</a> hat einen fragwürdigen Consent-Dialog, ähnlich wie bei Dozer Demolish. Werbung ist mir zwar nicht aufgefallen, dafür sind die Preise noch extremer als zuvor gesehen: 120 Euro für ein In-Game-Paket – ohne zu wissen, wie lange dieses hält. Eher nicht die Preisklasse, mit der man Kinder konfrontieren sollte.</p>
<p align="center">
  <a href="family-farm-adventure.png" target="_blank" style="margin: 0 auto; display: block;">
    <img src="family-farm-adventure.png" alt="alt text" width="250"/>
  </a>
</p>
<center><small>Preistabelle für Family Farm Adventure</small></center>
<br />
<br />
<p><a href="https://play.google.com/store/apps/details?id=com.centurygames.idlecourier">Idle Courier</a> kommt ebenfalls mit einem wenig transparenten Consent-Dialog und dem Prinzip der „gekoppelten Einwilligung“ (wer weiterspielt, akzeptiert die Datenschutzbestimmungen). Hier wurde mir bereits nach 2 Minuten die erste spielbare Werbung für Kingshot (Altersfreigabe 12+) angezeigt.</p>
<p><a href="https://play.google.com/store/apps/developer?id=RiverGame">River Game</a> und <a href="https://play.google.com/store/apps/developer?id=FUNFLY&#43;PTE.&#43;LTD.">Funfly PTE</a> bieten keine Spiele mit einer Altersfreigabe von 0 Jahren an. <a href="https://play.google.com/store/apps/developer?id=FunPlus&#43;International&#43;AG">FunPlus International AG</a> hat 15 Spiele im Angebot, alle mit Altersfreigaben zwischen 12 und 16 Jahren. <a href="https://play.google.com/store/apps/dev?id=9028773071151690823">Scopely</a> hat nur ein Spiel mit Altersfreigabe 0, aber ohne Werbung.</p>
<h2 id="fazit">Fazit?</h2>
<p>Die genannten Spiele verfolgen ihr Werbeziel zwar bei weitem nicht so aggressiv wie &ldquo;Dozer Demolish&rdquo;, aber die Ausspielung scheint auch hier systematisch dem gleichen Muster zu folgen. In Spielen, die eine bestimmte Altersbeschränkung haben, wird Werbung für Spiele mit einem höheren Alter ausgespielt. Und nicht nur das, sie können sogar direkt ausprobiert werden.</p>
<p>Nun kann man sich darüber streiten, ob 4-jährige Kinder überhaupt schon Zugang zu Tablets und Smartphones haben sollten, um dann damit auch noch derartige Spiele zu spielen. Aber das ist eine pädagogische Frage. Letztlich werden die Spiele mit einer gewissen Altersbeschränkung vertrieben, ebnen aber trotzdem den Weg zu Inhalten, die nicht altersgerecht sind. Und das ist dann nicht mehr nur eine pädagogische Problematik. Ganz zu schweigen von den Consent-Dialogen und der Preisgestaltung.</p>
<p>Bemerkenswert ist, dass derart erfolgreiche Spiele unter dem Radar fliegen. Aus eigener Erfahrung weiß ich, dass Google zumindest formell sehr strenge Vorgaben hat. Die Einhaltung der Plattformrichtlinien wird (automatisiert?) überwacht und mit Fristen und drohender De-Publizierung durchgesetzt. So mein Eindruck. Ist Google in manchen Fällen etwas nachlässiger, weil auch der eigene Umsatz von den Werbeeinnahmen abhängt?</p>
<p>Nicht falsch verstehen: Die meisten Spiele sind qualitativ durchaus hochwertig, manche bieten sogar eine ordentliche Story. Es ist nur fair, dass Entwickler oder Publisher versuchen, ihre Kosten durch Monetarisierung zu decken. Auf Homa bin ich nur durch Zufall gestoßen und möchte den Publisher keineswegs als schwarzes Schaf darstellen. Aber da es hier um die jüngste Zielgruppe geht, um lasche Datenschutzpraktiken, unkontrollierte Werbung und teure In-App-Käufe, sollte vielleicht mal etwas genauer hinschauen - nicht nur bei Homa.</p>
<p>Und außedem frage ich mich, ob es überhaupt noch darum geht, gute Unterhaltung zu bieten, oder eher darum, mit möglichst geringem Aufwand den Markt zu überschwemmen, um Nutzer mit einfachen Spielideen so lange wie möglich am Gerät zu halten und so möglichst viel Werbung auszuspielen?</p>
<p>Ich bin kein Fan von Handyspielen. Und jetzt weißt du warum.</p>
<h2 id="stellungnahme-von-homa-und-google">Stellungnahme von Homa und Google</h2>
<p>Ich habe <strong>Homa</strong> und <strong>Google</strong> am 30.07. um eine Stellungnahme gebeten. Homa hat innerhalb von zwei Tagen geantwortet und angekündigt, sich intern der Thematik anzunehmen. Vorbildlich, ich bin gespannt. Google hat sich bisher nicht geäußert.</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>blog</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Der Schmale Grat zwischen Scam und eifrigem Unternehmertum - Project</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Die Nerd Enzyklopädie 46 - Bastard Operator From Hell</title>
      <link>http://localhost:1313/2025/2025-03-10-nerd-enzyklop%C3%A4die-46---bastard-operator-from-hell/</link>
      <pubDate>Mon, 10 Mar 2025 12:19:31 +0100</pubDate>
      <author></author>
      <guid>http://localhost:1313/2025/2025-03-10-nerd-enzyklop%C3%A4die-46---bastard-operator-from-hell/</guid>
      <description>Wer sich mit Nerd-Kultur beschäftigt, kommt am Bastard Operator From Hell, kurz BOfH (zu deutsch sinngemäß in etwa „Mistkerl-Admin aus der Hölle&quot;), nicht …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Wer sich mit Nerd-Kultur beschäftigt, kommt am **Bastard Operator From Hell**, kurz **BOfH** (zu deutsch sinngemäß in etwa „Mistkerl-Admin aus der Hölle&#39;), nicht herum.&#39; reading_time: 4 content_type: &#34;project</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Database, Ai, Design</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> expert</p>
          
        </div>
        
        
        <p>Wer sich mit Nerd-Kultur beschäftigt, kommt am <strong>Bastard Operator From Hell</strong>, kurz <strong>BOfH</strong> (zu deutsch sinngemäß in etwa „Mistkerl-Admin aus der Hölle&quot;), nicht herum.</p>
<p>Der BOFH ist eine fiktive Figur aus den satirischen Erzählungen von <strong>Simon Paul Travaglia</strong>, die erst in einer Universität, später in einem Büro als Operator - also einer Art Service-Mitarbeiter oder laut Wikipedia „Systembetreuer“ - tätig ist.</p>
<p>Travaglia arbeitete Ende der 1980er Jahre an der Universität von Waikato (Neuseeland) selbst als Operator. Seine Aufgabe war der technische Support und er beschreibt seinen, wie er es selbst nennt, nervigen und langweiligen Arbeitsalltag so:</p>
<blockquote>
<p>All the power and none of the responsibility. Good Times. You could do ANYTHING to a user and no-one would know. Well, they&rsquo;d know, but they couldn&rsquo;t prove a thing. ~ Travaglia (BOFH1)</p></blockquote>
<p>Bei einem Umzug in ein anderes Gebäude fiel ihm ein alter ungenutzter Tandy TRS-80 Model 100, Spitzname Trash 80, in die Hände. Der Trash 80 war der Vorläufer des modernen Notebooks. Das RS steht für Radio Shack, einem bekannten Elektronikhändler in den USA. Travaglia verfasste damit in seiner Freizeit, wie er es selber nannte, zusammenhangslose, „seltsame&quot; Geschichten („oddball stories&quot;).
In regelmäßigen Abständen nahm er das „Notebook“ mit ins Büro, um dort einige seiner „Rants“ im Usenet unter dem Titel „Striped Irregular Bucket“ zu veröffentlichen. In einem dieser Rants beschreibt er den wenig zimperlichen Umgang mit einem Hilfesuchenden Angestellten wie folgt (MYTH1) :</p>
<quote> 
[…]
So I fill in a couple of hours by killing users off and deleting their files, then waiting for them to call...
<p>&ldquo;Um, I can&rsquo;t find my files&rdquo; the wimpering simp on the phone says</p>
<p>&ldquo;Files? What files?&rdquo;</p>
<p>&ldquo;The files in my account. My thesis, my research - all gone!&rdquo;</p>
<p>&ldquo;Gone ay? What&rsquo;s your username?&rdquo;</p>
<p>&ldquo;TURGEN&rdquo;</p>
<p>&ldquo;TROJAN?! LIKE THE CONDOM?&rdquo;</p>
<p>&ldquo;No TURGEN. T-U-R&rdquo;</p>
<p>&ldquo;OH Turgen, like TURD, but with a GEN instead of a D&hellip; Ok lets see&rdquo; I make vague clicking noises my dragging the quicklimed man&rsquo;s fingers back and forth across the keypad. &ldquo;Uh-huh&rdquo; &gt;drag drag&lt; &ldquo;Yeah..&rdquo; &gt;dragedy poke&lt; &ldquo;AH! - You haven&rsquo;t got any files&rdquo;</p>
<p>&ldquo;I KNOW!&rdquo;</p>
<p>&ldquo;Well, what are you calling ME for? We don&rsquo;t make the files you know, we just look after them. And chopitty-chop too, your thesis looks like it&rsquo;s due in a couple of days..&rdquo;</p>
<p>I hang up - he&rsquo;ll call back. Meantime I open up a copy of &ldquo;VMS BASTARD OPERATORS MANUAL FROM HELL&rdquo; I&rsquo;m reading the article I sent in about getting rid of those trouble users&hellip;</p>
<p>[…]
</quote></p>
<p>Diese und zahlreiche weitere Erzählungen des zynischen, gemeinen und bis dahin noch unbekannten Operators fanden recht schnell großen Anklang, dennoch pausierte er seine Arbeit daran zunächst, wohl auch weil ihm die Inspiration fehlte (BJASH1) .
Ende der 1992er Jahre arbeitete er in London für Enterprise Oil PLC, einem damals sehr erfolgreichen Ölförderunternehmen, aber das hat für die Geschichte keine Relevanz. Travaglia verfasste hier zwei weitere Episoden über den BOFH und erinnert sich vor allem an den abenteuerlichen Prozess der Veröffentlichung: Die Enterprise Oil besaß keinen Zugang zum Internet, also schlich er sich abends in das University College London, schrieb dort einige Geschichten, die er über einen langsamen Telnet-Zugang auf einer Virtuellen Maschine im Usenet veröffentlichen konnte.
Travaglia kehrte London den Rücken und begab sich wieder nach Neuseeland, um dort als Analyst Programmer zu arbeiten. Er veröffentlichte nun nur noch sporadisch neue Episoden bis er, ermuntert durch Maxwell Cooter, Journalist beim Network Week Magazin, in fast regelmäßigen Abständen neue BOFH-Geschichten für eben das Network Week Magazine, später auch The Register oder Datamation zu schreiben und sogar in Buch-Form zu veröffentlichen.
Auch wenn der teils schmerzbefreite Humor ein wenig aus der Zeit gefallen zu sein scheint, ist der BOFH nach wie vor ein fester Bestandteil der Nerd-Kultur.
Florian Schiel begann 1997 damit die BOfH Geschichten ins Deutsche zu übersetzen, und entwickelt später mit dem BAfH einen eigenen erfolgreichen deutschen Ableger. Der BAfH treibt sein Unwesen als Systemadministrator an der Universität München.</p>
<p>Wer die Welt einmal aus der Sicht eines unterforderten, aber auch ziemlich arroganten und gelangweilten Administrators erleben möchte, der sollte sich BOfH und BAfH auf die Liste der Bettlektüre setzen. Eine fast vollständige Sammlung aller Erlebnisse von Travaglias Original gibt es hier: (ARCH1)</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>nerdenz</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Die Nerd Enzyklopädie 46 - Bastard Operator From Hell - Project</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Die Nerd Enzyklopädie 43 - 0x5f3759df</title>
      <link>http://localhost:1313/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/</link>
      <pubDate>Mon, 01 Jan 2024 12:19:31 +0100</pubDate>
      <author></author>
      <guid>http://localhost:1313/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/</guid>
      <description>In der Informationstechnologie gibt es zwei wichtige Innovationstreiber: Die Porno-Industrie und die Spiele-Industrie. Quake III ist ein wegweisender Vertreter …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>In der Informationstechnologie gibt es zwei wichtige Innovationstreiber: Die Porno-Industrie und die Spiele-Industrie. Quake III ist ein wegweisender Vertreter der Spiele-Industrie.&#39; reading_time: 6 content_type: &#39;project</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Mac, Mobile, Ai, Security, Design</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> intermediate</p>
          
        </div>
        
        
        <p>In der Informationstechnologie gibt es zwei wichtige Innovationstreiber: Die <strong>Porno-Industrie</strong> und die <strong>Spiele-Industrie</strong>. <strong>Quake III</strong> ist ein wegweisender Vertreter der Spiele-Industrie. Der Pionier unter den Ego-Shootern wurde <strong>1999</strong> veröffentlicht, eroberte die Herzen der spielenden Gemeinde im Sturm und glänzte mit für die damaligen Verhältnisse herausragenden optischen Effekten. Und das trotz vergleichsweise geringer Anforderungen an die Hardware.</p>
<p><img src="/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/image_1.png" alt=""></p>
<p>Nerd-Enzyklopädie #43</p>
<p>Um das zu ermöglichen nutzte <strong>Quake</strong> die „<strong>fast inverse square root</strong>“ (zu Deutsch klingt es etwas sperriger: „Schnelle umgekehrte Quadratwurzel”).</p>
<p>Aber… warum? Um in einer dreidimensionalen Welt bestimmte physikalische Effekt zu simulieren, nutzt man <strong>Vektoren</strong>. Nehmen wir z.B. die Berechnung von <strong>Lichtreflektionen</strong>: Um den Einfalls- und Ausfallswinkel auf einer beliebigen Fläche korrekt zu berechnen, benötigt man einen Vektor, genau genommen einen <strong>normierten Vektor</strong>.</p>
<p>Die Formel für die Berechnung des Betrages eines Vektor (sprich seiner „Länge“) sieht folgendermaßen aus:</p>
<p><img src="/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/image_2.png" alt=""></p>
<p>Wer in der Schule gut aufgepasst hat, sollte davon nicht sonderlich beeindruckt sein. Es handelt sich im Prinzip um den <strong>Satz des Pythagoras</strong> <strong>auf Steroiden</strong>.</p>
<p>Ein <strong>normierter Vektor</strong> hat einen Betrag von 1, die Richtung bleibt unverändert:</p>
<p><img src="/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/image_3.png" alt=""></p>
<p>Um einen Vektor zu normieren, multipliziert man ihm mit dem Kehrwert seines Betrages:</p>
<p><img src="/2024/2024-01-01-nerd-enzyklop%C3%A4die-43---0x5f3759df/image_4.png" alt=""></p>
<p>Diese Formel muss <strong>millionenfach</strong> ausgeführt werden, wenn man eine Lichtbrechung mit einer halbwegs ansehnlichen Qualität in einem Spiel erzeugen möchte.</p>
<p>Für die Summen und Potenzen (das sind ja letztlich auch nur Summen) ist das kein Problem, wohl aber für die Wurzel bzw. den Kehrwert der Wurzel — die <strong>inverse square root</strong>.</p>
<p>Anfangs behalf man sich mit riesigen Tabellen, die die Ergebnisse zahlreicher Berechnungen enthielten. Das sprengt irgendwann den Rahmen und man musste eine andere Lösung finden. Und diese ist und war <strong>elegant und rebellisch</strong> zugleich — der „<strong>fast inverse square root</strong>“ Algorithmus:</p>
<pre><code>float Q_rsqrt( float number )  
{  
    long i;  
    float x2, y;  
    const float threehalfs = 1.5F;  
    x2 = number * 0.5F;  
    y = number;  
    i = * ( long * ) &amp;y; // evil floating point bit level hacking  
    i = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck?   
    y = * ( float * ) &amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration  
    // y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed  
    return y;  
}
</code></pre>
<p>In dieser Funktion passieren einige spannende, um nicht zu sagen verrückte Dinge. Wie zum Beispiel der „<strong>evil floating point bit hack</strong>“.</p>
<p>Dazu ein kurzer Ausflug in das mysteriöse Reich der <strong>Fließkommazahlen</strong>: Diese zeichnen sich durch eine spezielle Art der Speicherung aus, damit in unseren binär geprägten Computern (Nullen und Einsen) auch <strong>Dezimalzahlen</strong> verarbeiten werden können. Dazu wird die Dezimalzahl als Kombination von <strong>Vorzeichen</strong>, <strong>Exponent</strong> und <strong>Mantisse</strong> abgespeichert: Das <strong>IEEE-754</strong> Format!</p>
<p>Der Nachteil: Beim Zurückrechnen kann es zu Ungenauigkeiten kommen. So wird der Wert 3,3 nach IEEE-754 binär abgespeichert:</p>
<p><code>01000001001000011001100110011010</code></p>
<p>Berechnet man diesen Wert zurück in ein Dezimalzahl, erhält man:</p>
<p><code>3.2999999523162841796875</code></p>
<p>Nicht schön, aber selten und meistens auch ausreichend genau.</p>
<p>Der „<strong>evil floating point bit hack</strong>“ schnappt sich den binären Wert der Fließkommazahl und interpretiert ihn schlicht als Ganzzahl, ohne die aufwendige Berechnung nach <strong>IEEE-754</strong>. Aus 3,3 wird damit der „evil integer“ <strong>1.079.194.419</strong>.</p>
<p>Als nächstes kommt es zu einer unter Fachleuten auch als <strong>What-The-Fuck-Transformation</strong> bezeichneten <strong>What-The-Fuck-Transformation</strong>. Unser „evil integer“ wird zunächst per <strong>Bitshift</strong> halbiert (ein bitweises verschieben nach links oder rechts kommt einer Multiplikation oder Division mit 2 gleich — probier es mal aus!). Das Ergebnis wird von einer <strong>höchstseltsamen Konstante</strong> abgezogen. Da ist sie — sie ist wunderschön:</p>
<p><code>0x5f3759df</code></p>
<p>Der dezimale Wert dieser mathematischen Grazie ist <strong>1.597.463.007</strong> — nicht sonderlich spannend. Behandelt man den Wert aber ebenfalls als Fließkommazahl nach <strong>IEEE-754</strong>, erhält man diese Kombination aus Exponent und Mantisse:</p>
<p><code>0.10111110.01101110101100111011111</code></p>
<p>Daraus ergibt sich ein <strong>Exponent</strong> von <strong>63</strong> und die <strong>Mantisse</strong> mit <strong>1,43243014812469482421875</strong>. Zusammen errechnet sich daraus die ziemlich große Zahl: <strong>13.211.836.172.961.054.720</strong> Und das ist eine ziemlich gute Annäherung an die Wurzel von <code>2¹²⁷</code>, nämlich <code>13.043.817.825.332.782.212,349…</code></p>
<p>Das Ergebnis dieser wahnwitzigen Operation wird nun über einen umgedrehten „<strong>evil floating point hack</strong>“ zurück in eine Fließkommazahl „umgewandelt“.</p>
<p>Abschließend findet noch ein weiterer kleiner Trick aus der wunderbaren Welt der Mathematik Anwendung: Mittels des <strong>Newton-Verfahrens</strong> erfolgt eine Korrektur des bisherigen Ergebnisses.</p>
<p>Schließlich kann die Funktion den <strong>Kehrwert einer Wurzel</strong> in etwa genauso gut bestimmen, wie eine konventionelle Berechnung, aber weitaus schneller.</p>
<p>Diese geniale Optimierung der Berechnung wird übrigens oft alleine <strong>John Carmack</strong> zugeschrieben, einem der Schöpfer von <strong>Quake III</strong>. Tatsächlich führen die Wurzeln (<strong>no pun intended…</strong>) aber viel weiter zurück. So basiert die Funktion wohl auf den Arbeiten vieler schlauer Köpfe.</p>
<p>Bereits <strong>1974</strong> tauchte eine ähnliche Routine im Quellcode für den <strong>PDP-11</strong> auf [<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5%2Fusr%2Fsource%2Fs3%2Fsqrt.s"><strong>TUHS1</strong></a>]. In einem Quellcode von <strong>1993</strong> findet sich ein Kommentar mit dem Verweis auf eine wissenschaftliche Arbeit von <strong>William Kahan</strong> und <strong>K.C. Ng</strong> aus <strong>1983</strong>, in dem sie genau diese optimierte Methode beschreiben. Kahan gilt übrigens als „Architekt“ der IEEE-Fließkommazahlen-Aritmetik. <strong>1997</strong> präsentierte <strong>Jim Blinn</strong> in den „Floating-point tricks“ eine vergleichbare Funktion, dort noch ohne die „magische Konstante“ [<a href="https://ieeexplore.ieee.org/document/595279">IEEE2</a>].</p>
<p>Aber zurück zu John Carnack, der die Urheberschaft ganz explizit von sich wies:</p>
<blockquote>
<p>Not me, and I don’t think it is Michael [Abrash]. Terje Matheson perhaps?</p>
<p>~John Carmack, per E-Mail in 2004</p></blockquote>
<p>Der nächste „Verdächtige“ wäre <strong>Gary Tarolli</strong>, <strong>NVidia</strong>-Mitarbeiter der ersten Stunde und Mitbegründer von <strong>3Dfx</strong>. Dieser räumte ein, Mitte der 1990er Jahre die besagte Funktion genutzt und vielleicht sogar optimiert zu haben, weißt aber die eigentliche Urheberschaft ebenfalls von sich [<a href="https://www.beyond3d.com/content/articles/8/">BEYON1</a>].</p>
<p>Die Spur führt schließlich zu <strong>Greg Walsh</strong>, Ende der 1980er Jahre Entwickler bei der <strong>Ardent Computer Corporation</strong>. Inspiriert von der Arbeit seines Kollegen, dem Informatiker und Mathematiker <strong>Cleve Moler</strong>, Autor von <strong>MatLab</strong>, war es wohl Walsh, der die berüchtigte Funktion entwickelte.</p>
<p>Übrigens: Auch zwischen Moler und Kahan gibt es eine Verbindung. Zwar ist nicht klar wie eng die Bekanntschaft war, aber sie sind sich zumindest einmal über den Weg gelaufen [<a href="https://blogs.mathworks.com/cleve/2014/07/07/floating-point-numbers/">MATH1</a>].</p>
<p>Zurück zu Ardent: Das Unternehmen wurde damals unter anderem von <strong>Kubota</strong> “finanziell unterstützt”, einem japanischen Mischkonzern. Für Kubota arbeitete seinerzeit auch <strong>Gary Tarolli</strong>! So gelang der Quellcode wohl in die Hände von Tarolli. Die Verbindung zu John Carmack und <strong>id Software</strong> entstand dann vermutlich über <strong>Brian Hook</strong>, einem der ersten Angestellten von 3Dfx und später auch Entwickler bei id Software [<a href="https://www.quakewiki.net/profile-retro-interview-brian-hook/">QUAKE1</a>]. Und so schließt sich der Kreis…</p>
<p>Der <strong>Fast Inverse Square Root Algorithmus</strong> hat nichts an Faszination eingebüßt, vielleicht aber etwas an Bedeutung. Moderne Computer ermöglichen mittlerweile — dank hoher Leistung und angepasster Befehlssätze — eine sehr schnelle Berechnung von Wurzeln und deren Kehrwerten.</p>
<p>Hinter der mysteriösen Konstante und der merkwürdigen Optimierung steckt also eine verworrene Geschichte und am Ende fast schon der tragische Untergang in die Bedeutungslosigkeit. Wenn das kein Material für einen <strong>Nerd-Blockbuster</strong> ist…</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>nerdenz</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Die Nerd Enzyklopädie 43 - 0x5f3759df - Project</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Die Nerd Enzyklopädie 23 - 30 x 10 = 1.000</title>
      <link>http://localhost:1313/2023/2023-05-01-nerd-enzyklop%C3%A4die-23---30-x-10--1.000/</link>
      <pubDate>Mon, 01 May 2023 12:19:31 +0100</pubDate>
      <author></author>
      <guid>http://localhost:1313/2023/2023-05-01-nerd-enzyklop%C3%A4die-23---30-x-10--1.000/</guid>
      <description>
Wenn du deinen Python-Nachlass mit ein wenig Pfeffer würzen willst, empfiehlt es sich, die „Definition eines Integers“ zu ändern. Wenn du in Python eine Zahl …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Wenn du deinen Python-Nachlass mit ein wenig Pfeffer würzen willst, empfiehlt es sich, die „Definition eines Integers“ zu ändern.&#39; reading_time: 1 content_type: &#39;guide</p>
          
          
          <p><strong>Hauptthemen:</strong> Python</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> intermediate</p>
          
        </div>
        
        
        <p><img src="/2023/2023-05-01-nerd-enzyklop%C3%A4die-23---30-x-10--1.000/image1.png" alt=""></p>
<p>Wenn du deinen Python-Nachlass mit ein wenig Pfeffer würzen willst, empfiehlt es sich, die „Definition eines Integers“ zu ändern. Wenn du in Python eine Zahl verwendest, nehmen wir die 30, verwendet Python die 30 als Referenz auf ein Objekt im Speicher, in dem wiederum der Wert 30 hinterlegt wird. Die 30 ist also ein Verweis auf ein Objekt, das den tatsächlichen Wert enthält. In der Regel sollten Verweis und Wert gleich sein, sonst wird das mit der Mathematik schwierig.</p>
<p>Schwierig? Das mögen Nerds doch!</p>
<p>Mit dieser Funktion kannst du einen derartigen Verweis anpassen und einen abweichenden Wert hinterlegen:</p>
<pre><code>import ctypes   
def reference(val):  
  return ctypes.cast(id(val), ctypes.POINTER(ctypes.c_int))
</code></pre>
<p>Und so aktivierst du den „Spaß“:</p>
<pre><code>reference(30)[6] = 100
</code></pre>
<p>Willst du nun mit der Ziffer 30 mathematische Operationen durchführen, erzeugt das interessante Ergebnisse:</p>
<pre><code>&gt;&gt;&gt; 30 * 10  
&gt;&gt;&gt; 1000
</code></pre>
<p>Viel Spaß beim Debuggen!</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>nerdenz</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Die Nerd Enzyklopädie 23 - 30 x 10 = 1.000 - Guide</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Random Knowledge</title>
      <link>http://localhost:1313/2022/2022-10-21-random-knowledge/</link>
      <pubDate>Fri, 21 Oct 2022 07:51:37 +0100</pubDate>
      <author></author>
      <guid>http://localhost:1313/2022/2022-10-21-random-knowledge/</guid>
      <description>&ldquo;Random Knowledge&rdquo; ist ein automatisierter Podcast, bei dem eine computer-generierte Stimme zufällige Artikel der Wikipedia vorliest.
Dazu wird in …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Ein automatisierter Podcast-Generator, der Wikipedia-Artikel mit Python abruft, durch Text-to-Speech von Google in Audio umwandelt und über anchor.fm auf alle gängigen Podcast-Plattformen verteilt.&#39; reading_time: 3 content_type: &#39;project</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Text-to-Speech, Automation, Podcast, Wikipedia, Google TTS, anchor.fm</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> intermediate</p>
          
        </div>
        
        
        <p>&ldquo;Random Knowledge&rdquo; ist ein automatisierter Podcast, bei dem eine computer-generierte Stimme zufällige Artikel der Wikipedia vorliest.</p>
<p>Dazu wird in Python ein zufälliger Artikel der englischen Wikipedia abgerufen und vorbereitet. Der gesamte Artikel wird in Abschnitte getrennt, Bereiche, die nicht vorlesbar sind, wie z.B. Tabellen, werden entfernt. Über die Text-to-Speech-API von Google wird der Text in Sprache umgewandelt und als Audio-Datei abgelegt. Die Dateien werden über eine undokumentierte Schnittstelle zu anchor.fm hochgeladen und von dort an die gängigen Portale verteilt (Spotify, Deezer, Google, Amazon, Apple, &hellip;)</p>
<p><a href="https://spotifyanchor-web.app.link/e/zjG3R1ANFxb">https://spotifyanchor-web.app.link/e/zjG3R1ANFxb</a></p>

        
        
      ]]></content:encoded>
      
      
      
      <category>projekte</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Random Knowledge Podcast - Automatisierte Wikipedia-Artikel als Audio</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Wie funktioniert der SHA256 Algorithmus…im Detail? (Teil&amp;nbsp;1/2)</title>
      <link>http://localhost:1313/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/</guid>
      <description>SHA-256 (Secure Hash Algorithm) ist der Name einer “kryptologischen Hashfunktion”. SHA-256 ist Teil einer ganzen Gruppe von Algorithmen, mit dem gleichen Ziel: …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>SHA-256 (Secure Hash Algorithm) ist der Name einer “kryptologischen Hashfunktion”.&#39; reading_time: 13 content_type: &#39;tutorial</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Mac, Git, Mobile, Ai, Security</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>SHA-256 (Secure Hash Algorithm) ist der Name einer “kryptologischen Hashfunktion”. <a href="https://de.wikipedia.org/wiki/SHA-2">SHA-256 ist Teil einer ganzen Gruppe von Algorithmen</a>, mit dem gleichen Ziel: Die Erzeugung eines Hashes, der resistent gegen Kollisionen ist, dessen Berechnung nur in eine Richtung funktioniert und eine feste Länge hat. Im folgenden Artikel beschreibe ich die einzelnen Schritte die der Algorithmus vornimmt, um einen Hash zu erzeugen.</p>
<p><em>Im ersten Teil kümmern wir uns um die Vorbereitungen, im <a href="https://nickyreinert.de/blog/2021/10/31/wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/">zweiten Teil</a> geht es an den eigentlichen Algorithmus. Der Sourcecode</em> <a href="https://gist.github.com/nickyreinert/00d631fe9a90108924b1df6e911c8cd5"><em>liegt auf Github</em></a><em>.</em></p>
<h3 id="was-wirst-dulernen">Was wirst du lernen?</h3>
<p>Neben dem Erzeugen eines SHA-256 wirst du hier vor allem den Umgang mit binären Zahlen und binäre Rechenoperationen wie <strong>XOR</strong>, <strong>AND</strong> usw kennenleren. Ich gehe allerdings davon aus, dass ein Grundverständnis für binäre Zahlen vorhanden ist, der Fokus liegt auf dem Algorithmus. <strong>10</strong> sollte in deinem Kopf also entweder für die <strong>zehn</strong> oder eine <strong>zwei</strong> stehen. (Oder auch <strong>zwölf</strong>, wenn du das <strong>Duodezimalsystem</strong> magst.)</p>
<h3 id="vorwort">Vorwort</h3>
<p>Bricht man das auf eine maximal laienhafte Beschreibung herunter, passiert bei einer krytpologischen Hash-Funktion das folgende: Ein Ausgangs-Text <strong>beliebiger</strong> Länge wird so verarbeitet, dass daraus einen Ergebnis-Text (<em>der</em> <em>Hash</em>) mit der <strong>immer gleichen</strong> Länge entsteht. Es ist nahezu unmöglich, aus dem Hash den Ausgangs-Text zu berechnen. Außerdem kann man fast sicher davon ausgehen, dass jeder Ausgangs-Text <strong>einen anderen Hash</strong> erzeugt. Ändere ich nur ein Zeichen, wirkt sich das drastisch auf den Ausgangs-Text aus. Ein derartiger Algorithmus ist daher zB prädestiniert, Texte, sprich Nachrichten, zu verfizieren. Man spricht deswegen auch von einer Prüfsumme.</p>
<p>Und das ist die Grundlage einer Technologie, die in jüngster Vergangenheit immer mehr von sich Reden macht: Die <strong>Blockchain</strong>, Basis für Kryptowährungen wie zB den <strong>Bitcoin</strong>. Bei der Blockchain sind, und auch das nur laienhaft heruntergebrochen, die Einträge des “Kassenbuches” sicher vor Manipulation, weil eben die Änderung eines historischen Wertes (zB Buchungsvorganges) unweigerlich eine drastische Änderung der daraus erzeugten Prüfsummen nach sich ziehen würde. Um den Blockchain-Apologeten gleich den Wind aus den Segeln zu nehmen zitiere ich mal Fefe, sinngemäß: <a href="https://ptrace.fefe.de/Blockchain/#46">Es geht auch einfacher</a>. Ich gebrauche Bitcoin hier auch nur als Buzzword, aus Marketing-Gründen. :]</p>
<p>Um dich nun aber auch zum Weiterlesen zu motivieren, ein wichtiger Hinweis:</p>
<p>Der Algorithmus wird dazu verwendet, die nächsten Einträge der Blockchain zu berechnen. Genau genommen wird hier ein bestimmter Hash vorgegeben, der errechnet werden soll (das berüchtigte <em>Mining</em>). Die Belohnung für die korrekte Berechnung sind Bitcoins. Das Problem: Diese Berechnung ist <strong>sehr,</strong> <strong>sehr aufwendig</strong>, denn wie schon oben geschrieben: Sie funktioniert nur in eine Richtung. Die <em>Miner</em> müssen also unsagbar viele Berechnungen durchführen, um einen Ziel-Wert zu errechnen. Und der Miner, der die Berechnung am schnellsten ausführt, wird dafür auch belohnt. Gelingt es dir also, wider erwarten, den Algorithmus zu optimieren, kannst du im Mining-Business ganz groß rauskommen. Das klingt doch nach einer Herausforderung, oder? ;)</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/images/image2.png" alt=""></p>
<p>Quelle: <a href="https://peakd.com/deutsch/@marcus0alameda/dagobert-gold-bitcoin-perfektion">https://peakd.com/deutsch/@marcus0alameda/dagobert-gold-bitcoin-perfektion</a></p>
<blockquote>
<p>Disclaimer: Ich habe den ganzen Algorithmus in Python nachgebaut. Python ist aus Performance-Sicht sicher nicht die beste Option, um SHA-256 zu berechnen und der Umgang mit binären oder hexadezimalen Werten ist etwas unbequem. Python eignet sich dank Jupyter aber am ehesten dazu, einen komplexen Algorithmus Schritt-für-Schritt zu beschreiben.</p></blockquote>
<h3 id="einführung">Einführung</h3>
<p>Bevor wir uns an die Schleifen machen, müssen wir uns um ein paar Funktionen kümmern, die wir später dazu nutzen, um <strong>binäre Zahlen</strong> ein wenig durchzumischen.</p>
<blockquote>
<p>Hinweis 1: Ich verzichte im folgenden auf die Präfixe der Zahlensystem, wie zB 0b für binär, um den Text übersichtlich zu halten. Ich gehe davon aus, dass folgendes bekannt ist: 0 =&gt; Falsch und 1 =&gt; Wahr</p></blockquote>
<blockquote>
<p>Hinweis 2: Im Kontext von SHA-256 entspricht ein Wort (bzw word) genau 32 Bit. In der Regel entspricht 1 Word = 2 Byte = 16 Bit.</p></blockquote>
<h4 id="das-explizite-oderxor">Das explizite Oder (XOR)</h4>
<p>Das explizite Oder (<strong>Entweder-Oder</strong>) ist ein elementarer logischer, bitweise Operator. Der Ausgang der Operation ist nur dann wahr, wenn exakt ein Zustand wahr ist (im Vergleich dazu ist das Ergebnis bei dem “einfachen“ <strong>OR</strong> übrigens dann wahr, wenn mindestens ein Operand wahr ist oder beide).</p>
<p>Es werden also zwei Werte folgendermaßen verarbeitet:</p>
<p><img src="images/image.png" alt=""></p>
<p>XOR: nur wenn genau ein Wert wahr (1) ist, ist die entsprechende Stelle im Ergebnis wahr (1)</p>
<p>Die Implementierung in Python erfolgt mit dem <strong>Zirkumflex</strong>:</p>
<p># 110 ^ 100<br>
# 010</p>
<h4 id="das-logische-undand"><strong>Das logische Und (AND)</strong></h4>
<p>Der AND-Operator ist ebenfalls recht geläufig und vergleichsweise simpel. Analog zu XOR ist das Ergebnis wahr, wenn exakt beide (bzw. alle) Operanden wahr sind.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/images/image-4.png" alt=""></p>
<p>AND: Nur wenn beide Werte einer Stelle wahr sind, ist die Stelle im Ergebnis wahr</p>
<p>Die Implementierung in Python erfolgt mit dem <strong>kaufmännischen Und</strong>:</p>
<p># 110 &amp; 100<br>
# 100</p>
<h4 id="die-negierung-nope">Die Negierung (Nope?)</h4>
<p>Jetzt wirds seltsam: Auch dafür gibt es einen Operator: Der bitweise Operator <strong>Negierung</strong> dreht Werte um. Aus 0 wird 1, aus 1 wird 0.</p>
<p><img src="images/image-3.png" alt=""></p>
<p>Die Negierung kehrt Werte bitweise um. Nicht mehr aber auch nich weniger.</p>
<p>Die Implementierung in Python erfolgt mit der <strong>Tilde —</strong> meinem Lieblingszeichen!</p>
<p># ~110<br>
# 001</p>
<h4 id="die-shift-operation"><strong>Die Shift-Operation</strong></h4>
<p>Die Shift-Funktion ist eine elementare binäre Rechenoperation, bei der die einzelnen Stellen eines binären Werts <strong>nach links oder rechts geschoben</strong> werden. Die freien Stellen auf der jeweils anderen Seite werden mit 0 aufgefüllt.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/images/image-6.png" alt=""></p>
<p>Shift nach links um eine Stelle, aus 6 wird 12</p>
<p>Und jetzt gibt es hoffentlich einen positiven Knick in der Lernkurve: Wenn du genau hinschaust, fällt dir etwas auf und lass mich dir versichern, es handelt sich nicht um einen Zufall: 12 ist das Produkt aus 6 und 2. Das deutet auf ein interessanten Nebeneffekt: Ein Shift kommt einer Multiplikation bzw. Division mit 2 gleich. Ein Shift um mehrere Stellen entspricht demnach einer Multiplikation mit einer Potenz zur Basis 2 besteht. Klingt kompliziert, deswegen ein Beispiel:</p>
<p>Anstatt 139 * 2 ^17 kannst du die binäre Darstellung von 139, also 10001011, um 17 Stellen nach links shiften. Das Ergebnis: 1000101100000000000000000. Zähl gerne nach, rechts der 1 eins gibt es jetzt 17 Nullen.</p>
<p>In Python ist der binäre Shift mit dem <strong>Doppelpfeil</strong> implementiert:</p>
<p># 110 &raquo; 1<br>
# 011</p>
<p># 110 &laquo; 2<br>
# 000</p>
<h4 id="die-rotate-funktion">Die Rotate-Funktion</h4>
<p><strong>Rotate</strong> bedeutet, dass ein die Werte einer (binären) Zahl in eine Richtung verschoben werden. Und das erklärt man am besten an einem Beispiel. Die folgende Zahlenreihe soll um einen Zähler nach links rotiert werden. Die Zahl auf der linken Seite fällt also heraus und wir rechts wieder angehangen. Die anderen Zahlen rücken eine Position nach links.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/images/image-5.png" alt=""></p>
<p>Rotate eines binären Wertes um eine Stelle nach links, aus 6wird 5</p>
<p>Das funktioniert in beide Richtungen und mit beliebig vielen Stellen. Die entsprechende Funktion (<a href="https://stackoverflow.com/a/59005609/2360229">Kudos an so</a>) sieht so aus:</p>
<p>def rotate(value, rotations, width = 32):<br>
if int(rotations) != abs(int(rotations)):<br>
rotations = width + int(rotations)<br>
return (int(value) &laquo; (width - (rotations%width)) | (int(value) &raquo; (rotations % width))) &amp; ((1 &laquo; width) - 1)</p>
<h4 id="die-sigma-funktionen">Die Sigma-Funktionen</h4>
<p>Insgesamt werden vier sogenannte <strong>Sigma-Funktionen</strong> verwendet. <strong>σ0</strong> und <strong>σ1</strong> (das kleine Sigma) bzw. <strong>Σ0</strong> und <strong>Σ1</strong> (das große Sigma, vielen bekannt als das Summen-Zeichen). Alle funktionen werden mit einem binären Wert aufgerufen und geben diesen binären Wert in veränderter Form zurück.</p>
<p>σ0 (<strong>sigma0</strong>) läuft folgendermaßen ab:</p>
<ul>
<li>der Ausgangs-Wert wird um 7 <strong>Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>18 Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>3 Stellen</strong> nach <strong>rechts geshifted</strong></li>
</ul>
<p>Daraus entstehen drei unterschiedliche Werte, die miteinander <strong>XOR-Verknüpft</strong> werden. Die Funktion dazu in Python:</p>
<p>def sigma0(word):<br>
part1 = bin(rotate(int(word, 2), 7, 32))<br>
part2 = bin(rotate(int(word, 2), 18, 32))<br>
part3 = bin(int(word, 2) &raquo; 3)<br>
return bin(int(part1, 2) ^ int(part2, 2) ^ int(part3, 2))[2:].zfill(32)</p>
<blockquote>
<p><strong>Wichtiger Hinweis</strong>: Ich arbeite mit bin() und in(s, 2), um die Ausgaben und Eingaben leserlich und vor allem nachvollziehbar zu machen. Außerdem sorge ich mit [2:] dafür, dass die binäre Darstellung ohne <strong>0b</strong> auskommt. Das kommt dem Lernzweck zugute, da die binären Operationen an dezimalen Werten schwerer nachvollziehbar sind. Mit zfill(32) (<strong>zero fill</strong>) wird der binäre Wert nach links um so viele Nullen erweitert, um immer <strong>32 Stellen</strong> zu umfassen. Teilweise erleichtert das die Übersicht, andererseits erfüllt das später auch eine Längen-Vorgabe. Die obere Funktion kann also auch folgendermaßen vereinfacht werden:</p></blockquote>
<p>def sigma0(word):<br>
part1 = rotate(word, 7, 32)<br>
part2 = rotate(word, 18, 32)<br>
part3 = word &raquo; 3<br>
return part1 ^ part2  ^ part3</p>
<p>Bei σ1 (<strong>sigma1</strong>) sieht es ganz ähnlich aus:</p>
<ul>
<li>der Ausgangs-Wert wird um <strong>17 Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>19 Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>10</strong> <strong>Stellen</strong> nach <strong>rechts geshifted</strong></li>
</ul>
<p>Daraus entstehen drei unterschiedliche Werte, die miteinander <strong>XOR-Verknüpft</strong> werden. Die Funktion dazu in Python:</p>
<p>def sigma0(word):<br>
part1 = bin(rotate(int(word, 2), 7, 32))<br>
part2 = bin(rotate(int(word, 2), 18, 32))<br>
part3 = bin(int(word, 2) &raquo; 3)<br>
return bin(int(part1, 2) ^ int(part2, 2) ^ int(part3, 2))[2:].zfill(32)</p>
<p>Nun zu Σ0 (<strong>Sigma0</strong>). Auch hier keine großen Überaschungen, hier nun ohne <strong>Shift:</strong></p>
<ul>
<li>der Ausgangs-Wert wird um <strong>2 Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>13 Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>22</strong> <strong>Stellen</strong> nach <strong>rechts rotiert</strong></li>
</ul>
<p>Auch hier werden die jeweiligen Ergebnisse final <strong>XOR-Verknüpftg</strong>. In Python also:</p>
<p>def upper_sigma0(word):<br>
part1 = bin(rotate(int(word, 2), 2, 32))<br>
part2 = bin(rotate(int(word, 2), 13, 32))<br>
part3 = bin(rotate(int(word, 2), 22, 32))<br>
return bin(int(part1, 2) ^ int(part2, 2) ^ int(part3, 2))[2:].zfill(32)</p>
<p>Kommen wir zum letzten Teilnehmer unserer illustren griechischen Runde: Σ1 (<strong>Sigma1</strong>):</p>
<ul>
<li>der Ausgangs-Wert wird um <strong>6</strong> <strong>Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>11Stellen</strong> nach <strong>rechts rotiert</strong></li>
<li>der Ausgangs-Wert wird um <strong>25</strong> <strong>Stellen</strong> nach <strong>rechts rotiert</strong></li>
</ul>
<p>Und am Ende wieder die XOR-Verknüpfung. Python:</p>
<p>def upper_sigma1(word):<br>
part1 = bin(rotate(int(word, 2), 6, 32))<br>
part2 = bin(rotate(int(word, 2), 11, 32))<br>
part3 = bin(rotate(int(word, 2), 25, 32))<br>
return bin(int(part1, 2) ^ int(part2, 2) ^ int(part3, 2))[2:].zfill(32)</p>
<h4 id="wahl-undmehrheit">Wahl und <strong>Mehrheit</strong></h4>
<p>Bleiben wir noch etwas bei den Griechen und wechseln in die Politik: Die Wahl und die Mehrheit, englisch: <strong>choose</strong> und <strong>majority</strong>.</p>
<p>Choose ist eine etwas komplexere Funktion, die drei binäre Werte verarbeitet und zwar wieder bitweise. Die Funktion geht durch die jeweiligen Stellen (x) des ersten Eingangswerts und prüft:</p>
<ul>
<li>Wenn <strong>x = 1</strong> dann nimm <strong>y</strong></li>
<li>Wenn <strong>x = 0</strong> dann nimm <strong>z</strong></li>
</ul>
<p>Y und z stehen für die jeweiligen Stellen des zweiten und dritten Eingangswertes. Wie kann man das programmatisch lösen? So:</p>
<p>def choose(word1, word2, word3):<br>
bin_word1 = (int(word1, 2))<br>
bin_word2 = (int(word2, 2))<br>
bin_word3 = (int(word3, 2))<br>
return bin((bin_word1 &amp; bin_word2) ^ (~bin_word1 &amp; bin_word3))[2:].zfill(32)</p>
<p>Zunächst werden also Wert 1 und Wert 2 logisch UND-verknüpft. Dann wird die Negierung von Wert 1 mit Wert 3 UND-verknüpft. Die beiden Zwischensummen werden abschließend durch XOR gejagt.</p>
<p>Majority prüft ganz einfach für jede Stelle der drei Eingangs-Werte, welcher Wert, 1 oder 0, häufiger vorkommt. Das sieht in Python so aus — hier erklär ich die logischen Operationen jetzt nicht noch mal, es werden einfach XOR und AND verknüpft:</p>
<p>def majority(word1, word2, word3):<br>
bin_word1 = (int(word1, 2))<br>
bin_word2 = (int(word2, 2))<br>
bin_word3 = (int(word3, 2))<br>
return bin((bin_word1 &amp; bin_word2) ^ (bin_word1 &amp; bin_word3) ^ (bin_word2 &amp; bin_word3))[2:].zfill(32)</p>
<p><strong>Primzahlen?</strong></p>
<p>Um noch ein anderes beliebtes Feld der Arithmetik abzudecken, lasst uns noch kurz über Primzahlen reden. Primzahlen sind mystisch. Und damit genau richtig für unser irdisches Vorhaben, das Mining zu optimieren.</p>
<p>SHA-256 nutzt Primzahlen als Grundlage für den Algorithmus. Was nicht bedeutet, dass das Ergebnis durchschaubar wäre.</p>
<p>Wir fangen mal mit den ersten 64 Primzahlen an und bauen daraus einen Satz Konstanten. Selbstverständlich in Bitform.</p>
<p>first_64_prime_numbers = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311]</p>
<p>Diese werden nun aber auch noch ordentlich durch die Mangel genommen. Warum das erforderlich ist, kann ich nicht nachvollziehen. Aus meiner Sicht ist es ziemlich egal, welche Konstanten man verwendet werden, da sie immer gleich sind (deswegen ja <strong>konstant</strong>, diesmal übrigens aus dem lateinischen). Dahinter steckt also kein großes Geheimins.</p>
<p>Aus den 64 Primzahlen wird zuerst jeweils die dritte Wurzel gezogen. Dann wird der natürliche Teil entfernt (sprich alles vor dem Komma) und das Ergebnis mit 2³² (aka 4.294.967.296, was übrigens auch der Anzahl verfügbarer IPv4-Adressen entspricht — der 2. positive Knick in der heutigen Lernkurve?) multipliziert. Wie du oben ja gelernt und hoffentlich noch nicht vergessen hast, ist die Mulitplikation mit 2^32 ja eigentlich gar nicht so aufwendig im Bituniversum.</p>
<p>Das Ergebnis wird jedenfalls auf eine natürlich Zahl abgerundet — sprich alle Nachkommastellen entfernt. Wiederholt man das für die restlichen 63 Primzahlen, erhält man eine wohlgeformte Liste mit 64 Einträgen, die in etwa so aussehen, am Beispiel der notorischen Primzahl 2:</p>
<p>01000010100010100010111110011000</p>
<p>Oder als Hex-Wert:</p>
<p>0x428a2f98</p>
<p>Und im Dezimal-Zahlensystem:</p>
<p>1.116.352.408</p>
<p>Die Funktion dafür sieht folgendermaßen aus:</p>
<p>result_constants = []<br>
for prime_number in first_64_prime_numbers:<br>
cube_root = prime_number ** (1./3.)<br>
frac_part = cube_root - floor(cube_root)<br>
product = frac_part * (2**32)<br>
floored_product = floor(product)<br>
result_constants.append(bin(floored_product)[2:].zfill(32))</p>
<p>Das ganze nennen wir <strong>Ergebnis-Konstante</strong>, denn diese Liste ist der Anfang unsere finalen Ausgabe. Diese Liste heben wir gut auf und weil die Arbeit mit Primzahlen so befreiend ist, veranstalten wir für die ersten 8 Primzahlen einen ähnlichen Zirkus. Mit einem Unterschied: Als Grundlage dient diesmal die Quadrat-Wurzel:</p>
<p>compression_constants = []<br>
for prime_number in first_8_prime_numbers:<br>
square_root = prime_number ** (1./2.)<br>
frac_part = square_root - floor(square_root)<br>
product = frac_part * (2**32)<br>
floored_product = floor(product)<br>
compression_constants.append(bin(floored_product)[2:].zfill(32))</p>
<p>Die Namen haben übrigens eine Bedeutung, auf die ich später noch eingehe.</p>
<h3 id="epilog">Epilog</h3>
<p>Die Vorbereitungen sind damit abgeschlossen und wir können uns <a href="https://nickyreinert.de/blog/2021/10/31/wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/">im zweiten Teil</a> dem eigentlichen Algorithmus widmen.</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>anleitungen</category>
      
      <category>blog</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Wie funktioniert der SHA256 Algorithmus…im Detail? (Teil&amp;nbsp;1/2) - Tutorial</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Wie funktioniert der SHA256 Algorithmus…im Detail? (Teil&amp;nbsp;2/2)</title>
      <link>http://localhost:1313/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/</guid>
      <description>Wenn du den ersten Teil erfolgreich verarbeitet hast, bist du bestens gewappnet, um in diesem Teil zu erfahren, wie die einzelnen Komponenten bzw. Funktionen …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Wenn du den ersten Teil erfolgreich verarbeitet hast, bist du bestens gewappnet, um in diesem Teil zu erfahren, wie die einzelnen Komponenten bzw. Funktionen nun zusammenspielen.&#39; reading_time: 9 content_type: &#39;tutorial</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Git, Mobile, Ai, Security</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Wenn du <a href="https://nickyreinert.de/blog/2021/10/31/wie-funktioniert-der-sha256-algorithmusim-detail-teil-1-2/">den ersten Teil</a> erfolgreich verarbeitet hast, bist du bestens gewappnet, um in diesem Teil zu erfahren, wie die einzelnen Komponenten bzw. Funktionen nun zusammenspielen.</p>
<h3 id="vorbemerkung">Vorbemerkung</h3>
<p>Bevor es los geht möchte ich noch einmal die Zusammenhänge verdeutlichen: Wir werden gleich eine Nachricht (<strong>Message</strong>) erzeugen, deren Länge einem Vielfachen von <strong>512 Bit</strong> entspricht; im Beispiel genau <strong>512 Bit</strong>. Die Nachricht wird in <strong>Message-Blocks</strong> zerlegt, die exakt <strong>512 Bit</strong> lang sind. Jeder Message-Block wird wiederum zu einer <strong>Message-Schedule</strong> zerlegt, mit <strong>16 Wörtern</strong> (Words) zu je <strong>32 Bit</strong> Länge. Die Länge der Wörter muss und wird immer <strong>32 Bit</strong> sein! Der Message-Schedule wird dann aber erweitert, um <strong>64 Wörter zu</strong> enthalten. Seine Länge dann: <strong>2.048 Bit</strong>. Und grafisch:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-2.png" alt=""></p>
<p>Wichtige Zusammenhänge</p>
<h3 id="dekompressions">Dekompressions</h3>
<p>Wir wollen also aus einer Nachricht eine <strong>SHA-256</strong>-konforme Prüfsumme, den Hash, berechnen. Dazu muss die Nachricht, also der String, zunächst vorbereitet werden. Unsere Nachricht ist, klischeegerecht:</p>
<p>message = &lsquo;hello_world&rsquo;</p>
<p>Zunächst müssen wir für jeden Buchstabend die Position in der Zeichentabelle herausbekommen, sprich die Buchstaben (bzw genauer jedes Zeichen) in ihre numerische Repräsentation umwandeln:</p>
<p>dec_message = []<br>
for char in message:<br>
dec_message.append(ord(char))</p>
<p>Das Ergegnis ist eine Liste mit Integern:</p>
<p>[104, 101, 108, 108, 111, 95, 119, 111, 114, 108, 100]</p>
<p>Und da wir im ersten Teil so viel Spaß am Umgang mit binären Werten hatten, wandeln wir die Liste in binäre Werte um, die wir schlicht miteinander verknüpfen:</p>
<p>bin_message = &rsquo;&rsquo;<br>
for decimal in dec_message:<br>
bin_message += &lsquo;0&rsquo; + bin(decimal)[2:</p>
<p>Das Ergebnis:</p>
<p>0110100001100101011011000110110001101111010111110111011101101111011100100110110001100100</p>
<p>Hier gibt es allerdings eine Stolperfalle, und es widerstrebt mir das so stehen zu lassen, für die ich noch keine Erklärung gefunden habe: Bei der Umwandlung in die binäre Entsprechung stellen wir jedem binären Wert eine 0 voran. Aus <strong>104</strong> wird also nicht <strong>1101000</strong> sondern <strong>01101000</strong>, uswf.</p>
<p>Außerdem hängen wir an dieses Datum eine 1 heran, sozusagen als Trennzeichen für das, was jetzt gleich kommt.</p>
<p>Als nächstes berechnen wir die Länge dieser binären Zahl:</p>
<p>len_bin_message = len(bin_message)</p>
<p>Die Längenangabe darf bzw muss exakt <strong>64 Bit</strong> belegen. Wir wandeln sie also auch in eine binäre Zahl um hängen vorne ein paar Nullen ran um genau 64 Stellen zu erhalten:</p>
<p>rest_to_64 = 64 - len(bin(len_bin_message)[2:])</p>
<p>bin_message_len = &lsquo;0&rsquo; * rest_to_64 + bin(len_bin_message)[2:]</p>
<p>Nun müssen wir diese drei binären Informationen, Nachricht, trennende Eins und Längenangabe nicht nur verbinden, sondern auch mit so vielen Nullen auffüllen, damit die Gesamtlänge ein vielfaches von 512 ist.</p>
<p>payload = bin_message + &lsquo;1&rsquo; + bin_message_len</p>
<p>len_payload = len(payload)</p>
<p>pad_string = int(512 - (len_payload % 512))</p>
<p>full_message = bin_message + &lsquo;1&rsquo; + (&lsquo;0&rsquo; * pad_string) + bin_message_len</p>
<p>In unserem Beispiel belegen die drei Informationen 153 Bit. Wir müssen also 359 Nullen dazupacken. Genau genommen kommen die zwischen Nachricht und Längenangabe. Das Ergebnis ist immer <strong>n* 512 Bits</strong> lang:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-8.png" alt=""></p>
<p>Aufbau einer vorkodierten Nachricht</p>
<p>Zu guter Letzt nehmen wir diese sehr, sehr, sehr, sehr….sehr, sehr große Zahl (sie ist sehr groß, du solltest sie auch nicht als Zahl sehen, sondern als <strong>Bitfolge</strong>!) und teilen sie in sogenannte Message Blocks mit einer Länge von jeweils <strong>512 Bits</strong> auf:</p>
<p>message_block_length = 512<br>
message_blocks = [full_message[i:i+message_block_length] for i in range(0, len(full_message), message_block_length)]</p>
<p>Schnapp dir einen Kaffee, geh noch mal frische Luft schnappen, schüttel den Stuhl aus. Jetzt geht es los.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/beer.jpg" alt=""></p>
<p>8 Bits sind keine Bitfolge</p>
<h3 id="die-schleife">Die Schleife!</h3>
<p>Da es einfacher ist, den Vorgang ohne Schleife zu erklären, hier nur eine Schleife. Die programmatische Schleife findest du trotzdem auf <a href="https://gist.github.com/nickyreinert/00d631fe9a90108924b1df6e911c8cd5"><strong>Github</strong></a>.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-9.png" alt=""></p>
<p>Es folgt: Eine Schleife</p>
<p>Da unsere Nachricht genau 512 Bit groß ist und wir auch ohne Schleife arbeiten, können wir direkt in die Vollen gehen: Die mühsam zusammengeklebte Nachricht wird nun in den sog. Message Schedule zerlegt: Sprich in <strong>16 Wörter</strong> mit jeweils 32 Bit Länge.</p>
<p>Im ersten Durchlauf nehmen wir vier Wörter und führen folgende Modifikationen aus:</p>
<ul>
<li><strong>σ1</strong> wird auf <strong>Wort 1</strong> an Position 14 angewendet,</li>
<li><strong>Wort 2</strong> von Position 9 bleibt unverändert,</li>
<li><strong>σ0</strong> wird auf <strong>Wort 3</strong> an Position 1 angewendet und</li>
<li><strong>Wort 4</strong> an Position 0 bleibt wieder unberührt</li>
</ul>
<p>Die Werte werden zunächst addiert und jetzt gibt es wieder einen <strong>wichtigen Punkt</strong> zu beachten: Wir müssen strikt dafür sorgen, dass die Wörter nicht länger als <strong>32 Bit</strong> sind. Denn nur so können wir sicherstellen, dass der finale Hash immer die gleiche länge hat. Und spätestens jetzt, bei der <strong>Addition großer Werte</strong>, können wir die <strong>32 Bit</strong> recht schnell überschreiten. Das ist auch aus technischer Sicht eine Hürde. Deswegen gilt: Hier und bei allen Additionen müssen wir abschließend <strong>Modulo 2</strong>³² anwenden. Und jetzt kommt der dritte hoffentlich positive Knick in der Lernkurve: Auch für Modulo hält das binäre Universum eine schöne Vereinfachung parat: <strong>Das logische Und</strong> mit 2³²–1 (bzw 4.294.967.295, das ist eine sehr große Zahl, nicht so groß wie die im ersten Teil, sondern genau einen Zähler kleiner) führt zum gleichen Ergebnis.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-5.png" alt=""></p>
<p>Berechnung des ersten Schritts</p>
<p>Damit wäre der Message-Schedule vorbereitet und enthält nun <strong>64 wunderschöne Wörter</strong> zu <strong>je 32 Bit</strong>. Wir haben die Informationen aus dem Message Block also zunächst aufgeplustert und von <strong>512 Bit auf 2.048 Bit</strong> erweitert- sie sind aber immer noch lesbar:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-6.png" alt=""></p>
<p>Der erweiterte Message Schedule</p>
<p>Aber damit ist jetzt Schluss, wir kommen zum nächsten und wichtigsten Schritt:</p>
<h3 id="die-kompression">Die Kompression</h3>
<p>Der erweiterte Message-Schedule wird in diesem Schritt nicht direkt modifiziert, die Wörter werden vielmehr als Grundlage für die Modifikation der anfangs erzeugten <strong>Kompressions-Konstanten</strong> verwendet.</p>
<p>In 64 Schleifen-Durchläufen gehen wir durch den Message-Schedule. Aus jedem Wort des Schedules (also unserer ursprünglichen Nachricht) wird zusammen mit den <strong>64 Ergebnis-Konstanten</strong> und den <strong>8 Kompressions-Konstanten</strong> ein neues Wort berechnet. Das neue Wort wird dann den Kompressions-Konstanten vorangestellt, gleichzeitig wird der letzte Eintrag gelöscht. So enthält die Liste immer genau 8 Einträge.</p>
<p>new_compression_constants = compression_constants.copy()</p>
<p>for i, word in enumerate(message_schedule):</p>
<pre><code>term1 = (int(upper\_sigma1(new\_compression\_constants\[4\]), 2) + \\  
            int(choose(new\_compression\_constants\[4\], new\_compression\_constants\[5\], new\_compression\_constants\[6\]), 2) + \\  
            int(new\_compression\_constants\[7\], 2) + \\  
            int(result\_constants\[i\], 2) + \\  
            int(word, 2)) \\  
            &amp; int('11111111111111111111111111111111', 2)

term2 = (int(upper\_sigma0(new\_compression\_constants\[0\]), 2) + \\  
            int(majority(new\_compression\_constants\[0\], new\_compression\_constants\[1\], new\_compression\_constants\[2\]), 2)) &amp; int('11111111111111111111111111111111', 2)

new\_compression\_constants.insert(0, 1)  
new\_compression\_constants.pop()

new\_compression\_constants\[0\] = bin(  
            (term1 + term2) &amp; int('11111111111111111111111111111111', 2)  
            )\[2:\].zfill(32)

new\_compression\_constants\[4\] = bin(  
            (int(new\_compression\_constants\[4\], 2) + term1) &amp; int('11111111111111111111111111111111', 2)  
            )\[2:\].zfill(32)
</code></pre>
<p>Zunächst ein paar Berechnungen:</p>
<ul>
<li><strong>Term 1</strong> berechnet sich aus den Kompressions-Konstanten, einer der Ergebnis-Konstanten und dem jeweiligen Wort. Wir verwenden hier auf Bitebene und <strong>Σ1</strong> (upper_sigma1) sowie <strong>choose</strong>.</li>
<li><strong>Term 2</strong> ist eine Summe zweier anderer Kompressions-Konstanten, die mithilfe von <strong>Σ0</strong> (upper_sigma0) sowie <strong>majority</strong> modifiziert werden.</li>
</ul>
<p>Und jetzt achte mal drauf, dass die ursprüngliche Nachricht Teil des 1. Terms ist — in der Abbildung rot markiert:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-3.png" alt=""></p>
<p>Im ersten Schritt erfolgt die Berechnung zweier Terme</p>
<p>Die beiden Terme werden nun wiederum addiert (und wie immer mit <strong>Modulo 2³²</strong> auf 32 Bit-Kurs gebracht) und an den Anfang der Kompressions-Konstanten gestellt. Der erste Term wird außerdem mit der 4. Position dieser nun 9 Wörter langen List summiert:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-1.png" alt=""></p>
<p>Im zweiten Schritt wird die Listse der Kompression-Konstanten aktualisiert</p>
<p>Als nächstes wird der letzte Eintrag der Liste gelöscht, sie umfasst nun <strong>8 komplett neue Kompressions-Konstanten</strong> (wenn du aufmerksam aufgepasst hast, wird dir nicht entgangen sein, dass sie gar nicht mal so konstant sind).</p>
<p>Ein Teil der ursprünglichen Nachricht befindet sich nun an als <strong>Summand von Term 1</strong> and den <strong>Positionen 0 und 4</strong> und. Diese werden in den nächsten Durchläufen Teil der gleichen Berechnungen und immer weiter nach unten rutschen. So verteilt sich die ursprüngliche, bisher noch halbwegs lesbare Nachricht, über die gesamte Liste.</p>
<p>Diese Liste ist also die Grundlage für den zweiten Durchlauf, der sie erneut “durchrotiert”, um wiederum eine komplett neue Liste für den dritten Durchlauf zu erzeugen. Und so weiter, bis alle 64 Wörter des Message-Schedules verarbeitet wurden. Das Ergebnis sollte in etwa so aussehen:</p>
<p>11100010000000010111101011011001<br>
01000110110100101000001000010100<br>
11100011111110010111100001001011<br>
01110001100001100000010000011110<br>
01001000000111100100000000011000<br>
00011111110001101011001000110101<br>
11101001110010001101110111110100<br>
00001001011011110000111011111011</p>
<p>Oder in Hexadezimal:</p>
<p>0xe2017ad9 0x46d28214 0xe3f9784b 0x7186041e 0x481e4018 0x1fc6b235 0xe9c8ddf4 0x96f0efb</p>
<p>Abschließend gehen wird durch genau diese Liste der 8. Kompressions-Konstanten und addieren jede Positionen mit dem entsprechenden Wort der Ausgangs-Liste:</p>
<p>result = []</p>
<p>for i in range(0, 8):</p>
<pre><code>result.append(  
    bin(int(compression\_constants\[i\], 2) +   
    int(new\_compression\_constants\[i\], 2)  &amp;      
    int('11111111111111111111111111111111', 2))\[2:\].zfill(32))
</code></pre>
<p>Und im Klartext:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-4.png" alt=""></p>
<p>Letzter Schritt: Addieren der Listen</p>
<p>Die neue Liste ist nun die <strong>Ausgangs-Liste</strong> für den nächsten Message-Schedule. Da wir die Schleife hier aber nicht implementieren, war es das fürs erste. Im Folgenden noch mal eine beispielhafte Zusammenfassung der Schritte:</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/screenshot-7.png" alt=""></p>
<p>Schematische Darstellung des SHA-256 Algorithmus’</p>
<h3 id="haschee-gesundheit-was">Haschee. Gesundheit. Was?</h3>
<p>Wir haben es geschafft. Du hast es geschafft. Herzlichen Glückwunsch.</p>
<p><img src="/2021/2021-10-31-wie-funktioniert-der-sha256-algorithmusim-detail-teil-2-2/images/not-bad.jpg" alt=""></p>
<p>Quelle: memecreator.org</p>
<p>Nun können wir den Hash entweder als Hex-Wert ausgeben oder wieder in binärer Schreibweise darstellen, je nach Anwendungszweck.</p>
<p>for word in result:</p>
<pre><code>print(hex(int(word, 2))\[2:\].zfill(8) + '', end = '')
</code></pre>
<p>Das Ergebnis kann sich in jedem Fall sehen lassen.</p>
<p>35072c1ae546350e0bfa7ab11d49dc6f129e72ccd57ec7eb671225bbd197c8f1</p>
<p>Oder</p>
<p>110101000001110010110000011010111001010100011000110101000011101011111110100111101010110001111010100100111011100011011111001010011110011100101100110011010101011111101100011111101011110011100010010001001011011101111010001100101111100100011110001</p>
<h3 id="epilog">Epilog</h3>
<p>Eine komplette Implementierung, inklusive einer Schleife, um auch große Nachrichten zu verarbeiten, findest <a href="https://gist.github.com/nickyreinert/00d631fe9a90108924b1df6e911c8cd5">du in diesem Gist</a>.</p>
<p>Freilich ist Python nicht dazu geeignet, den SHA-256 Prozess zu optimieren, wohl aber um den Prozess zu verstehen und den Umgang mit elementaren binären Rechenoperation zu lernen.</p>
<p>Willst du den Prozess noch etwas interaktiver nachvollziehen, möchte ich dir <a href="https://www.youtube.com/watch?v=f9EbD6iY9zI">dieses Video</a> empfehlen. Dort wird der Algorithmus in Ruby nachgebaut und die einzelnen Rechenschritte auch etwas genauer erklärt.</p>
<p>Und warum ist SHA-256 für das Mining von Kryptowährungen jetzt so wichtig? Kurz: Der Hash validiert die Gültigkeit des <em>Kassenbuches</em>. Beim Mining geht es darum, aus einer gegebenen Nachricht und einem frei wählbaren Zusatz exakt einen gegebenen Ziel-Hash zu berechnen. Der Algorithmus muss also wahnsinng oft durchlaufen werden. Da das sehr aufwendig ist, kostet das Zeit und wird entsprechend belohnt.</p>

        
        
        <div class="tags">
          <p><strong>Tags:</strong> bitcoin, mining, sha</p>
        </div>
        
      ]]></content:encoded>
      
      
      
      <category>anleitungen</category>
      
      <category>blog</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Wie funktioniert der SHA256 Algorithmus…im Detail? (Teil&amp;nbsp;2/2) - Tutorial</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Augenblicke - Eine statistische Analyse des Flirt-Portals der BVG</title>
      <link>http://localhost:1313/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/</guid>
      <description>Was ist &ldquo;Augenblicke&rdquo;? Im Frühjahr 2006, mehr als 6 Jahre bevor Tinder die Herzen der Smarthphone-Besitzer im Sturm eroberte, startete die BVG auf …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Im Frühjahr 2006, mehr als 6 Jahre bevor **Tinder** die Herzen der Smarthphone-Besitzer im Sturm eroberte, startete die BVG [auf ihrer Seite ein Portal mit dem Namen &#39;**Augenblicke**&#39;](https://www.bvg.</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Wordpress, Mac, Git, Database, Ai</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <h2 id="was-ist-augenblicke">Was ist &ldquo;Augenblicke&rdquo;?</h2>
<p>Im Frühjahr 2006, mehr als 6 Jahre bevor <strong>Tinder</strong> die Herzen der Smarthphone-Besitzer im Sturm eroberte, startete die BVG <a href="https://www.bvg.de/de/Meine-BVG/Meine-Augenblicke/Alle-Augenblicke">auf ihrer Seite ein Portal mit dem Namen &ldquo;<strong>Augenblicke</strong>&rdquo;</a>. Im Gegensatz zu Tinder sind sich die Nutzer von <em>Augenblicke</em> in der Regel aber ziemlich sicher schon einmal über den Weg gelaufen - nämlich in einer der zahlreichen Fahrzeuge der BVG oder S-Bahn.</p>
<p><em><strong>Augenblicke</strong></em> will diese verlorenen Seelen nun zusammenbringen. Wer beim ersten Treffen nicht den Mut aufgebracht hat, das Gegenüber anzusprechen, darf das später mit einer Nachricht auf dem Portal nachholen. Das geschieht unter der Angabe eines <strong>Pseudonyms</strong>, <strong>ein paar Zeilen Text</strong>, <strong>der Tram-, Bus- oder Bahn-Linie</strong> und natürlich dem <strong>Zeitpunkt</strong>, wann man sich über den Weg gelaufen ist - der sogenannte und namensgebende <strong>Augenblick</strong>. Das Prinzip ist also recht einfach. Nach einem verhaltenen Start Anfang 2006 dauerte es erstmal einige Zeit, bis sich ein gewisser Erfolg zeigte.</p>
<p><em>(Hinweise zur Methodik und Fehlerquellen am Ende)</em></p>
<h2 id="kleinermannmitbart">KleinerMannMitBart</h2>
<p><a href="https://www.bvg.de/de/Meine-BVG/Meine-Augenblicke/Alle-Augenblicke?act=read-moment&amp;id=2846">Zum allerersten Augenblick</a> kam es an einem <strong>Valentinstag</strong>: Am 14. Februar 2006 um 5 Uhr traf es <strong>KleinerMannMitBart</strong> in der <strong>Buslinie 284</strong>:</p>
<blockquote>
<p>&ldquo;Du (blond, grüne Augen, schlank)&rdquo;</p>
<p>KleinerMannMitBart, 14. Februar 2006</p></blockquote>
<p>Der Dienst dümpelte dann eine Weile vor sich hin, bevor er in der Öffentlichkeit nachhaltig wahrgenommen wird. Erst in 2007 nahm das Portal tatsächlich <em>fahrt</em> auf: die monatliche Beitragszahl stieg auf über 100. Der vorläufige Höhepunkt wurde <strong>im Mai 2018 mit 291 Beiträgen</strong> im Monat erreicht, fast 10 Gesuche pro Tag! Doch dann war der Hype schon wieder vorbei, das <strong>Ende der fetten Flirtjahre</strong>:</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-21.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-21-700x435.png" alt=""></a></p>
<p>Anzahl Beiträge / Jahr nach Anbieter</p>
<p>Der Abwärtstrend ist insofern überraschend, da die Zahl der tatsächlichen Fahrgäste in den letzten Jahren stetig zunimmt.</p>
<p>Bis Januar 2021 haben die Besucher in 240 verschiedenen <strong>Linien der BVG, S-Bahn und sogar Deutschen Bahn (Regio!)</strong> <strong>genau 20.108 Augenblicke</strong> erlebt. Zu den meisten Begegnungen kommt es den <strong>U-Bahnen und S-Bahnen</strong>:</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-2.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-2-700x367.png" alt=""></a></p>
<p>Wenn man etwas mehr ins Detail geht, zeigt sich, dass die <strong>U-Bahn</strong> mit <strong>8.149 Einträgen</strong> leicht vorne liegt, dicht gefolgt von der <strong>S-Bahn</strong> (<strong>6.581</strong>)</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-3.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-3-700x803.png" alt=""></a></p>
<p>Für dieses Ranking kann es übrigens drei Erklärungen geben:</p>
<ol>
<li>Entweder gibt es mehr Singles, die bevorzugt die U-Bahn benutzen, oder</li>
<li>die Fahrt unter der Erde ermutigt die Menschen eher zum Flirten.</li>
<li>Oder die Menschen sind in der U-Bahn besonders schüchtern und müssen daher vermehrt auf dieses Portal zurückgreifen.</li>
</ol>
<h2 id="trakl-und-2151-anonyme">Trakl und 2.151 Anonyme</h2>
<blockquote>
<p>[&hellip;]Ihr Lächeln, mal amüsiert, gelegentlich auch erstaunt, aber immer von feinster Anmut - ach, es macht(e)mich zufrieden. Nun, die hellen Tage [&hellip;]</p>
<p>Takl am 21. März 2011 in der M1</p></blockquote>
<p><em>Trakl</em> ist nicht nur der Name eines expressionistischen Dichters aus Österreich. Der Name taucht auch auf der Plattform auf und ist mit <strong>39 Einträgen</strong> das am meisten genutzte <strong>Synonym</strong>. Insgesamt wurden <strong>12.298 verschiedene Pseudonyme</strong> genutzt. <strong>2.151 Benutzer</strong> <strong>haben keinen Namen</strong> angeben. Das ist die Top-10 der beliebtesten Namen auf dem Portal:</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-4.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-4-700x210.png" alt=""></a></p>
<p>Schaut man sich an, auf welchen Linien <em>die Autoren:innen</em> unterwegs waren, kommt schnell der Verdacht auf, dass es sich jeweils um ein und dieselbe Personen handelt.</p>
<p>Natürlich lässt der Datensatz auch Rückschlüsse auf die <strong>genau Uhrzeit</strong> oder die <strong>exakte</strong> <strong>Linienbezeichnung</strong> und damit vermutlich sogar eine <strong>Pendelstrecke</strong> zu. <em>Aus Gründen</em> möchte ich diese Details hier nicht weiter vertiefen.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-6.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-6-700x184.png" alt=""></a></p>
<h2 id="tageszeiten-und-wochentage">Tageszeiten und Wochentage</h2>
<p>Zurück zur grauen Masse und der Frage: <strong>Zu welcher Tageszeit</strong> und an welchem Wochentag sind die Portal-Nutzer am aktivsten? Zunächst zum offensichtlichen: Die Pendlerzeiten liegen zwischen 7 und 9 Uhr sowie 16 und 19 Uhr. An den Werktagen zeigt sich, dass die Bereitschaft zu Flirten am müden Morgen noch relativ gering ist. Abends, zum Feierabendverkehr - kommt es dagegen zu sehr vielen Kontakten.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-7.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-7-700x768.png" alt=""></a></p>
<p>Beiträge je Wochentag und Tageszeit</p>
<p>Wenig überraschend sieht es am Wochenende etwas anders aus. Hier verlagert sich die Anzahl der Einträge zunächst auf den frühen Nachmittag.</p>
<p>Ein kurzer Blick auf die Stimmung der Beiträge: Eine klare Tendenz lässt sich hier nicht erkennen. In den frühen Morgenstunden scheint die Stimmung stärker zu schwanken als Abends.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-9.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-9-700x771.png" alt=""></a></p>
<p>Stimmung im Wochenverlauf (-1: negativ, 1: positiv)</p>
<h2 id="textanalyse">Textanalyse</h2>
<p>Zunächst ein grober Überblick über die Stimmung im Verlauf der Jahre sowie die durchschnittliche Länge der Beiträge und Wortanzahl.</p>
<p>Die Wortlänge über alle Nachrichten hat sich im Laufe der Jahre kaum verändert. Die Ausschläge zu Beginn der Messung sind auf die geringe Fallzahl zurückzuführen. Danach sind es zwischen 70 und 80 Wörter pro Nachricht. Ab Ende 2014 gibt es einen kurzlebigen Aufwärtstrend in Richtung 90 Wörter pro Eintrag.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-10.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-10-700x364.png" alt=""></a></p>
<p>Zwischen 2011 und 2014 lässt sich ein kleines Stimmungstief erkennen. In 2020 gibt es noch mal einen deutlichen Knick - Auswirkungen von Corona? Auch die (durchschnittliche) Länge der Nachrichten und die Wortanzahl scheint ab 2015 leicht zu steigen.</p>
<p>Die nächste Abbildung zeigt die Stimmung aller Autoren:innen sowie die Objektivität ihrer Nachrichten. Die Objektivität liefert kaum Erkenntnisgewinn und wird hier nur einmal erwähnt. Interesssanter ist die Stimmung, die in den allermeisten Fällen positiv ist, mitunter sogar stark positiv.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-11.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-11-700x435.png" alt=""></a></p>
<p>Stimmung und Objektivität aller Autoren</p>
<p>Weiter geht es mit der Stimmung nach Fahrzeugklasse. Die Abbildung zeigt neben der Stimmung auch die Anzahl der Beiträge (blaue Punkte). So dürfte sich die relativ hohe mittlere Stimmung bei den Nachtbussen erklären. Insgesamt lässt sich vielleicht festhalten, dass die Stimmung in den S- und U-Bahnen sowie Regionalzügen am geringsten ist.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-13.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-13-700x562.png" alt=""></a></p>
<p>Das passt zu der Erkenntnis oben, dass Beiträge mit Bezug zu z.B. Bussen vergleichsweise selten vorkomen: <strong>Sind die Menschen dort glücklicher und demnach vor Ort kontaktfreudiger</strong>?</p>
<p>Die <strong>längsten Nachrichten</strong> mit den <strong>meisten Wörtern</strong> kommen übrigens nicht aus den Linien-Favoriten S-Bahn oder U-Bahn. Nein, es sind Regionalbahnen und die Nacht-Busse, die sich offenbar äußerst fruchtbar auf die Fantasie der Fahrgäste auswirken. Eine Erklärung: Hat man hier mehr Zeit zum Schreiben?</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-15.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-15-700x463.png" alt=""></a></p>
<p>Noch mal zurück zur Auswertung der Stimmung. Für das folgende Histogramm habe ich die Stimmungswerte in 0,05 Schritten geclustert um deutlich zu machen, in welchem Bereichen sich die Stimmung der meisten Nachrichten bevorzugt zeigt. Hier ist ganz klar eine Dominanz im neutralen Bereich (0) bis hin zu mittelmäßig positiv (0,5) zu erkennen.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-16.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-16-700x454.png" alt=""></a></p>
<p>Lässt man sich die Cluster im Tagesverlauf anzeigen, dass die Stimmung fast gleichmäßig verteilt zu sein scheint. Nur am Freitag gibt es im Bereich um 0,2 eine höhere Konzentration an Nachrichten (je dunkler die Farbe, desto mehr Nachrichten in diesem Cluster):</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-18.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-18-700x556.png" alt=""></a></p>
<h2 id="phrasen-und-wörter">Phrasen und Wörter</h2>
<p>Zum Abschluss noch ein kleiner Blick auf beliebte Phrasen und Wörter. Zunächst alle Wörter (die mindestens 1.000 mal gezählt wurden):</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-19.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-19-700x285.png" alt=""></a></p>
<p>Wenig überraschend sind hier beschreibende Wörter wie <strong>Auge, Haar, Jacke</strong>, <strong>Braune</strong>, <strong>Rucksack</strong> oder <strong>Mantel</strong> zu finden. Interessant auch: Das Wort <strong>leider</strong> wird über <strong>6.000</strong> mal verwendet. Nachvollziehbar: Die Plattform ist ja eine Anlaufstelle, für verpasste Chancen. Das absolut häufigste Wort ist <strong>haben</strong> mit über 22.000 Vorkommen. Zur Erklärung: Da die Wortstämme gezählt werden, fallen darunter auch <strong>hat, hast, habe</strong> usw. Sprich: <strong>Ich habe dich gesehen, hast du mich gesehen</strong>.</p>
<p>Nun noch ein kurzer Blick auf die beliebtesten Phrasen:</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/grafik-20.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/grafik-20-700x315.png" alt=""></a></p>
<p>Sehr schön gefällt mir hier das Vorkommen von &ldquo;<strong>unsere Blicke</strong>&rdquo; - was sich nicht nur wunderbar auf den Namen des Portals - Augenblicke - sondern auch seinen Zweck beziehen lässts. Ansonsten finden sich hier natürlich auch naheliegende, beschreibende Phrasen. Es geht ja um die &ldquo;Personensuche&rdquo;: <strong>Blonde Haare, dein Lächeln, schwarze Jacke</strong>.</p>
<h2 id="methodik-und-fehlerquellen">Methodik und Fehlerquellen</h2>
<h3 id="datenerfassung-und-grobes-datenmodell">Datenerfassung und grobes Datenmodell</h3>
<p>Um die Beiträge <a href="https://www.bvg.de/de/Meine-BVG/Meine-Augenblicke/Alle-Augenblicke">von der Hauptseite</a> abzugreifen, nutze ich ein in <strong>PHP</strong> geschriebenes Script (<a href="https://github.com/nickyreinert/crawl-augenblicke">crawl-augenblicke auf Github</a>). In einer <strong>MySQL</strong>-Tabelle speichere ich dann den <strong>Titel der Nachricht</strong>, den <strong>Nachrichten-Text</strong>, den <strong>Verfasser der Nachricht</strong>, das <strong>Datum</strong> an dem die Nachricht verfasst wurde sowie das <strong>Datum, an dem der &ldquo;Augenblick&rdquo; stattgefunden</strong> hat. Dazu wird die <strong>URL</strong> zum Beitrag sowie die <strong>Linie</strong> erfasst. Zusätzlich nutze ich einige selbstgeschriebene <strong>MySQL-Funktionen</strong>, um die <strong>Anzahl der Wörter im Titel</strong> und dem <strong>Nachrichten-Text</strong> sowie die <strong>Differenz zwischen den beiden Zeitpunkten</strong> zu erfassen. Ein paar eigene Views erleichtern das anfängliche Finden von Fehlern.</p>
<p>Daneben gibt es zwei weitere Tabellen mit Meta-Informationen. Dies ist zunächst eine <strong>Blacklist</strong>-Tabelle, die bei einer Aggregation der Wort-Häufigkeiten ignoriert werden sollen. Das betrifft nicht den Vorgang des Zählens der Wörter! In einer weiteren Tabelle wird eine <strong>Zuordnung der Linien</strong> zu den Linientypen sowie Subtypen festgehalten. Zu den Linientypen zählen nur Bus, Tram, Zug sowie Fähre. Anhand der Subtypen kann außerdem in besondere Liniengruppen unterschieden werden, wie z.B. Metro-Bus, Express-Bus usw.</p>
<p><a href="https://www.nickyreinert.de/files/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/datenbankschema.png"><img src="/2021/2021-01-21-augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/images/datenbankschema-300x182.png" alt="Datenbankschema"></a></p>
<p>Datenbankschema</p>
<p>Mit einem <strong>Python-Script</strong> lese ich den Datensatz ein und bereinige die Texte. Stoppwörter werden aussortiert, Steuerzeichen, HTML-Entitites und andere Störquellen werden entfernt. Dann berechen ich für jedes Wort die <strong>IDF</strong> (<strong>Inverse Document Frequency</strong>) nach der Formel <strong>log 1 + (doc_count_total / doc count with word occurrence</strong>). Für die NLP-Aufgaben nutze ich das NLTK bzw. den <strong>HannoverTagger</strong> (<a href="https://nickyreinert.de/blog/2020/12/09/einfuehrung-in-stemming-und-lemmatisierung-deutscher-texte-mit-python/">siehe auch</a>). Für die Erkennung der Phrasen und der Stimmung nutze ich <strong>TextBlob</strong> mit deutschen <a href="https://github.com/markuskiller/textblob-de">Trainingsdaten von hier</a>.</p>
<h3 id="mögliche-fehlerquellen">Mögliche Fehlerquellen</h3>
<p>Grundsätzlich gibt es zwei Dinge zu beobachten: Die Auswertungen werden nicht in Relation zur tatsächlichen Anzahl der Fahrgäste der jeweiligen Linie betrachtet, da diese nur auf Jahresebene zu Verfügung stehen. Es kann also nur ein Vergleich der absoluten Zahlen stattfinden. In Relation betrachtet kann die Gegenüberstellung der Linien ein anderes Ergebnis liefern.</p>
<p>Außerdem kann die Anzahl der Einträge je Linie auf zwei Arten interpretiert werden: Die Passagiere sind in der Linie mit vielen Einträgen entsprechend flirtfreudiger und offener und deshalb kommt es auf der Plattform zu mehr Gesuchen. Oder aber es ist genau andersrum: Da die Menschen einer bestimmten Linie schüchterner sind, trauen sie sich erst im Nachhinein die Kontaktaufnahme über diese Plattform zu starten. Diese Erkenntnisse müssen also mit Vorsicht betrachtet werden.</p>
<p>Leider gab es im Laufe der Zeit einige technische Anpassungen auf den Seiten der BVG, die einige Analysen etwas erschweren bzw. verhindern. Das betrifft vor allem das Datum, an dem die Beiträge verfasst (<strong>date_posted</strong>) wurden. Es fällt auf, dass sehr viele Einträge offenbar am 13. August 2014 verfasst wurden, das Datum des Augenblicks (<strong>date_met</strong>) aber sehr lange zurück liegt, teilweise bis 2006. Das älteste Datum in date_posted ist der 30.06.2014, bei date_met allerdings der 14.02.2006. Die Vermutung ist also, dass das Datum, an dem der Beitrag verfasst wurde, erst ab Juni 2014 mit erfasst wurde. Im August hat man dann vermutlich alle älteren Beiträge auf das feste Datum, nämlich den 13.08.2014 gesetzt. Insgesamt betrifft das immerhin 15.560 Datensätze.</p>
<p>Die Stimmungsanalyse nutzt einen fertigen Trainingsdatensatz und ist nur so gut, wie die Qualität der Texte. Rechtschreibfehler und Umgangssprache können hierbei nur unzureichend erfasst werden.</p>
<h2 id="verwendete-technologie">Verwendete Technologie</h2>
<p>Für das Abgreifen des BVG-Portals verwende ich ein <a href="https://github.com/nickyreinert/crawl-augenblicke">PHP-Script</a>. Das Python-Script zur Normalisierung, Anreicherung und Bereinigung der Daten ist nicht öffentlich. Ganz offensichtlich verwende ich Wordpress. In einer früheren Variante habe ich zwei selbstgeschriebene Plugins verwendet. Das ist zum einen das Plugin für die Darstellung der <a href="https://github.com/nickyreinert/data-heatmap">HTML-Heatmap</a> sowie das Plugin für die <a href="https://github.com/nickyreinert/wordCloud-for-Wordpress">WordCloud</a>, basierend auf dem fantastischen wordCloud2.js von Tim Dream. Die Idee war, die Zahlen dynamisch zu aktualisieren. Mittlerweile bin ich auf einfache Screenshots von Tableau Public umgestiegen.</p>

        
        
        <div class="tags">
          <p><strong>Tags:</strong> analyse, augenblicke, berlin, bvg, oepnv, statistik, tinder</p>
        </div>
        
      ]]></content:encoded>
      
      
      
      <category>projekte</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Augenblicke - Eine statistische Analyse des Flirt-Portals der BVG - Analysis</media:title>
      </media:content>
      
      
      
      
      <dc:subject>Lesezeit: 12 Minuten</dc:subject>
      
      
      
      <dc:type>analysis</dc:type>
      
      
    </item><item>
      <title>Einführung in Stemming und Lemmatisierung deutscher Texte mit Python</title>
      <link>http://localhost:1313/2020/2020-12-09-einfuehrung-in-stemming-und-lemmatisierung-deutscher-texte-mit-python/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2020/2020-12-09-einfuehrung-in-stemming-und-lemmatisierung-deutscher-texte-mit-python/</guid>
      <description>Um beim Text Mining zusammengehörende Wörter zu gruppieren, bedient man sich im Natural Language Processing (NLP) zweier Methoden: Lemmatisierung (lemmatising) …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Um beim Text Mining zusammengehörende Wörter zu gruppieren, bedient man sich im Natural Language Processing (NLP) zweier Methoden: Lemmatisierung (lemmatising) und Stemming. Das ist notwendig, um z. B.&#39; reading_time: 9 content_type: &#39;project</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Wordpress, Docker, Mac, Git, Database</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Um beim <strong>Text Mining</strong> zusammengehörende Wörter zu gruppieren, bedient man sich im <strong>Natural Language Processing</strong> (<strong>NLP</strong>) zweier Methoden: <strong>Lemmatisierung</strong> (lemmatising) und <strong>Stemming</strong>. Das ist notwendig, um z.B. einen Text besser kategorisieren bzw. mit Stichworten versehen zu können. Eines der wichtigsten Anwendungsgebiete ist sicherlich die Indexierung von Dokumenten durch eine Suchmaschine. Ein ganz einfaches Beispiel: Enthält ein Dokument sehr oft das Wort <em>Häuser</em> und der Nutzer sucht nach dem Begriff <em>Haus</em>, wird das relevante Dokument wohl nicht in den Suchergebnissen auftauchen.</p>
<p>Um das zu umgehen, müssen flektierte und abgeleitete Wörter zu Ihrer Grundform zurückgeführt werden. Beim <strong>Stemming</strong> werden dazu einfache heuritische Methoden angewendet, bei dem das Suffix der Wörter entfernt wird. Aus dem Wort <em>Katzen</em> wird so dessen Grundform <em>Katze</em>. Bei der Plural-Form <em>Häuser</em> ist das etwas schwieriger. Mit dem Abschneiden des Suffixes kommt man hier nicht weit, weshalb man sich bei der <strong>Lemmatisierung</strong> an Listen bzw. Datenbanken orientiert, die die reflektierte Formen enthalten und so eine sichere Verknüpfung von <em>Häuser</em> zur Singular-Form <em>Haus</em> erlauben.</p>
<p>Soviel zur Theorie. In der Praxis gibt es <strong>Python</strong> und eine Vielzahl von Modulen, die einem eine Menge Arbeit abnehmen. Im Folgenden vergleiche ich ein halbes Dutzend Module, die die <strong>Lemmatisierung</strong> und das <strong>Stemming</strong> beherrschen und auch für <strong>Deutsche Texte</strong> anwendbar sind.</p>
<p><em>Hinweis: Zur Vorbereitung beim Text Mining gehören natürlich auch das Säubern des Textes, Entfernen von Stop-Wörtern und das <strong>Tokenizing</strong>, also Aufbrechen eines Satzes in seine einzelnen Bestandteile. Diesen Schritt überspringe ich hier.</em></p>
<h2 id="stemming-mit-porter-lancaster-und-snowball">Stemming mit Porter, Lancaster und Snowball</h2>
<p>Für das Stemming habe ich mir drei Module angeschaut:</p>
<ul>
<li>Porter Stemmer</li>
<li>Lancaster Stemmer</li>
<li>Snowball Stemmer</li>
</ul>
<p>Der <strong>Porter Stemmer</strong> wurde bereits 1979 von <strong>Martin F. Porter</strong> entwickelt und <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">gilt zumindest in der englischen Sprache als sehr effektiv</a>. Der <strong>Lancaster Stammer</strong> geht auf den Ende der 1980er Jahre an der Lancaster University von <strong>Chris Paice</strong> und <strong>Gareth Husk</strong> entwickelten Paice-Husk Stemming Algorithmus zurück. Im Gegensatz zum festen Regelsatz von Porter wird <a href="https://www.scientificpsychic.com/paice/paice.html">beim Lancaster mit externen Regeln gearbeitet</a>, womit der Algorithmus flexibler ist.</p>
<p>Der Snowball Stemmer ist eigentlich kein eigener Algorithmus, <a href="https://www.datacamp.com/community/tutorials/stemming-lemmatization-python">sondern eine Sprache</a>, um einen eigenen Stemmer zu schreiben.</p>
<h3 id="installation-und-anwendung">Installation und Anwendung</h3>
<p>Alle drei Module sind Bestandteil des <a href="https://www.nltk.org/">Natural Language Toolkit</a> und können dementsprechend sehr unkompliziert mit <strong>pip install nltk</strong> installiert werden. Danach sieht ein Anwendungsbeispiel folgendermaßen aus:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln"> 1</span><span class="cl"> from nltk.stem import PorterStemmer
</span></span><span class="line"><span class="ln"> 2</span><span class="cl"> from nltk.stem import LancasterStemmer
</span></span><span class="line"><span class="ln"> 3</span><span class="cl"> from nltk.stem.snowball import SnowballStemmer
</span></span><span class="line"><span class="ln"> 4</span><span class="cl"> 
</span></span><span class="line"><span class="ln"> 5</span><span class="cl"> porter = PorterStemmer()
</span></span><span class="line"><span class="ln"> 6</span><span class="cl"> lancaster = LancasterStemmer()
</span></span><span class="line"><span class="ln"> 7</span><span class="cl"> snowball = SnowballStemmer(&#34;german&#34;)
</span></span><span class="line"><span class="ln"> 8</span><span class="cl"> 
</span></span><span class="line"><span class="ln"> 9</span><span class="cl"> word = &#39;Katzen&#39;
</span></span><span class="line"><span class="ln">10</span><span class="cl"> 
</span></span><span class="line"><span class="ln">11</span><span class="cl"> print (&#39;Porter: &#39; + porter.stem(word))
</span></span><span class="line"><span class="ln">12</span><span class="cl"> print (&#39;Lancaster: &#39; + lancaster.stem(word))
</span></span><span class="line"><span class="ln">13</span><span class="cl"> print (&#39;Snowball: &#39; + snowball.stem(word))
</span></span></code></pre></div><p>Da Snowball mehrere Sprachen unterstützt, muss hier vorher festgelegt werden, mit welcher Sprache wir arbeiten. Der Rest ist eigentlich ziemlich straight forward. Das Ergebnis zeigt aber die Schwächen des Stemmings:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Porter: katzen 
</span></span><span class="line"><span class="ln">2</span><span class="cl">Lancaster: katz 
</span></span><span class="line"><span class="ln">3</span><span class="cl">Snowball: katz 
</span></span></code></pre></div><p>Keiner der Stemmer kommt auf <em>Katze</em>. Klar: Hier werden einfach nur ein paar Buchstaben abgeschnitten. Da Porter nicht für die deutsche Sprache ausgelegt ist, wird hier sogar die reflektierte Form zurückgegeben. Das Stemming kann also dabei helfen, reflektierte Wörter auf einen gemeinsamen Stamm zu reduzieren. Die Bedeutung geht dabei aber oft verloren.</p>
<p>Genau deshalb gibt es die <strong>Lemmatisierung</strong>&hellip;</p>
<h2 id="lemmatisieren-mit-hannovertagger-wordnet-spacy-und-iwnlp">Lemmatisieren mit HannoverTagger, WordNet, Spacy und IWNLP</h2>
<p>Für die Lemmatisierung habe ich vier Module herausgesucht. Vor allem <a href="https://www.machinelearningplus.com/nlp/lemmatization-examples-python/">für die englische Sprache ist die Auswahl aber weitaus größer</a>, für deutsche Texte ist es hingegen schwierig, aktuelle und gepflegte Module zu finden.</p>
<ul>
<li>WordNet</li>
<li>SpaCy</li>
<li>HannoverTagger</li>
<li>IWNLP</li>
</ul>
<p>Das <strong>WordNet</strong> Modul gehört ebenfalls zum NLTK und ist einer der am weitesten verbreiteten Lemmatiser. Das Modul wurde 2001 entwickelt; <strong>WordNet</strong> selber ist eine riesige lexikalische Datenbank, die seit 1985 an der <strong>Princeton University</strong> entwickelt wird und mittlerweile über 200 Sprachen unterstützt.</p>
<p><strong>SpaCy</strong> ist vergleichsweise jung (2015) aber mittlerweile auch sehr weit verbreitet. Im Gegensatz zum NLTK, dass eine Vielzahl von Lösungen und Algorithmen mitbringt, konzentriert sich SpaCy auf genau einen Algorithmus, um ein Problem zu lösen und ist damit ein wenig fokussierter als das NLTK. Während das NLTK eher im Forschungsbereich anzutreffen ist, wird SpaCy vornehmlich im produktiven Bereich verwendet.</p>
<p>Der <strong>HannoverTagger</strong>, kurz <strong>HanTa</strong> - <a href="https://www.rki.de/DE/Content/Infekt/EpidBull/Merkblaetter/Ratgeber_Hantaviren.html">nicht zu verwechseln mit dem gleichnamigen Virus</a>, wurde 2019 <a href="https://textmining.wp.hs-hannover.de/Preprocessing.html">an der Hochschule Hannover</a> entwickelt. HanTa wurde mit dem Ziel entwickelt, auch für deutsche Texte eine vernünftige Lemmatisierungs-Lösung zu besitzen.</p>
<p>Daneben gibt es noch <a href="https://github.com/Liebeck/spacy-iwnlp">IWNLP</a> von <strong>Matthias Liebeck</strong>. IWNLP ist der Name der entsprechenden SpaCy-Erweiterung für <a href="https://github.com/Liebeck/iwnlp-py">IWNLP-py</a>, was wiederum die Python-Implementierung von IWNLP ist: <strong>Inverse Wiktionary for Natural Language Processing</strong>. IWNLP nutzt zur Lemmatisierung einfach den Deutschen Bereich des Wiktionaries.</p>
<h3 id="was-ist-mit-germalemma-und-german-lemmatizer">Was ist mit GermaLemma und German Lemmatizer?</h3>
<p><strong><a href="https://github.com/WZBSocialScienceCenter/germalemma">GermaLemma</a></strong> ist ein weiteres, recht junges Modul von <strong>Markus Konrad</strong>, das aber leider die <strong>POS</strong> der Wörter erfordert. POS steht für <strong>Part-Of-Speech</strong>, also die Wortart, wie z.B. Substantiv, Verb, Adjektiv und so weiter. Da alle anderen Lemmatizer ohne die POS arbeiten und ich die einfachste Lösung gesucht habe, bleibt dieses Modul außen vor.</p>
<p>Eine weitere Lösung wäre <a href="https://pypi.org/project/german-lemmatizer/">Docker-Image</a> mit dem Namen <strong>German Lemmatizer</strong> gewesen, dass die Funktionen von <strong>INWLP</strong> und <strong>GermaLemma</strong> kombiniert. Das ganze lässt sich aber leider nur mit etwas Mehraufwand auch außerhalb von Docker nutzen, weshalb ich auch den <strong>German Lemmatizer</strong> hier nicht berücksichtigt habe.</p>
<p><strong>WordNet</strong> kann Wörter übrigens ohne POS lemmatisieren, die Ergebnisse sind mit POS aber weitaus genauer. Die Klassifizierung des POS ist freilich keine Raketenwissenschaft und <a href="https://www.machinelearningplus.com/nlp/lemmatization-examples-python/">z.B. hier recht gut beschrieben</a>.</p>
<h3 id="installation-und-anwendung-1">Installation und Anwendung</h3>
<p>Da wir oben schon das NLTK installiert haben, können wir direkt auf WordNet zugreifen. SpaCy installieren wir mit <strong>pip install spacy</strong>, dort wird dann auch gleich IWNLP mitgeliefert. Der HanTa lässt sich ebenfalls unkompliziert installieren: <strong>pip install HanTa</strong>.</p>
<p>Um IWNLP zum Laufen zu bringen, benötigen wir noch <a href="http://lager.cs.uni-duesseldorf.de/NLP/IWNLP/">den letzten Dump von hier</a> (letzter Stand 2018/10/01). Das Archiv enthälte eine JSON-Datei - das Lexikon mit etwa drölfizigtausend Lemmas. Um SpaCy für die deutsche Sprache anwendbar zumachen, <a href="https://spacy.io/models/de/">müssen wir hier ein komplettes Modell herunterladen</a>. Das übernimmt SpaCy für uns mit folgendem Befehl:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="ln">1</span><span class="cl"><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">spacy</span> <span class="n">download</span> <span class="n">de_core_news_md</span>
</span></span></code></pre></div><p><em>(Es gibt drei verschieden große Modelle, ich habe mich für die goldene Mitte entschieden).</em></p>
<p>Die Implementierung ist dann etwas aufwendiger, da bei der Lemmatisierung Trainingsmodelle eingesetzt werden, und nicht nur &ldquo;einfache&rdquo; Algorithmen:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="ln"> 1</span><span class="cl"> <span class="n">from</span> <span class="n">HanTa</span> <span class="n">import</span> <span class="n">HanoverTagger</span> <span class="n">as</span> <span class="n">ht</span>
</span></span><span class="line"><span class="ln"> 2</span><span class="cl"> <span class="n">from</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span> <span class="n">import</span> <span class="n">WordNetLemmatizer</span>
</span></span><span class="line"><span class="ln"> 3</span><span class="cl"> <span class="n">from</span> <span class="n">spacy_iwnlp</span> <span class="n">import</span> <span class="n">spaCyIWNLP</span>
</span></span><span class="line"><span class="ln"> 4</span><span class="cl"> <span class="n">import</span> <span class="n">spacy</span>
</span></span><span class="line"><span class="ln"> 5</span><span class="cl"> 
</span></span><span class="line"><span class="ln"> 6</span><span class="cl"> <span class="n">hannover</span> <span class="o">=</span> <span class="n">ht</span><span class="o">.</span><span class="n">HanoverTagger</span><span class="p">(</span><span class="s1">&#39;morphmodel_ger.pgz&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="ln"> 7</span><span class="cl"> <span class="n">wordnet</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
</span></span><span class="line"><span class="ln"> 8</span><span class="cl"> 
</span></span><span class="line"><span class="ln"> 9</span><span class="cl"> <span class="n">spc</span> <span class="o">=</span>  <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;/usr/local/lib/python3.9/site-packages/de_core_news_md/de_core_news_md-2.3.0&#39;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;parser&#39;</span><span class="p">,</span> <span class="s1">&#39;ner&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="ln">10</span><span class="cl"> 
</span></span><span class="line"><span class="ln">11</span><span class="cl"> <span class="n">iwnlp</span> <span class="o">=</span> <span class="n">spc</span>
</span></span><span class="line"><span class="ln">12</span><span class="cl"> <span class="n">iwnlp_pipe</span> <span class="o">=</span> <span class="n">spaCyIWNLP</span><span class="p">(</span><span class="n">lemmatizer_path</span><span class="o">=</span><span class="s1">&#39;/Users/user1/Downloads/IWNLP.Lemmatizer_20181001.json&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">13</span><span class="cl"> <span class="n">iwnlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="n">iwnlp_pipe</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">14</span><span class="cl"> 
</span></span><span class="line"><span class="ln">15</span><span class="cl"> <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;HanTa:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hannover</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">word</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
</span></span><span class="line"><span class="ln">16</span><span class="cl"> <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Wordnet:&#39;</span> <span class="o">+</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="s1">&#39;NN&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="ln">17</span><span class="cl"> <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;SpaCy:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">spc</span><span class="p">(</span><span class="n">word</span><span class="p">)][</span><span class="mi">0</span><span class="p">]))</span>
</span></span><span class="line"><span class="ln">18</span><span class="cl"> <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;IWNLP:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">iwnlp</span><span class="p">(</span><span class="n">word</span><span class="p">)][</span><span class="mi">0</span><span class="p">]))</span>
</span></span></code></pre></div><p>Dem HannoverTagger wird bei der Initialisierung das entsprechende Modell mitgegeben. WordNet benötigt keine weiteren Parameter. Der <strong>SpaCy-Lemmatiser</strong> (hier spc) wird mit dem deutschen News Paket über <em>spacy.load()</em> initialisiert. Alternativ funktioniert die Initialisierung auch über den Shortcut <em>de</em>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="ln">1</span><span class="cl"> <span class="n">spc</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;de&#39;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;parser&#39;</span><span class="p">,</span> <span class="s1">&#39;ner&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>Um den Vorgang etwas zu beschleunigen, deaktivieren wir die Funktionen <em>parser</em> und <em>ner</em>. Der Parser macht bei der Verarbeitung von Sätzen Sinn, <em>ner</em> steht für <strong>Name Entity Recognition</strong>, sprich die Erkennung von Eigennamen. Das ist bei der Lemmatisierung durchaus wichtig, möchte ich hier aber erstmal nicht berücksichtigen.</p>
<p>Da <strong>IWNLP</strong> ebenfalls über SpaCy aktiviert wird, klonen wir das Objekt einfach und fügen dann unsere eigene Pipeline hinzu <em>add_pipe()</em>. Diese muss auf das Lexikon als JSON-Datei verweisen, den wir vorher heruntergeladen haben. Das wars auch schon, danach sehen wir, wie sich die Module untereinander und im Vergleich zum Stemming schlagen:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">HanTa:Katze 
</span></span><span class="line"><span class="ln">2</span><span class="cl">Wordnet:Katzen
</span></span><span class="line"><span class="ln">3</span><span class="cl">SpaCy:Katze
</span></span><span class="line"><span class="ln">4</span><span class="cl">IWNLP:Katze 
</span></span></code></pre></div><p>Das Ergebnis überrascht nur ein kleines bisschen: Obwohl die eigentliche WordNet-Datenbank 200 Sprachen unterstützt, schafft es das Modul nicht, das richtige Lemma zuzuordnen. Ich finde leider auch keine Informationen dazu, wie WordNet auf Deutsch getrimmt werden kann. Die Ergebnisse von HanTa, SpaCy und IWNLP passen allerdings. IWNLP (und demnach auch SpaCy) liefern bei Bedarf übrigens mehr als nur ein Lemma zurück:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl"> print (str([token._.iwnlp_lemmas for token in iwnlp(word)][0]))
</span></span><span class="line"><span class="ln">2</span><span class="cl"> print (str([token.pos_ for token in iwnlp(word)][0]))
</span></span></code></pre></div><p>Mit <strong>pos_</strong> und <strong>_.iwnlp_lemmas</strong> bekommt man einerseits den Part-Of-Speech und in IWNLP sogar eine Liste aller denkbaren Lemmas - sofern zutreffend.</p>
<p>Wer den Vergleich etwas hübscher aufbereitet für mehrer Wörter nutzen will, <a href="https://gist.github.com/nickyreinert/72548ce88d812f9203687ece93c608d8">kann dazu folgendes Jupyter-Notebook nutzen</a>. Ich hab das ganze mal <a href="https://www.spiegel.de/wissenschaft/mensch/uno-bericht-ueber-klimaziele-auf-dem-weg-zu-drei-grad-erderwaermung-a-05ecdcdb-2f84-4aa0-84b6-a7a2d8c71c80">für eine beliebige Schlagzeile von Spiegel Online</a> durchgespielt und folgendes Ergebnis erhalten. Der Original-Satz lautet:</p>
<blockquote>
<p>Der weltweite CO₂-Ausstoß steigt weiter – trotz Corona-Knick, heißt es im neuen Bericht des Uno-Umweltprogramms. Ohne grüne Konjunkturpakete sei das Pariser Zwei-Grad-Limit nicht mehr zu retten.</p></blockquote>
<p>Und das ist das Ergebnis nach dem <strong>Steming</strong> und <strong>Lemmatisieren</strong>:</p>
<p><a href="https://www.nickyreinert.de/files/eine-kleine-einfuhrung-in-das-stemming-lemmatisieren-deutscher-texte/grafik.png"><img src="/2020/2020-12-09-einfuehrung-in-stemming-und-lemmatisierung-deutscher-texte-mit-python/images/grafik-700x249.png" alt=""></a></p>
<p>7 Methoden zum Stemming und Lemmatisieren im Vergleich</p>
<p>Das Stemming liefert, naturgemäß, ein relativ grobes Ergebnis ab. Um die Wörter in einem Text schnell zu kategorisieren reicht das sicherlich aus. Bei der Lemmatisierung fällt auf, das SpaCy trotz deutscher Sprachpakete nicht ganz zufriedenstellend arbeitet. So wird aus &ldquo;das&rdquo; z.B. &ldquo;der&rdquo;. Dafür wird &ldquo;trotz&rdquo; korrekt &ldquo;trotzen&rdquo; zugeordenet - was dem HanTa nicht gelingt. HanTa wiederum kennt als einziger den Singular von Konjunkturpakete.</p>
<h2 id="fazit">Fazit</h2>
<p>Die Verarbeitung englischer Texte ist, aufgrund der großen Verbreitung der Sprache, gar kein Problem. Bei deutschen Texten wird es schon etwas schwieriger, allerdings liefern <strong>HanTa</strong>, <strong>IWNLP</strong> und auch <strong>SpaCy</strong> recht gute Ergebnisse ab. Mein subjektiver Favorit ist <strong>HanTa</strong>. Aber die Stichprobe ist viel zu gering, um hier einen klaren Favoriten identifizieren zu können.</p>
<p>Der Vergleich dient eher nicht als repräsentivate Untersuchung aller denkbaren Varianten, soll aber einen kleinen Einblick in <strong>NLP</strong> und die automatisierte Text-Verarbeitung im <strong>Text-Mining</strong> geben und ein paar Code-Beispiele liefern, um den Einsteig in Python zu erleichtern. Ich hoffe das ist gelungen!</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>blog</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Einführung in Stemming und Lemmatisierung deutscher Texte mit Python - Project</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Fefes Blog - Eine Analyse</title>
      <link>http://localhost:1313/2019/2019-11-05-fefes-blog-eine-analyse/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2019/2019-11-05-fefes-blog-eine-analyse/</guid>
      <description>Nach der gar nicht mal so großen öffentlichen Wahrnehmung meiner laienhaften statistischen Analyse des Flirtportals der BVG &ldquo;Augenblicke&rdquo;, habe ich …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Nach der gar nicht mal so großen öffentlichen Wahrnehmung meiner laienhaften [statistischen Analyse des Flirtportals der BVG &#39;Augenblicke&#39;](https://www.nickyreinert.de/augenblicke-eine-statistische-an.</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Mac, Git, Server, Mobile, Ai</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Nach der gar nicht mal so großen öffentlichen Wahrnehmung meiner laienhaften <a href="https://www.nickyreinert.de/augenblicke-eine-statistische-analyse-des-flirt-portals-der-bvg/">statistischen Analyse des Flirtportals der BVG &ldquo;Augenblicke&rdquo;</a>, habe ich mich mal einem anderem Projekt gewidmet. Es geht um <a href="http://blog.fefe.de">Fefes Blog</a>, einer meiner ersten Anlaufstellen, wenn ich mir die tägliche Nachrichtendosis gebe. Inspiriert wurde ich dazu durch eine <a href="https://www.netaction.de/datenvisualisierung-von-fefes-blogzeiten/">Analyse der Blogzeiten von Fefe</a>, die allerdings schon acht Jahre zurück liegt.<br>
Für meine Analyse des BVG-Portal hatte ich damals noch PHP gewählt, um die Seiten auszulesen und in eine Datenbank zu hauen. Das war ziemlich aufwendig. Diesmal wollte ich es mit Python probieren und damit auch gleich mein erstes Projekt in dieser Sprache realisieren (der Quellcode steht <a href="https://github.com/nickyreinert/fefeScrape">auf Github</a> zur Verfügung).</p>
<p>Die ersten Schritte mit Python waren etwas holprig. Mit der Zeit zeigt sich aber, dass das Scraping hier weitaus bequemer ist als mit PHP. Außerdem ist Fefes Blog eine ziemlich angenehme Datenquelle, da Fefe seit Anbeginn auf eine wirklich saubere und konsistente Seitenstruktur setzt. Pures HTML. Es ist ein Traum. Danke, Fefe. Ein paar Hintergründe zur Datenerfassung gibt es am Ende.</p>
<h2 id="auswertung">Auswertung</h2>
<p>Insgesamt habe ich 43.908 Einträge im Zeitraum von Ende März 2005 bis Anfang November 2019 ausgewertet. Nach meiner Zählung hat Fefe einen sehr reichen Wortschatz: ich konnte 141.048 verschiedene &ldquo;Wörter&rdquo; ausfindig machen. Außerdem verweißt Fefe auf 8.862 externe Quellen. Auf sich selber hat Fefe innerhalb des Zeitraums 2.661 mal verlinkt. Auch wenn Fefe den Spiegel oft als &ldquo;ehemaliges Nachrichtenmagazin&rdquo; bezeichnet: Der Spiegel ist mit 4.447 Verlinkungen die meist genutzt Quelle, gefolgt von heise.de (3.252). Man muss aber auch eingestehen, dass die Verlinkung zum Spiegel seit 2010 stark abnimmt.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/fefe_words-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/fefe_words-1-700x339.png" alt="Fefes Quellen - Spiegel Online, Heise und… er selbst ;)"></a></p>
<p>Fefes Quellen - Spiegel Online, Heise und&hellip; er selbst ;)</p>
<p>Insgesamt kann man einen Abwärtstrend der Nachrichtenfrequenz bei Fefe feststellen. Seinen Höhepunkt hatte Fefe gleich zu Beginn: Im Juli 2005 gab es 528 Einträge. Den zweiten Höhepunkt erreichte Fefes Blog knapp 10 Jahre später. Im April 2015 gab es 440 Einträge. Ansonsten zeigt der Trend leider nach unten. Im Schnitt gibt es jeden Monat 244 Beiträge (Median 238). Für November 2019 sagt das Prognosemodul von Tableau übrigens 182 Einträge voraus.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/monthly.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/monthly-700x361.png" alt="Anzahl der Einträge pro Monat im Jahresverlauf"></a></p>
<p>Anzahl der Einträge pro Monat im Jahresverlauf</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/blogging-times.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/blogging-times-62x300.png" alt="Anzahl der Nachrichten je Tageszeit im Jahresverlauf"></a></p>
<p>Anzahl der Nachrichten je Tageszeit im Jahresverlauf</p>
<p>In Anlehnung an mein Vorbild, habe ich mir natürlich auch angeschaut, zu welcher Tagszeit Fefe aktiv ist. Zunächst erkennt man, dass Fefe bevorzugt nachmittags aktiv ist. Aber scheinbar gibt es auch hier saisonale Unterschiede. So ist er im Januar bis Juli 2006, den März ausgeschlossen, eher ab 17 Uhr aktiv, danach aber wieder über den ganzen Tag verteilt (Nachtstunden ausgeschlossen). Im April und Mai 2007 konzentrieren sich die Nachrichten wieder auf den späten Nachmittag. In den folgenden Jahren, bis 2015, sind es immer wieder die Frühsommer / Frühlingsmonate, in denen sich die Beiträge zu dieser Tageszeit konzentrieren. Entweder ist Fefe ist ein ausgesprochener Frühlingsmensch. Eine andere Erklärung sind Projekte, die in diesen Monaten stattfinden und ein Bloggen erst zum Nachmittag zulassen. Denkbar ist auch, dass Fefe aufgrund seiner (zyklischen?) Reisetätigkeit und dem damit verbundenen Zeitzonenwechsel zu unterschiedlichen Zeiten bloggt.</p>
<p>Kreuzt man den Wochentag mit der Tageszeit, zeigt sich, wann Fefe die meisten Beiträge absetzt. Mittwochs um 17 Uhr. Das Wochenende ist Fefe heilig, die Beitragsfrequenz ist hier sehr niedrig. Auch zu den typischen Nachtzeiten gibt es nur sehr wenige Einträge. Hier gibt es öfter auffällige Konzentrationen, wie z.B. im Frühling 2015, die ich auch auf Zeitzonenwechsel - sprich Reisen - schiebe.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-nachrichten-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-nachrichten-1.png" alt="Anzahl der Nachrichten je Wochentag und Tageszeit"></a></p>
<p>Anzahl der Nachrichten je Wochentag und Tageszeit</p>
<p>Die längsten Nachrichten entstehen übrigens zur Nachtzeit (oder je nach Sichtweise, während den Reisen in andere Zeitzonen). Montags, um 5 Uhr, ist die durchschnittliche Wortzahl am höchsten. Der Median weist dazu übrigens den Sonntag um 2 Uhr nachts aus.</p>
<ul>
<li>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-avg-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-avg-1.png" alt=""></a></p>
<p>Wortanzahl (Mittelwert) je Wochentag und Tageszeit</p>
</li>
<li>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-median-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/wochentag-x-uhrzeit-wortzahl-median-1.png" alt=""></a></p>
<p>Wortanzahl (Median) je Wochentag und Tageszeit</p>
</li>
</ul>
<p>Eine Wortwolke, analog der Wolke der externen Quellen, ist aufgrund der schieren Menge etwas zu aufwendig und hätte auch nur wenig Informationsgehalt, weshalb ich darauf mal verzichte. Hier nur eine Darstellung der häufigsten Wörter, weil es so schön aussieht:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/woerter.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/woerter-700x387.png" alt="Spektakuläre Topliste der verwendeten Wörter"></a></p>
<p>Spektakuläre Topliste der verwendeten Wörter</p>
<p>Was ich allerdings liefern kann, ist eine Liste der Fefe-Kunstwörter, wie z.B. &ldquo;<a href="https://blog.fefe.de/?ts=a27615a6">Notfall-Soforthilfe-Klopapier&rdquo;</a>. Das längste dieser Art ist &ldquo;<a href="https://blog.fefe.de/?ts=b293636b">Webforen-Besserwisser-Klugscheißer-Korinthenkacker-Sockenpuppen-Grabenkriegen</a>&rdquo;. Das folgende Diagramm zeigt die Top 33 der Fef&rsquo;schen Wortschöpfungen:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-700x368.png" alt="Fefes Wortschöpfungen Top 33"></a></p>
<p>Fefes Wortschöpfungen Top 33</p>
<p>Kommen wir zu den Verweisen auf externe Quellen. Der Spiegel (Online) gehört wie gesagt zu den favorisierten Quellen von Fefe. Ansonsten ist Fefe nicht wählerisch, was Quellen angeht. Die Auswahl ist immens. Interessant ist, wie z.B. <em>Twitter</em> seit 2009 immer öfter zu den verlinkten Quellen gehört. Auf <em>The Guardian</em> hingegen wurde von Fefe 2013 zum letzten Mal verwiesen. Auf sich selber verweist Fefe natürlich auch hin und wieder. Am häufigsten in 2008, mit abnemender Tendenz.</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/jahr-quellen-ab-50.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/jahr-quellen-ab-50-700x391.png" alt="Verwendete Quellen / Domains"></a></p>
<p>Verwendete Quellen / Domains</p>
<h2 id="fazit">Fazit</h2>
<p>Und was ist jetzt Fefes WLAN-Passwort? Wir wissen es nicht. Und wir werden es auch nicht erfahren, wenn wir seinen Blog noch drölf mal parsen. Vielleicht sind die zahlreichen zusammengesetzen Substantive als Indiz hilfreich? Egal.</p>
<p>Also gibt es kein Fazit, mit Ausnahme der Feststellung, dass es zeitliche Muster gibt, Fefe ein außerordentliche fleißiger Autor ist aber sonst, leider, die Tendenz der Nachrichtenanzahl in den letzten Jahren zurück gegangen ist.</p>
<h2 id="fehlerquellen-und-technische-hintergründe">Fehlerquellen und technische Hintergründe</h2>
<p>Auch wenn der HTML-Code sehr aufgeräumt ist, vor Fehlern ist auch Fefe nicht gefeit. So gibt es zum Beispiel 110 nicht bzw. falsch geschlossene <A>-Tags. Hier musste ich per Script stumpf ein schließendes </a> setzen, was die Auswertung der Quellen / Domains ein wenig, aber kaum merklich, verfälscht.</p>
<p>Auch bei den Wörtern musste ich etwas aufräumen, um so z.B. alle möglichen Nicht-Buchstaben entfernen. Danach musste ich die Liste noch ein wenig von Hand sortieren, un so z.B. ein paar verirrte URL zu entfernen.</p>
<p>Die verlinkten Quellen war recht einfach zu handhaben. Hier habe ich lediglich die Präfixe entfernt, wenn diese mit www und ggf. einer Ziffer beginnen. Trotzdem muss bei dieser Liste berücksichtigt werden, dass manche Quellen über mehrere Domains erreichbar sind. So verweist Fefe z.B. auf das Angebot der BBC mit zehn verschiedenen Varianten:</p>
<p><a href="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-1.png"><img src="/2019/2019-11-05-fefes-blog-eine-analyse/images/grafik-1-700x341.png" alt="Varianten für den Verweis zur BBC"></a></p>
<p>Varianten für den Verweis zur BBC</p>
<p>Der Fefe-Timestamp ist eine Geschichte für sich. Alleine wäre ich vermutlich kaum auf die Idee gekommen, dass hinter der eindeutigen Id, mit der jeder Beitrag erreichbar ist, tatsächlich eine Zeitangabe steckt. <a href="https://www.netaction.de/datenvisualisierung-von-fefes-blogzeiten/">Meine Inspirationsvorlage</a> hat hier zum Glück sehr gute Vorarbeit geleistet und erklärt, wie sich der alphanumerische Wert in ein lesbares Datum umwandeln lässt. Es handelt sich bei dem Wert nämlich um einen Hexadezimalangabe, die zunächst in eine Dezimalziffer umgewandelt werden muss. Danach erfolgt eine bitweise XOR-Operation um einen bestimmten Schlüssel: <strong>0xFEFEC0DE</strong>. Das ergibt schließlich einen Unix-Zeitstempel, der sich in ein lesbares Datum umwandeln lässt.</p>
<p>Zuletzt noch ein Hinweis zu den Daten aus den Anfangszeiten, also März bis Juni 2005. Vermutlich hat Fefe diese nachträglich eingefügt, da dort der Zeitstempel jeweils auf 12 bis 13 Uhr zeigt. Diese Monate habe ich aus den Analysen mit den Tageszeiten ausgeschlossen.</p>
<p>Zuletzt noch ein Hinweis zu den verwendeten Tools:</p>
<p>Einerseits nutze ich für die Auswertung und Darstellung <a href="https://public.tableau.com/en-us/s/">Tableau Public</a>, dass es auch als kostenlose Variante gibt. Für die Wordcloud nutze ich <a href="http://www.wordle.net/">Wordle</a>. Wordle gab es eine zeitlang nur als WebApp, mittlerweile läuft Wordle aber auch als native OSX- oder Windows-Anwendung. Das Python-Script habe ich mit <a href="https://code.visualstudio.com/">Visual Studio Code</a> geschrieben, das im Begriff ist, Notepad++ als Allround-IDE abzulösen. Und mit Excel habe ich die Daten etwas bereinigt, das klappt damit immer noch fixer als mit Tableau.</p>
<h2 id="update">UPDATE</h2>
<p>Durch Zufall bin ich eben noch auf <a href="https://weltliteratur.net/Fefe-Research-Institute/">eine etwas tiefere Textanalyse</a> gestoßen, die auch sehr interessant ist.</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>blog</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Fefes Blog - Eine Analyse - Project</media:title>
      </media:content>
      
      
      
      
      <dc:subject>Lesezeit: 8 Minuten</dc:subject>
      
      
      
      <dc:type>project</dc:type>
      
      
    </item><item>
      <title>Mehrere virtuelle Server mit nginx und PHP-FPM für Wordpress (Teil 1 / 3)</title>
      <link>http://localhost:1313/2019/2019-04-12-mehrere-virtuelle-server-mit-nginx-und-php-fpm-fur-wordpress-teil-1-3/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2019/2019-04-12-mehrere-virtuelle-server-mit-nginx-und-php-fpm-fur-wordpress-teil-1-3/</guid>
      <description>Bisher war ich immer recht zufrieden mit der Geschwindigkeit meiner selbstgehosteten Wordpress-Seiten. Im Schnitt hat es nicht länger als 2 Sekunden gedauert, …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Bisher war ich immer recht zufrieden mit der Geschwindigkeit meiner selbstgehosteten Wordpress-Seiten. Im Schnitt hat es nicht länger als 2 Sekunden gedauert, bis die Inhalte aufgebaut waren.&#39; reading_time: 16 content_type: &#39;analysis</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Wordpress, Mac, Git, Database, Server</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Bisher war ich immer recht zufrieden mit der Geschwindigkeit meiner selbstgehosteten Wordpress-Seiten. Im Schnitt hat es nicht länger als 2 Sekunden gedauert, bis die Inhalte aufgebaut waren. Mal mehr, mal weniger. Und das schien mir ein akzeptabler Wert zu sein. Ich nutzte eine der üblichen Standard-Installationen, die da draußen wohl weit verbreitet ist: <strong>Apache2</strong> mit <strong>mod_php</strong>. Der PHP-Interpreter ist dabei &ldquo;Teil&rdquo; des Apache2-Servers. Das ist unkompliziert und schnell zu installieren und somit einfach eine pragmatische Lösung und auch deshalb wohl sehr weit verbreitet. Aber: Die einfachsten Lösungen sind oft nicht die besten. Geschweige denn, die sichersten.</p>
<h2 id="ziel">Ziel</h2>
<p>Um es kurz zu machen: Das Ziel ist es, einen sicheren und schnellen Web-Server mit <strong>Nginx</strong>, <strong>PHP-FPM</strong> und <strong>chroot</strong> aufzusetzen, mit dem sich mehrere getrennte Webseiten betreiben lassen. Um der Sache einen Zweck zu geben, werde ich mich im Folgenden an Wordpress orientieren.</p>
<p><strong>Warum chroot?</strong> Wenn sich mehrere Wordpress-Installationen einen (virtuellen) Server teilen, ist es fast schon fahrlässig diese einfach in ein paar Unterordner zu packen und die Domains darauf zeigen zu lassen. Wird eine Wordpress-Installation kompromittiert, ist es für den Angreifer nicht sonderlich schwer, sich im gesamten System zu auszubrreiten. Mit <strong>chroot</strong> sorge ich dafür, dass jede Wordpress-Instanz sich nur in ihrem eigenen Verzeichnis bewegen kann. Das ist in etwa zu vergleichen mit der PHP-Direktive <strong>open_basedir</strong> aber noch etwas restriktiver.</p>
<p><strong>Warum PHP-FPM?</strong> Weil es sicherer und schneller ist und weil <strong>mod_php</strong> nur unter Apache2 funktioniert. Hier stand anfangs auch <strong>FastCGI</strong> zur Wahl.  CGI bedeutet Common Gateway Interface. Mit dieser Schnittstelle können Anfragen über einen Port oder einen Datei-Socket an den PHP-Interpreter weitergeleitet werden, der dazu aber immer wieder komplett neu gestartet wird. Bei <strong>FastCGI</strong>, einer Weiterentwicklung, wird der Interpreter nicht jedes mal neu gestartet, sondern läuft permanent im Hintergrund.</p>
<p>Und <strong>FPM</strong> schließlich steht für <strong>FastCGI Process Manager</strong>, eine weitere Weiterentwicklung. Ein Neuerung ist unter anderem, dass nun mehrere PHP-Interpreter im Hintergrund laufen. Einen tieferen Überblick über die Grundlagen und Unterschiede <a href="https://www.admin-magazin.de/Das-Heft/2012/06/Der-PHP-Interpreter-PHP-FPM">bietet dieser Artikel</a>.</p>
<p><strong>Und warum nginx?</strong> Meine Seite ist nicht der größte Krümel auf dem Kuchenblech, weshalb die Performance-Vorteile vielleicht kaum ins Gewicht fallen. Dennoch: <strong>Nginx</strong> ist leichtfüßiger als der mit allen möglichen Paketen ausgestattete Apache. Außerdem hatte ich bisher frustriert versucht, <strong>PHP-FPM</strong> mit <strong>chroot</strong> unter Apache zum Laufen zu bringen. Ohne Erfolg.</p>
<p>Und den Zahn muss ich allen nginx-Kritikern gleich einmal ziehen: <strong>nginx ist nicht komplizierter zu bedienen als Apache</strong>. Wer sich bisher für Apache durch die Config-Dateien gewühlt hat, bekommt das locker auch mit nginx hin. Beide Server nehmen sich in Punkte Komplexität, Community und Dokumentation aus meiner Sicht nichts.</p>
<p>Da das ganz jetzt schon ziemlich umfangreich ist, ich den Beitrag in zwei Teile getrennt. Viel Spass beim Lesen.</p>
<h2 id="installation">Installation</h2>
<p>Alles beginnt mit einem apt für <strong>nginx</strong> und zwei wichtigen Helfern:</p>
<p>apt install nginx nscd python-certbot-nginx</p>
<p><strong>Nscd</strong> steht für Name Service Cache Daemon und dient dazu, DNS-Anfragen auch im chroot zu ermöglichen, gleichzeitig anhand eines internen Caches aber auch zu beschleunigen. Die genauen Hintergründe <a href="https://blog.kthx.at/2015/09/23/php-fpm-chroot">sind hier beschrieben</a>. Außerdem nutze ich die SSL-Zertifikate von <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a>, da diese kostenlos sind und sich die Re-Zertifizierung außerdem bequem automatisieren lässt. Ich muss also den entsprechenden <strong>certbot</strong> für <strong>nginx</strong> installieren.</p>
<h2 id="ordnerstruktur">Ordnerstruktur</h2>
<p>Chroot (<em>change root</em>) bedeutet, dass einem Prozess (sprich: der entsprechend konfigurierten Website) ein eigenes Root-Verzeichnis <em>vorgegaugelt</em> wird. Das ist sehr sinnvoll, weil der Prozess so nicht auf die gesamte Partition zugreifen kann. Das erschwert die Sache allerdings auch, da ihm wichtige Systemfunktionen zur Verfügung gestellt werden müssen, die sich sonst irgendwo auf der Partition befinden. Die Lösung dafür lautet <em>mount</em>. Grundsätzlich forderte chroot mir bei der Konfiguration sämtlicher Pfade etwas mehr Konzentration ab, da das Root-Verzeichnis nun nicht mehr unter / sondern z.B. unter /var/www/nickyreinert/ liegt.</p>
<p>Jede Website bekommt grundsätzlich erstmal ein eigenes Verzeichnis, in dem sich jedoch nun nicht nur - wie gewohnt - die Ressourcen der Webseite befinden. Hier werden System-Funktionen, Sockets etc. eingebunden, die PHP und nginx für die einwandfreie Funktion benötigen. Die Ordner-Struktur sieht also folgendermaßen aus:</p>
<p>/ &lt;- tatsächlicher root-Ordner des Systems
/var
/var/www
/var/www/nickyreinert_de &lt;- root-Ordner für diese Website
- cache
- data
- dev
- etc
- htdocs
- logs
- sessions
- tmp
- usr
- var
/var/www/foobar_de &lt;- root-Ordner für eine andere Website
- &hellip;</p>
<p><strong>Htdocs</strong>, <strong>logs</strong>, <strong>tmp</strong> und <strong>sessions</strong> sind fester und individueller Bestandteil des Ordners. Alle anderen sind Verweise auf die tatsächlichen System-Order und werden daher per mount <strong>lesend</strong> eingebunden.</p>
<p>Um die Ordner und die fixen Bestandteile einmal initial anzulegen, nutze ich folgendes Script. Als erster Parameter wird der Name der Website erwartet.</p>
<p>#!/bin/sh
cd /var/www/
mkdir $1
cd $1
mkdir -p htdocs logs tmp sessions cache
chown root:sudo htdocs
chown $1:www-data logs
chown $1:www-data sessions
chmod 700 sessions</p>
<p>Um nun noch das das mounten zu erleichtern, nutze ich <a href="https://blog.kthx.at/2015/09/23/php-fpm-chroot">das Init-Script von kthx.at</a>, das ich noch etwas angepasst habe (Unterstützung für <em>sendmail</em> und <em>php-gettext</em>):</p>
<p>#!/bin/bash</p>
<h3 id="begin-init-info">BEGIN INIT INFO</h3>
<h1 id="provides----------php5-fpm-chroot-setup">Provides:          php5-fpm-chroot-setup</h1>
<h1 id="required-start----nscd">Required-Start:    nscd</h1>
<h1 id="required-stop">Required-Stop:</h1>
<h1 id="default-start-----2-3-4-5">Default-Start:     2 3 4 5</h1>
<h1 id="default-stop------0-1-6">Default-Stop:      0 1 6</h1>
<h1 id="short-description-mounts-needed-sockets-and-other-data-into-a-previously-set-up-chroot-environment">Short-Description: Mounts needed sockets and other data into a previously set up chroot environment.</h1>
<h3 id="end-init-info">END INIT INFO</h3>
<h1 id="hier-die-dateien-und-ordner-die-in-die-chroot-umgebung-gemountet-werden-sollen">Hier die Dateien und Ordner die in die Chroot-Umgebung gemountet werden sollen</h1>
<p>CHROOT_FILES=&quot;/usr/lib/sendmail /etc/hosts /etc/resolv.conf /etc/ssl/certs /usr/share/ca-certificates /dev/null /dev/random /dev/urandom /dev/zero /var/run/mysqld /var/run/nscd /usr/share/zoneinfo /usr/share/php/php-gettext&quot;</p>
<h1 id="siehe-unten">siehe unten!</h1>
<p>CACHE_FOLDER=&quot;/var/run/nginx/_SERVER_&quot;</p>
<p>case &ldquo;$1&rdquo; in
restart|force-reload|start)
# Aufräumen bevor wir aufbauen
$0 stop 2&gt;/dev/null</p>
<h1 id="0-stop">$0 stop</h1>
<pre><code>    for chrootdir in /var/nginx/\*; do
        # Nur in Ordnern mit eigenem /tmp Verzeichnis als Markierung einen Chroot aufsetzen
        if \[ -d &quot;${chrootdir}/tmp&quot; \]; then
            # Berechtigungen von /tmp korrigieren
            chmod 777 &quot;${chrootdir}/tmp&quot;
            chmod +t &quot;${chrootdir}/tmp&quot;

            echo &quot;Setting up ${chrootdir}...&quot;
            for f in $CHROOT\_FILES; do
                if \[ -d &quot;$f&quot; \]; then
                    # $f ist ein Pfad zu einem Verzeichnis
                    mkdir -p &quot;${chrootdir}${f}&quot;
                    mount --bind -o ro &quot;${f}&quot; &quot;${chrootdir}${f}&quot;
                else
                    # $f ist ein Pfad zu einer Datei
                    mkdir -p &quot;${chrootdir}$(dirname &quot;${f}&quot;)&quot;
                    touch &quot;${chrootdir}${f}&quot;
                    mount --bind -o ro &quot;${f}&quot; &quot;${chrootdir}${f}&quot;
                fi
            done
            # willst du den Cache-Ordner auf eine existierende RAM-Disk mounten,
            # kommentiere diesen Bereich aus und setze CACHE\_FOLDER auf den 
            # entsprechenden Zielordner
</code></pre>
<h1 id="for-c-in-cache_folder-do">for c in $CACHE_FOLDER; do</h1>
<h1 id="-f-enthält-_server_-was-als-platzhalter-dient"># f enthält _SERVER_, was als Platzhalter dient</h1>
<h1 id="serverbasename-chrootdir">server=$(basename ${chrootdir})</h1>
<h1 id="cc_server_server">c=${c/_SERVER_/$server}</h1>
<h1 id="if----d-c--then">if [ ! -d &ldquo;${c}&rdquo; ]; then</h1>
<h1 id="mkdir--p-c">mkdir -p ${c}</h1>
<h1 id="fi">fi</h1>
<h1 id="echo-setting-up-cache-in-c">echo &ldquo;Setting up cache in $c&rdquo;</h1>
<h1 id="mkdir--p-chrootdircache">mkdir -p &ldquo;${chrootdir}/cache&rdquo;</h1>
<h1 id="mount-bind--o-rw-c-chrootdircache">mount &ndash;bind -o rw &ldquo;${c}&rdquo; &ldquo;${chrootdir}/cache&rdquo;</h1>
<h1></h1>
<h1 id="done">done</h1>
<pre><code>        fi
    done
;;

stop)
    for chrootdir in /var/nginx/\*; do

        if \[ -d &quot;${chrootdir}/tmp&quot; \]; then
            echo &quot;Destructing ${chrootdir}...&quot;
            for f in $CHROOT\_FILES; do
                umount &quot;${chrootdir}${f}&quot;
                if \[ -d &quot;${chrootdir}${f}&quot; \] &amp;&amp; \[ ! $(ls -A &quot;${chrootdir}${f}&quot;) \]; then
                    # Leerer Ordner, kann man löschen
                    rmdir &quot;${chrootdir}${f}&quot;
                elif \[ -f &quot;${chrootdir}${f}&quot; \]; then
                    # Datei, kann man löschen
                    rm &quot;${chrootdir}${f}&quot;
                fi
            done
        fi
    done
;;

\*)
    echo &quot;Usage: $N {start|stop|restart|force-reload}&quot; &gt;&amp;2
    exit 1
;;
</code></pre>
<p>esac</p>
<p>exit 0</p>
<p>Soll das Script bei jedem Systemstart geladen werden, legst du es unter <strong>/etc/init.d/php-fpm-chroot-setup</strong> ab und setzt das Ausführen-Flag (chmod +x). Danach wird es für den Systemstart vorgemerkt:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">update-rc.d php-fpm-chroot-setup defaults
</span></span></code></pre></div><h2 id="die-globale-konfiguration-für-nginx">Die globale Konfiguration für nginx</h2>
<p>Meine <strong>globale Konfiguration</strong> (für gewöhnlich unter <em>/etc/nginx/nginx.conf</em>) für nginx sieht folgendermaßen aus. Die Standard-Parameter von nginx werde ich nicht näher erläutern sondern nur kurz inline kommentieren. Wichtige Anpassungen erkläre ich darunter etwas genauer.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="ln">  1</span><span class="cl"><span class="c1"># in welcher Datei soll die Programm-Id abgelegt werden:</span>
</span></span><span class="line"><span class="ln">  2</span><span class="cl"><span class="n">pid</span> <span class="o">/</span><span class="n">run</span><span class="o">/</span><span class="n">nginx</span><span class="o">.</span><span class="n">pid</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">  3</span><span class="cl"><span class="c1"># der Benutzer, unter dem nginx gestartet wird:</span>
</span></span><span class="line"><span class="ln">  4</span><span class="cl"><span class="n">user</span> <span class="n">www</span><span class="o">-</span><span class="n">data</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">  5</span><span class="cl"><span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln">  6</span><span class="cl"><span class="n">worker_processes</span> <span class="mi">8</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">  7</span><span class="cl">
</span></span><span class="line"><span class="ln">  8</span><span class="cl"><span class="n">events</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln">  9</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln"> 10</span><span class="cl">		<span class="n">worker_connections</span> <span class="mi">768</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 11</span><span class="cl">		<span class="c1"># soll jeder Worker mehr als eine Verbindung gleichzeitig annehmen? Standard: off</span>
</span></span><span class="line"><span class="ln"> 12</span><span class="cl">		<span class="n">multi_accept</span> <span class="n">off</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 13</span><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="ln"> 14</span><span class="cl">
</span></span><span class="line"><span class="ln"> 15</span><span class="cl">
</span></span><span class="line"><span class="ln"> 16</span><span class="cl"><span class="n">http</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln"> 17</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 18</span><span class="cl">		<span class="c1"># Basic Settings</span>
</span></span><span class="line"><span class="ln"> 19</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln"> 20</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 21</span><span class="cl">
</span></span><span class="line"><span class="ln"> 22</span><span class="cl">		<span class="n">sendfile</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 23</span><span class="cl">		<span class="n">tcp_nopush</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 24</span><span class="cl">		<span class="n">tcp_nodelay</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 25</span><span class="cl">
</span></span><span class="line"><span class="ln"> 26</span><span class="cl">		<span class="n">client_body_timeout</span> <span class="mi">12</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 27</span><span class="cl">		<span class="n">client_header_timeout</span> <span class="mi">12</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 28</span><span class="cl">		<span class="n">keepalive_timeout</span> <span class="mi">65</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 29</span><span class="cl">    <span class="n">send_timeout</span> <span class="mi">10</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 30</span><span class="cl">
</span></span><span class="line"><span class="ln"> 31</span><span class="cl">		<span class="n">types_hash_max_size</span> <span class="mi">2048</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 32</span><span class="cl">		<span class="n">server_names_hash_bucket_size</span> <span class="mi">128</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 33</span><span class="cl">    <span class="c1"># server_name_in_redirect off;</span>
</span></span><span class="line"><span class="ln"> 34</span><span class="cl">
</span></span><span class="line"><span class="ln"> 35</span><span class="cl">		<span class="n">limit_req_zone</span> <span class="o">$</span><span class="n">binary_remote_addr</span> <span class="n">zone</span><span class="o">=</span><span class="n">one</span><span class="p">:</span><span class="mi">10</span><span class="n">m</span> <span class="n">rate</span><span class="o">=</span><span class="mi">5</span><span class="n">r</span><span class="o">/</span><span class="n">s</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 36</span><span class="cl">
</span></span><span class="line"><span class="ln"> 37</span><span class="cl">		<span class="n">include</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">mime</span><span class="o">.</span><span class="n">types</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 38</span><span class="cl">		<span class="n">default_type</span> <span class="n">application</span><span class="o">/</span><span class="n">octet</span><span class="o">-</span><span class="n">stream</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 39</span><span class="cl">
</span></span><span class="line"><span class="ln"> 40</span><span class="cl">		<span class="c1"># Verhindere, dass nginx auf Fehlerseiten die Versionsnummer mitliefert</span>
</span></span><span class="line"><span class="ln"> 41</span><span class="cl">		<span class="c1"># Frei nach dem Motto &#34;securtiy through obscurity&#34;</span>
</span></span><span class="line"><span class="ln"> 42</span><span class="cl">		<span class="n">server_tokens</span> <span class="n">off</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 43</span><span class="cl">
</span></span><span class="line"><span class="ln"> 44</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 45</span><span class="cl">		<span class="c1"># Logging Settings</span>
</span></span><span class="line"><span class="ln"> 46</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln"> 47</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 48</span><span class="cl">
</span></span><span class="line"><span class="ln"> 49</span><span class="cl">		<span class="n">log_format</span> <span class="n">cache_status</span> <span class="s1">&#39;[$time_local] &#34;$request&#34;  $upstream_cache_status&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 50</span><span class="cl">
</span></span><span class="line"><span class="ln"> 51</span><span class="cl">		<span class="n">log_format</span> <span class="n">main</span> <span class="s1">&#39;$time_local|$ip_anonymized|$remote_user|&#39;</span>
</span></span><span class="line"><span class="ln"> 52</span><span class="cl">				<span class="s1">&#39;&#34;$request&#34; $status $body_bytes_sent &#39;</span>
</span></span><span class="line"><span class="ln"> 53</span><span class="cl">				<span class="s1">&#39;&#34;$http_referer&#34; &#34;$http_user_agent&#34; $upstream_cache_status&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 54</span><span class="cl">
</span></span><span class="line"><span class="ln"> 55</span><span class="cl">		<span class="n">map</span> <span class="o">$</span><span class="n">remote_addr</span> <span class="o">$</span><span class="n">ip_anonym1</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln"> 56</span><span class="cl">		    <span class="n">default</span> <span class="mf">0.0</span><span class="o">.</span><span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 57</span><span class="cl">		    <span class="s2">&#34;~(?P&lt;ip&gt;(\d+)\.(\d+)\.(\d+))\.\d+&#34;</span> <span class="o">$</span><span class="n">ip</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 58</span><span class="cl">		    <span class="s2">&#34;~(?P&lt;ip&gt;[^:]+:[^:]+):&#34;</span> <span class="o">$</span><span class="n">ip</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 59</span><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="ln"> 60</span><span class="cl">
</span></span><span class="line"><span class="ln"> 61</span><span class="cl">		<span class="n">map</span> <span class="o">$</span><span class="n">remote_addr</span> <span class="o">$</span><span class="n">ip_anonym2</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln"> 62</span><span class="cl">		    <span class="n">default</span> <span class="o">.</span><span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 63</span><span class="cl">		    <span class="s2">&#34;~(?P&lt;ip&gt;(\d+)\.(\d+)\.(\d+))\.\d+&#34;</span> <span class="o">.</span><span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 64</span><span class="cl">		    <span class="s2">&#34;~(?P&lt;ip&gt;[^:]+:[^:]+):&#34;</span> <span class="p">::;</span>
</span></span><span class="line"><span class="ln"> 65</span><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="ln"> 66</span><span class="cl">
</span></span><span class="line"><span class="ln"> 67</span><span class="cl">		<span class="n">map</span> <span class="o">$</span><span class="n">ip_anonym1</span><span class="o">$</span><span class="n">ip_anonym2</span> <span class="o">$</span><span class="n">ip_anonymized</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln"> 68</span><span class="cl">		    <span class="n">default</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 69</span><span class="cl">		    <span class="s2">&#34;~(?P&lt;ip&gt;.*)&#34;</span> <span class="o">$</span><span class="n">ip</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 70</span><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="ln"> 71</span><span class="cl">
</span></span><span class="line"><span class="ln"> 72</span><span class="cl">		<span class="n">map</span> <span class="o">$</span><span class="n">http_ignoreMe</span> <span class="o">$</span><span class="n">log_this</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln"> 73</span><span class="cl">		    <span class="o">~</span><span class="bp">true</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 74</span><span class="cl">		    <span class="n">default</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 75</span><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="ln"> 76</span><span class="cl">
</span></span><span class="line"><span class="ln"> 77</span><span class="cl">		<span class="n">access_log</span> <span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="nb">log</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">access</span><span class="o">.</span><span class="n">log</span> <span class="n">main</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 78</span><span class="cl">		<span class="n">error_log</span> <span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="nb">log</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">error</span><span class="o">.</span><span class="n">log</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 79</span><span class="cl">
</span></span><span class="line"><span class="ln"> 80</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 81</span><span class="cl">		<span class="c1"># SSL Settings</span>
</span></span><span class="line"><span class="ln"> 82</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln"> 83</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 84</span><span class="cl">
</span></span><span class="line"><span class="ln"> 85</span><span class="cl">		<span class="n">ssl_session_cache</span> <span class="n">shared</span><span class="p">:</span><span class="n">SSL</span><span class="p">:</span><span class="mi">5</span><span class="n">m</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 86</span><span class="cl">		<span class="n">ssl_session_timeout</span> <span class="mi">1</span><span class="n">h</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 87</span><span class="cl">		<span class="n">add_header</span> <span class="n">Strict</span><span class="o">-</span><span class="n">Transport</span><span class="o">-</span><span class="n">Security</span> <span class="s2">&#34;max-age=15768000; includeSubDomains&#34;</span> <span class="n">always</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 88</span><span class="cl">
</span></span><span class="line"><span class="ln"> 89</span><span class="cl">		<span class="n">ssl_protocols</span> <span class="n">TLSv1</span> <span class="n">TLSv1</span><span class="o">.</span><span class="mi">1</span> <span class="n">TLSv1</span><span class="o">.</span><span class="mi">2</span><span class="p">;</span> <span class="c1"># Dropping SSLv3, ref: POODLE</span>
</span></span><span class="line"><span class="ln"> 90</span><span class="cl">		<span class="n">ssl_prefer_server_ciphers</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 91</span><span class="cl">	  <span class="n">ssl_ciphers</span> <span class="n">ECDH</span><span class="o">+</span><span class="n">AESGCM</span><span class="p">:</span><span class="n">ECDH</span><span class="o">+</span><span class="n">AES256</span><span class="p">:</span><span class="n">ECDH</span><span class="o">+</span><span class="n">AES128</span><span class="p">:</span><span class="n">DHE</span><span class="o">+</span><span class="n">AES128</span><span class="p">:</span><span class="o">!</span><span class="n">ADH</span><span class="p">:</span><span class="o">!</span><span class="n">AECDH</span><span class="p">:</span><span class="o">!</span><span class="n">MD5</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 92</span><span class="cl">
</span></span><span class="line"><span class="ln"> 93</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln"> 94</span><span class="cl">		<span class="c1"># Cache</span>
</span></span><span class="line"><span class="ln"> 95</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln"> 96</span><span class="cl">		<span class="c1">#</span>
</span></span><span class="line"><span class="ln"> 97</span><span class="cl">
</span></span><span class="line"><span class="ln"> 98</span><span class="cl">		<span class="n">fastcgi_cache_key</span> <span class="s2">&#34;$scheme$request_method$host$request_uri&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="ln"> 99</span><span class="cl">		<span class="n">add_header</span> <span class="n">X</span><span class="o">-</span><span class="n">Cache</span> <span class="o">$</span><span class="n">upstream_cache_status</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">100</span><span class="cl">
</span></span><span class="line"><span class="ln">101</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln">102</span><span class="cl">		<span class="c1"># Gzip Settings</span>
</span></span><span class="line"><span class="ln">103</span><span class="cl">		<span class="c1"># Beschreibung siehe unten</span>
</span></span><span class="line"><span class="ln">104</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln">105</span><span class="cl">
</span></span><span class="line"><span class="ln">106</span><span class="cl">		<span class="n">gzip</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">107</span><span class="cl">		<span class="n">gzip_vary</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">108</span><span class="cl">		<span class="n">gzip_min_length</span> <span class="mi">10240</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">109</span><span class="cl">		<span class="n">gzip_proxied</span> <span class="n">expired</span> <span class="n">no</span><span class="o">-</span><span class="n">cache</span> <span class="n">no</span><span class="o">-</span><span class="n">store</span> <span class="n">private</span> <span class="n">auth</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">110</span><span class="cl">		<span class="n">gzip_types</span> <span class="n">text</span><span class="o">/</span><span class="n">plain</span> <span class="n">text</span><span class="o">/</span><span class="n">css</span> <span class="n">text</span><span class="o">/</span><span class="n">xml</span> <span class="n">text</span><span class="o">/</span><span class="n">javascript</span> <span class="n">application</span><span class="o">/</span><span class="n">x</span><span class="o">-</span><span class="n">javascript</span> <span class="n">application</span><span class="o">/</span><span class="n">xml</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">111</span><span class="cl">		<span class="n">gzip_disable</span> <span class="s2">&#34;MSIE [1-6]\.&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">112</span><span class="cl">
</span></span><span class="line"><span class="ln">113</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln">114</span><span class="cl">		<span class="c1"># Virtual Host Configs</span>
</span></span><span class="line"><span class="ln">115</span><span class="cl">		<span class="c1"># wo befinden sich die Einstellungen für die Server / virtual hosts?</span>
</span></span><span class="line"><span class="ln">116</span><span class="cl">		<span class="c1"># welche Variante du nutzt, ist Geschmackssache und dir überlassen</span>
</span></span><span class="line"><span class="ln">117</span><span class="cl">		<span class="c1">##</span>
</span></span><span class="line"><span class="ln">118</span><span class="cl">
</span></span><span class="line"><span class="ln">119</span><span class="cl">		<span class="n">include</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">conf</span><span class="o">.</span><span class="n">d</span><span class="o">/*.</span><span class="n">conf</span><span class="p">;</span>
</span></span><span class="line"><span class="ln">120</span><span class="cl">	<span class="c1">#	include /etc/nginx/sites-enabled/*.conf;</span>
</span></span><span class="line"><span class="ln">121</span><span class="cl">
</span></span><span class="line"><span class="ln">122</span><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p><a href="https://nginx.org/en/docs/ngx_core_module.html#worker_processes">worker_processes</a> - Natürlich kannst du nginx mit einem einzigen Prozess laufen lassen. Du kannst aber auch dafür sorgen, dass sich mehrere Prozesse um die Beantwortung der Anfragen kümmern. Es empfiehlt sich <strong>für jeden Prozessor-Kern</strong> einen Prozess zu starten. Mit dem Wert &ldquo;auto&rdquo; kümmert sich nginx selber darum. Mit </p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">grep processor /proc/cpuinfo | wc -l
</span></span></code></pre></div><p>findest du heraus, wieviele Kerne dein System hat, um diesen Wert manuell zu setzen.</p>
<p><a href="https://nginx.org/en/docs/ngx_core_module.html#worker_connections">worker_connections</a> - Dieser Wert legt fest, wieviele Anfragen jeder einzelne <em>worker process</em> verarbeiten kann. Hat nginx also 8 simultane <em>worker processes</em> gestartet und ist dieser Wert  auf 1024 eingestellt, wird nginx insgesamt 8.192 Verbindungen gleichzeitig vertragen. Der Wert für diese Direktive wird allerdings durch die Anzahl gleichzeitiger offener Dateien für einen Prozess begrenzt. Diese erfährst du mit <em>ulimit -n</em>.</p>
<p><a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile">sendfile</a>, tcp_nopush und tcp_nodelay - Jetzt geht es ein wenig ans Eingemachte. Diese Parameter können einerseits einen wichtigen Geschwindigkeitsgewinn bedeuten oder völlig sinnlos sein. Da mir aber kein negative Impact bekannt ist, möchte ich an der Stelle pauschal erwähnen, diesen Parameter zu aktivieren. Wenn ich mich hier irre, lasst mir gerne einen Kommentar dazu da. Sendfile optimiert die Art, wie auf eine angefragte Datei zugegriffen wird. Tcp_nopush sorgt dafür, dass die Antwort in einem Paket verschickt wird und tcp_nodelay schließlich vermeidet das Buffern von Daten die zum Versand bereit liegen. Planst du den Einsatz von Cache, solltest du unbedingt prüfen, wie sich diese Parameter dann auswirken, da ein Cache durchaus ein Kontraindikator sein kann!</p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-optimize-nginx-configuration">client_body_timeout, client_header_timeout</a> - Diese Parameter werden die tatsächliche Geschwindigkeit weniger beeinflussen, sondern nur dafür sorgen, dass der HTTP Fehler 408 (Request time out) schneller ausgeliefert wird.</p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-optimize-nginx-configuration">keepalive_timeout und send_timeout</a> - Diese Parameter machen vermutlich eher Sinn, wenn du mit wirklich vielen (organischen) Verbindungen konfrontiert wirst. Sie sorgen dafür, dass nicht genutzte Verbindungen schneller geschlossen werden und der Prozess so neue Anfragen annehmen kann.</p>
<p><a href="http://nginx.org/en/docs/http/ngx_http_limit_req_module.html">limit_req_zone</a> - Mit dieser Direktive legst du fest, wie viele Anfragen der Server innerhalb eines Zeitraums annimmt, bevor er mit einem Fehler antwortet. Als Indikator habe ich die IP-Adresse gewählt ($binary_remote_addr), mit $server_name lässt sich das Limit je Server einstellen. Mit zone lege ich einen Namen für diese Einstellung fest. So kann ich z.B. mehrer Zonen für beliebige Orte oder Ordner einrichten. 10m beschreibt die Größe des Speichers, in dem die IP-Adressen abgelegt werden. 10 MByte sollte für etwa 160.000 IP-Adressen reichen. Rate legt fest, wie viele Anfragen pro Sekunde erlaubt sind. Mit burst kann eine Warteschlange eingerichtet werden, die (hier) 20 Anfragen zurückstellt um sie dann abzuarbeiten.</p>
<p><a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#server_names_hash_bucket_size">server_names_hash_bucket_size</a> - Damit kommst du unter Umständen in Berührung, wenn nginx dich mit der Fehlermeldung &ldquo;<em>could not build the server_names_hash, you should increase server_names_hash_bucket_size</em>&rdquo; begrüßt. Die Direktive beschreibt ihre Funktion eigentlich schon ganz gut: Die Größe des Buckets für die Hash-Werte der Server-Namen. Oder: Dein Server-Name ist zu groß und passt nicht in den Eimer.</p>
<h3 id="logging">Logging</h3>
<p>An erster Stelle definiere ich meine eigenen Log-Templates <strong>main</strong> und <strong>cache_status</strong>. Beachte, dass ich die IP-Adresse nur anonymisiert übernehme. Dies übernimmt die map-Direktive, die per regulärem Ausdruck das letzte Tupel der IP-Adresse entfernt. Das ganze ist <a href="https://blag.nullteilerfrei.de/2018/05/26/anonymize-ip-addresses-in-nginx-log-files/">hier etwas genauer dokumentiert</a>. Ebenfalls mit <strong>map</strong> lese ich einen HTTP-Header aus, um das Logging vom Client aus zu deaktivieren - warum ich das mache, <a href="https://www.nickyreinert.de/zugriff-nicht-loggen-wenn-ein-bestimmter-http-request-header-gesetzt-ist/">ist hier beschrieben</a>.</p>
<p>Schließlich lege ich mit <strong>access_log</strong> und <strong>error_log</strong> fest, an welchem Ort die Log-Files per default abgelegt werden. Das ändere ich später natürlich noch auf Server-Ebene.</p>
<h3 id="der-cache">Der Cache</h3>
<p>In der globalen Konfig-Datei werde ich nur zwei Direktiven vorgeben, die für alle Server gleich sind. Mit der Direktive <strong><a href="http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache_key">fastcgi_cache_key</a></strong>, lege ich fest, wie nginx die Cache-Keys erstellt. Hier sollte natürlich jeder Server unterscheidbar sein.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">fastcgi_cache_key &#34;$scheme$request_method$host$request_uri&#34;;
</span></span></code></pre></div><p>Außerdem soll jede Antwort einen Header enthalten, der den Cache-Status enthält. Mit der Variable <em>upstream_cache_status</em> kann z.B. ich so <a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html">HIT, MISS oder EXPIRED</a> übermitteln.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">add_header X-Cache $upstream_cache_status;
</span></span></code></pre></div><p>Wie der Cache bei nginx funktioniert und auf den wichtigsten Parameter fastcgi_cache_path gehe ich im 2. Teil genauer ein.</p>
<h3 id="welches-dateisystem-für-den-cache---tempfs-oder-ramfs">Welches Dateisystem für den Cache - tempfs oder ramfs?</h3>
<p>Der <strong>FastCGI</strong>-Cache ist dafür gedacht, die Auslieferung der PHP-Dateien zu beschleunigen. Es macht nämlich durchaus Sinn, eine PHP-Datei nicht jedes mal durch den PHP-Interpreter zu jagen, wenn sich am Inhalt nichts geändert hat. Dazu wird die &ldquo;interpretierte&rdquo; PHP-Datei einfach in einem Cache-Ordner abgelegt und bei Bedarf abgerufen. Dieser Ordner kann sich auf der Festplatte oder im Arbeitsspeicher befinden. Auf die Unterschiede gehe ich hier kurz ein:</p>
<p>Im <strong>Init-Script</strong> (siehe oben) wird dir ein großer, auskommentierter Block aufgefallen sein. Mein Setup ist darauf ausgelegt, dass der Cache auf der Festplatte abgelegt wird. Es ist aber wie gesagt auch möglich, eine <strong>RAM-Disk</strong> zu nutzen, wobei der Arbeitsspeicher als Ablage dient. Das ist in den meisten Fällen weitaus schneller ist als die Festplatte. <a href="https://www.searchstorage.de/tipp/Linux-Server-Unnoetige-Dateien-mit-tmpfs-vom-Storage-fernhalten">Man unterscheidet</a> zwischen zwei nutzbaren Dateisystemen: <strong>ramfs</strong> und <strong>tempfs</strong>.</p>
<p>Der <strong>Vorteil von ramfs</strong> ist, dass direkt der <strong>Arbeitsspeicher</strong> genutzt wird. Der <strong>Nachteil</strong> ist: Es gibt <strong>keine Größenbeschränkung</strong>. Mit den falschen Einstellungen kann man also ungewollt den Arbeitsspeicher volllaufen lassen. Bei <strong>tempfs</strong> kann zwar eine <strong>Obergrenze</strong> angegeben werden. Es kann aber sein, dass das <strong>Dateisystem</strong> selber eine Swap-Partition zum Zwischenspeichern nutzt (vor allem dann, wenn die vorgegeben Speichergrenze erreicht ist). Ein Test mit tempfs und normaler Festplatte hat bei mir ergeben, dass der <strong>Cache</strong> um den <strong>Faktor 10</strong> langsamer wird. Aus diesem Grund ist der Bereich hier deaktiviert. Um das Thema kümmere ich mich also vielleicht an anderer Stelle noch mal</p>
<h3 id="ssl">SSL</h3>
<p>Natürlich gehört auch SSL zu meinem Server-Setup. Ich nutze dazu <strong>Let&rsquo;s Encrypt</strong> in Verbindung mit dem certbot, da das so ziemlich den ganzen Prozess automatisiert. Der Parameter <em>ssl_session_cache</em> beschreibt, wie groß der Cache für Session-Caches ist. Der Standardwert von 5 MByte sollte hier völlig ausreichen und reicht für knapp 20.000 Sessions. Auch beim <em>ssl_session_timeout</em> kann der Standardwert übernommen werden. Nach 1 Stunde verfällt also die SSL-Session. Außerdem sorgen wir mit <em>add_header</em> Strict-Transport-Security dafür, dass nur Verbindungen über HTTPS aufgebaut werden können (HTTP Strict Transport Security, HSTS).</p>
<p>Schließlich solltest du über <em>ssl_protocols</em> die verwendeten SSL-Protokolle einschränken. Die meisten modernen Browser kommen mit TLS 1.2 schon ganz gut klar und seit August 2018 gibt es auch TLS 1.3. Ältere Versionen haben hier nichts mehr verloren, um z.B. Lücken wie <a href="https://de.wikipedia.org/wiki/Poodle">Poodle</a> keine Angriffsfläche zu bieten. Außerdem kannst du mit <em>ssl_prefer_server_ciphers</em> und <em>ssl_ciphers</em> festlegen, welche Verschlüsselungsmethoden akzeptiert werden sollen. Auch hier gibt es schwache und langsame Methoden. <a href="https://mozilla.github.io/server-side-tls/ssl-config-generator/">Mozilla bietet dafür übrigens ein Online-Tool</a> an, dessen Einstellung ich für einen guten Kompromiss zwischen Kompatibilität und Sicherheit halte</p>
<h3 id="gzip---kompression">GZIP - Kompression</h3>
<p>Neben dem Cache ist Kompression eine sinnvolle Maßnahme um den Seitenaufbau noch etwas zu beschleunigen. Die Kompression aktivierst du mit - Überraschung - <em>gzip on</em>.</p>
<p>Mit <em>gzip_vary</em> sorgst du dafür, dass komprimierte und unkomprimierte Ressourcen gecached werden. Der Parameter <em>gzip_min_length</em> legt fest, wie groß eine Ressource mindestens sein muss, um komprimiert zu werden. Mit gzip_proxied sorgst du dafür, dass Anfragen von Proxies komprimierte Daten bekommen und <em>gzip_types</em> definiert die Ressourcen-Typen, die komprimiert werden. Und schließlich sorgen wir noch dafür, dass Anfragen vom alten Internet Explorer nicht komprimiert werden, da dieser damit nicht arbeiten kann: <em>gzip_disable</em>.</p>
<p>Das war es mit der Einrichtung von nginx. Weiter geht es im 2. Teil mit den <strong>Servern</strong> bzw. wie sie unter Apache genannt werden: <strong>virtual hosts</strong>.</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>hosting</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Mehrere virtuelle Server mit nginx und PHP-FPM für Wordpress (Teil 1 / 3) - Analysis</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>Wordpress Debugging und Wartung oder: Keine Panik vor dem White Screen of Death und HTTP 500</title>
      <link>http://localhost:1313/2018/2018-11-18-wordpress-debugging-und-wartung-oder-keine-panik-vor-dem-white-screen-of-death/</link>
      <pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2018/2018-11-18-wordpress-debugging-und-wartung-oder-keine-panik-vor-dem-white-screen-of-death/</guid>
      <description>Deine Wordpress-Seite besteht nur aus einem weißen Bildschirm, dem HTTP-Fehlercode 500 oder lädt irsinnig langsam? White Screen of Death (WSoD), die …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Deine Wordpress-Seite besteht nur aus einem weißen Bildschirm, dem HTTP-Fehlercode 500 oder lädt irsinnig langsam.&#39; reading_time: 10 content_type: &#39;analysis</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Wordpress, Mac, Server, Ai, Automation</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Deine Wordpress-Seite besteht nur aus einem weißen Bildschirm, dem <strong>HTTP-Fehlercode 500</strong> oder lädt irsinnig langsam? <strong>White Screen of Death</strong> (WSoD), die berüchtigten <strong>500´er</strong> sowie lange <strong>Ladezeiten</strong> scheinen zu den größten Herausforderungen im Umgang mit WordPress zu gehören und sie hinterlassen regelmäßig lange Gesichter. Zwar gehören Ladezeit, PHP- und HTTP-Fehler nicht unbedingt zusammen, sie erfordern aber in der Regel das gleiche Vorgehen: Nämlich die <strong>Analyse</strong>, was da im <strong>Hintergrund</strong> so passiert.<br>
Die Suche nach der Ursache ist oft relativ simpel. Es sagt einem oft nur niemand. Der beliebteste Tipp bei Wordpress lautet oft:</p>
<blockquote>
<p><em>&ldquo;Deaktiviere mal alle Plugins und aktiviere sie nacheinander wieder.&rdquo;</em></p>
<p><em>Anonymer Ratgeber, Mai 2018</em></p></blockquote>
<p>Das ist alles andere als effizient, ja nicht einmal effektiv: Du erfährst nach 27 Minuten und zwei Tassen Kaffe, dass das Plugin &ldquo;Foobar&rdquo; für den Fehler verantwortlich ist, weil das den <strong>WSoD</strong> auslöst. Aber dann weißt du immer noch nicht, was genau der Fehler ist. Danke für nichts?</p>
<p>Tatsächlich gibt es nur <strong>drei Dinge</strong>, die dir helfen können, dir selber zu helfen, wenn WordPress dich mal wieder im Stich lässt. Und diese drei Werkzeuge zur <strong>Fehlersuche</strong> und <strong>Diagnose</strong> langsamer Wordpress-Installation stelle ich jetzt einmal vor:</p>
<h2 id="1-die-entwickler-konsole-deines-browsers">1. Die Entwickler-Konsole deines Browsers</h2>
<p>Dieses Werkzeug bringt mittlerweile jeder moderne Browser mit und das sollte auch die <strong>erste Anlaufstelle</strong> für dich sein. Welche Entwicklerkonsole du verwendest, ist deinem Geschmack überlassen, in der Funktionalität unterscheiden sie sich kaum. Du öffnest die Entwicklerkonsole auf vielfältige Weise über</p>
<ul>
<li>das Kontextmenü (Rechte Maustaste -&gt; Element untersuchen) oder</li>
<li>über mit der Funktionstaste F12 oder</li>
<li>mit dem Shortcut CTRL+SHIFT+I (Windows) / CMD+OPT+I (OS X)</li>
</ul>
<p>[gallery link=&ldquo;file&rdquo; columns=&ldquo;4&rdquo; ids=&ldquo;2356,2357,2358,2359&rdquo;]</p>
<h2 id="2-der-query-monitor---warum-ist-dein-wordpress-so-langsam">2. Der Query Monitor - warum ist dein Wordpress so langsam?</h2>
<p>Der <a href="https://de.wordpress.org/plugins/query-monitor/">Query Monitor</a> ist ein wirklich nützliches <strong>Plugin</strong> für Wordpress. Eines der wenigen. Du fragst dich, warum deine Seite so lange lädt und die Entwicklerkonsole gibt nicht vielmehr her als ein <strong>TTFB</strong> (Time To First Byte) von 60 Sekunden?</p>
<p>Die Entwicklerkonsole sagt dir nur, wie lange der Browser auf den Inhalt wartet. Hier kann maximal identifiziert werden, dass die reine Wartezeit (<strong>TTFB</strong>) 60 Sekunden beträgt und der Inhalt in 10 Sekunden heruntergeladen wird (die ganzen anderen Nerd-Kennzahlen jetzt mal außen vor gelassen). Letzteres liegt ziemlich wahrscheinlich an der Internetleitung von dir oder dem Hoster. Aber TTFB? Das ist im Grunde die Zeit, die der Server benötigt um die Ausgabe einmal zusammenzuschustern und zu deinem Browser zu schicken. Also das ganze PHP-Gedöns einmal &ldquo;interpretieren&rdquo; und ein paar Datenbankabfragen durchführen. Je umfangreicher deine WordPress-Seite ist (sprich Plugin-Vielfalt), desto mehr gibt es hier zu tun. Und was da im Hintergrund genau passiert, sagt dir der <strong>Query Monitor</strong>.</p>
<p>[gallery link=&ldquo;file&rdquo; columns=&ldquo;2&rdquo; ids=&ldquo;2354,2355&rdquo;]</p>
<p>Nach der Installation siehst du in der Admin-Toolbar erstmal ein paar oberflächliche Zahlen: <strong>Ladezeit,</strong> <strong>Größe</strong> und <strong>Anzahl der Queries.</strong> Wirklich spannend wird es, wenn du mal auf diese Zahlen klickst. Dann öffnet sich eine &ldquo;<em>Entwickler-Konsole&rdquo;,</em> die deiner WordPress-Seite mal gehörig unter die Haube schaut. Du siehst <strong>Datenbankabfragen,</strong> <strong>Scripte,</strong> <strong>Funktionen</strong> und alle möglichen Diagnostiken - einfach alles. Du kannst nun relativ zügig erkennen, ob manche Abfragen einfach nur doppelte durchgeführt wurden oder die Datenbank grundsätzlich zu langsam ist.</p>
<h2 id="3-der-debug-modus">3. Der Debug-Modus</h2>
<p>DasBbeste zum Schluss - der Debug-Modus verrät dir wirklich alles und ist eigentlich der Premium-Weg der Problemlösung.</p>
<p>Du wirst nur selten erleben, dass Wordpress bzw. dein Server dich wirklich gar nicht mit einer Fehlermeldung erhellen will. Der unliebsame <strong>White Screen of Death</strong> und der gefürchtete <strong>HTTP-Fehler 500</strong> sind im Grunde nur der Standardeinstellungen geschuldet. Du kannst dann entweder ein Ticket bei deinem Hoster öffnen und im nächsten Jahr mit einer Antwort rechnen oder versuchen, selber an die Fehlermeldung zu gelangen und das Problem eigenständig zu analysieren: <strong>Der geheime Trick</strong> lautet nämlich, einfach mal das Internet nach der Fehlermeldung zu durchsuchen. <strong>In 99,99% der Fälle</strong> bist du bei weitem nicht der erste mit diesem banalen Problem..</p>
<p>Die wahre Herausforderung ist allerdings, dass die Ausgabe von Fehlermeldungen eben standardmäßig unterdrückt  wird. Aus Gründen der Sicherheit und Bedienbarkeit ist das grundsätzlich nicht verkehrt. Wenn du doch mal wissen willst, woher der <strong>White Screen of Death</strong> wirklich kommt, gehst du folgendermaßen vor:</p>
<h3 id="a-du-aktivierst-die-fehlerausgabe-von-wordpress">A: Du aktivierst die Fehlerausgabe von Wordpress</h3>
<p>Dazu öffnest du die Datei wp-config.php, nachdem du sie lokal gespeichert hast, und setzt folgenden Parameter direkt an den Anfang, aber hinter das <em>&lt;?php</em>:</p>
<?php
define( 'WP\_DEBUG', true );
define( 'WP\_DEBUG\_LOG', true ); 
define('WP\_DEBUG\_DISPLAY', false);

Der 1. Parameter ist für das debuggen _essentiell:_ Damit aktivierst du die Ausgabe von Fehlermeldungen.

Mit dem 2. Parameter gibst du die Anweisung, dass die Fehlermeldungen in einer Datei gespeichert werden. Das ist aus zwei Gründen nützlich: Du kannst es später einfacher Nachvollziehen und außerdem solltest du vermeiden, dass Fehlermeldungen, die vielleicht sensible Informationen enthalten, direkt im Frontend landen.

Die besagte Datei befindet sich um Order /wp-content und heißt **debug.log**. etzt du **WP\_DEBUG\_LOG** auf true, wird Wordpress Fehlermeldungen in die Date _/wp-content/debug.log_ schreiben. Für die nachträgliche Analyse ist das sehr praktisch. Das funktioniert natürlich nur, wenn der Ordner beschreibbar ist. Andernfalls musst du diesen Parameter und den folgenden weglassen.

Der letzte Parameter sorgt noch einmal explizit dafür, dass die Fehlermeldungen nicht im Frontend angezeigt werden.

Neben diesen 3 Parameter gibt es noch **SCRIPT\_DEBUG**. Mit true aktiviert, sorgt dieser Schalter dafür, dass Wordpress die "echten" CSS- und JS-Dateien liest, anstatt der minifizierten. Das wird dich nur in Spezialfällen betreffen, solltest du aber kennen. Der nächste **Spezialparameter** in der Riege ist **SAVEQUERIES** - hiermit wird dir WordPress die Datenbank-Anfragen ausgeben. Auch das ist in der Regel nicht notwendig, aber gut zu wissen.

Denke daran, dass die Parameter im weiteren Verlauf der Config-Datei nicht wieder vorkommen und deine Einstellung so aufheben und vor allen, dass du die Parameter in einem Live-System nach der Fehlersuche **wieder auf _false_ zurücksetzen** solltest.

### B: Du aktivierst die Fehlerausgabe deines Servers

Eigentlich sollte dir **Nummero A** bereits weiterhelfen, denn damit wird auch die Fehlerausgabe von PHP aktiviert. Sollte deine Seite trotzdem weiß bleiben und dich nicht mit zusätzlichen Fehlernachrichten beglücken, kannst du etwas tiefer in die Trickkiste greifen. Diese Parameter machen im Grunde nichts anderes, als oben schon beschreiben ist, sie greifen allerdings etwas "früher" ein.

Ergänze, ebenfalls direkt hinter dem _<?php_ der Datei _wp-config.php_ die folgenden Zeilen:

<?php
error\_reporting(E\_ALL);
ini\_set('display\_errors', 1);
ini\_set('display\_startup\_errors', 1);
// ini\_set("log\_errors", 1);
// ini\_set("error\_log", "/pfad/zu/wordpress/temp/php-error.log");

Die beiden letzten Zeilen aktivieren, ähnlich wie oben, dass PHP Fehlermeldungen in eine Datei schreibt. Da die Log-Datei bei der ad hoc Fehlersuche nicht zwingend hilfreich ist, sind diese beiden Zeilen auskommentiert.

Wenn du den Pfad zu deiner Installation nicht kennst, bekommst du sie mit folgendem PHP-Befehl heraus. Wenn du diese Information nicht mehr benötigst, entferne sie aber sofort aus deinem Script. **Security through obscurity** - das _Document Root_ geht niemanden außer dich etwas an!

var\_dump($\_SERVER\["DOCUMENT\_ROOT"\]);

Achtung: Auf manchen Seiten wird dir empfohlen, den Zeilen ein @ vorzustellen. Das ist **ziemlich kontraproduktiv** - denn [das @ am Anfang der Zeile unterbindet Fehlermeldungen](http://php.net/manual/de/language.operators.errorcontrol.php) und weshalb bist du hier? Genau...

Das ist aber noch nicht alles - die Trickkiste ist noch tiefer. Doch obacht! Das folgende ist **Premium-Klasse-Debuggung** und auf den meisten Shared-Hostern gar nicht möglich. Die essentiellen Parameter befinden sich in der ersten Zeile. Die noch tiefergreifenden und wirklich nur in absoluten Sonderfällen benötigten Einstellungen sind darunter aufgeführt.

Öffne die Datei **.htaccess** und ergänze die folgenden Zeilen - auch hier gilt, achte darauf, dass die Parameter nicht an anderer Stelle ungewollt überschrieben werden:

\# Easy-Peasy Lemon-Squeezy:
php\_flag display\_startup\_errors on
php\_flag display\_errors on
php\_flag html\_errors on
php\_flag log\_errors on

# Fürs Protokoll: Wenn du das volle Entertainment brauchst
# nimm auch das hier mit - für alle Copy&Paste-Cowbowys, die 
# den Warnhinweis nicht lesen, habe ich die Zeilen auskommentiert
# php\_flag ignore\_repeated\_errors off
# php\_flag ignore\_repeated\_source off
# php\_flag report\_memleaks on
# php\_flag track\_errors on
# php\_value docref\_root 0
# php\_value docref\_ext 0
# php\_value error\_log /pfad/zu/wordpress/temp/php-error.log
# php\_value error\_reporting -1
# php\_value log\_errors\_max\_len 0

# <Files php\_errors.log>
#      Order allow,deny
#      Deny from all
#      Satisfy All
# </Files>

Warum A und warum B? Es ist möglich, dass die Server-Konfiguration es aus Sicherheitsgründen nicht zulässt, dass diese sogenannten **PHP-Direktiven** (aka Parameter) an beliebigen Stellen (aka .htaccess, in der PHP-Datei, ...) konfiguriert wird. Deshalb.  
Und was ist mit C - der **php.ini**\-Datei? Gute Frage, werter Leser, die bei dir ein gewisses Grundwissen erkennen lässt. Chapeau. In dem Fall gehe ich sehr stark davon aus, dass du Zugriff auf eben diese Datei hast. Und wer Zugriff auf diese Datei hat, mit diesem Vorwissen, ist ziemlich sicher und hoffentlich mit der notwendigen Erfahrung ausgestattet. Andernfalls: Ruf deinen SysOp an. ;) Fühle dich trotzdem herzlich dazu eingeladen, diesen Beitrag mit etwas zuästzlichem Fachwissen in den **Kommentaren** zu bereichern.

### C: Den Debug-Modus bei deinem Hoster aktivieren

Bei der Einstellung des Debug-Modus gibt es eine Hierarchie. Die Debug-Einstellung in der PHP-Datei (**wp-config.php**) ist hierbei die oberste Ebene, darunter folgt die Einstellung in der **.htaccess-Datei** und auf unterster Ebene lässt sich diese Funktion in der Einstellung des Servers bzw. PHP-Interpreters direkt einstellen (z.B. **php.ini**). Damit unbedarfte Laien wie wir an dieser Datei nicht wahllos rumfingern, ist bleibt uns diese Möglichkeit entweder komplett verwehrt oder ist nur über das Interface bei deinem Hoster einstellbar. Dort kann der Hoster auch festlegen, dass diese Einstellung (in Fachkreisen gerne auch **Direktive** genannt) in den Ebenen darüber gar nicht anpassen werden darf - **Schritt A und B bleiben also unwirksam.** Das ist der Zeitpunkt, wenn du in den Einstellungen bei deinem Hoster nach dieser Einstellung suchst - oder den Hoster darum bittest, den Debug-Modus für dich zu aktivieren.

Bei HostEurope kannst du das z.B. sehr leicht selber tun:

[![Host Europe Debug Modus aktivieren ](images/host_europe_debug_aktivieren-300x232.png)](https://www.nickyreinert.de/files/wordpress-debugging-und-wartung-oder-keine-panik-vor-dem-white-screen-of-death/host_europe_debug_aktivieren.png)

Host Europe Debug Modus aktivieren

## Freibier - Nachwort - Lies  mich!

Das ist jetzt wirklich wichtig: Wie immer, und oben bereits erwähnt, gilt auch hier: **Security through obscurity**.

> Wenn du den Debug-Modus auf dem Live-System nicht mehr benötigst, deaktiviere ihn. Basta.

Auf **Live-Systemen** hat der **Debug-Modus nur in Ausnahmefällen** etwas verloren. Und Fehler sollten zur Ausnahme zählen. Und auch, wenn du hier nur ein wenig an den PHP-Dateien rumschraubst, wobei eigentlich nicht viel kaputt gehen kann:

> Denke an die obligatorische Sicherungskopie.

Und jetzt viel Spass beim d_ebuggen_...

Ach ja - wenn all das da oben nicht funktioniert, dann kannst du tatsächlich auch mal den Holzhammer rausholen: **Plugins aktivieren und deaktivieren**. In der Regel helfen dir die hier geschilderten Schritte aber, genau diesen mühsamen Schritt zu übergehen.

        
        
        <div class="tags">
          <p><strong>Tags:</strong> wordpress-debugging-und-wartung-oder-keine-panik-vor-dem-white-screen-of-death-und-http-500</p>
        </div>
        
      ]]></content:encoded>
      
      
      
      <category>wordpress</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>Wordpress Debugging und Wartung oder: Keine Panik vor dem White Screen of Death und HTTP 500 - Analysis</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item><item>
      <title>SFTP auf Microsoft IIS korrekt einrichten</title>
      <link>http://localhost:1313/2015/2015-10-14-sftp-auf-microsoft-iis-korrekt-einrichten/</link>
      <pubDate>Wed, 14 Oct 2015 00:00:00 +0000</pubDate>
      <author></author>
      <guid>http://localhost:1313/2015/2015-10-14-sftp-auf-microsoft-iis-korrekt-einrichten/</guid>
      <description>Das Einrichten eines SFTP-Servers klingt einfach, ist es aber nicht. Es gibt mindestens drei Problem, denen du begegnen wirst.
Du kannst die Verbindung zum …</description>
      
      
      <content:encoded>&lt;![CDATA[
        
        <div class="ai-summary">
          <h3>AI-Zusammenfassung</h3>
          <p>Das Einrichten eines SFTP-Servers klingt einfach, ist es aber nicht. Es gibt mindestens drei Problem, denen du begegnen wirst.&#39; reading_time: 3 content_type: &#39;analysis</p>
          
          
          <p><strong>Hauptthemen:</strong> Python, Web, Mac, Server, Ai, Security</p>
          
          
          
          <p><strong>Schwierigkeitsgrad:</strong> beginner</p>
          
        </div>
        
        
        <p>Das Einrichten eines SFTP-Servers klingt einfach, ist es aber nicht. Es gibt mindestens drei Problem, denen du begegnen wirst.</p>
<blockquote>
<ol>
<li>
<ol>
<li>
<p>Du kannst die Verbindung zum Server nicht herstellen, weil das Server-Zertifikat ungültig ist. Die Fehlermeldung in FileZilla lautet dann z.B.<br>
GnuTLS error -48: Key usage violation in certificate has been detected. Could not connect to server</p>
</li>
<li>
<p>Obwohl du in der Firewall die passiven Ports für den Server freigeschaltet hast, kann die Verbindung nicht vollendet werden. FileZilla bleibt dann z.B. bei der folgenden Zeile stehen:</p>
<p>150 Opening BINARY mode data connection</p>
</li>
</ol>
</li>
</ol></blockquote>
<p>3. Und schließlich kann es sein, dass der Benutzer nicht die nötigen Zugriffsrechte für den Ordner hat, den du in den Einstellungen des FTP-Servers angegeben hast.</p>
<p>Keine Sorge. Mit diesen drei Probleme durfte auch ich schon kämpfen und ich habe die Lösungen hier zusammengetragen. Also.. eins nach dem anderen.</p>
<p>Die Ursache des ersten Problems ist der Assistent, mit dem man im IIS das Server-Zertifikat erstellt. Auf den Punkt gebracht, nutzt dieser ein paar falsche Parameter. Aus diesem Grund muss das Zertifikat per Hand in der PowerShell erstellt werden. Wichtig: In der normalen Konsole funktioniert das nicht.</p>
<p><a href="https://superuser.com/questions/1167351/filezilla-reporting-gnutls-error-48-key-usage-violation-in-certificate-has-be">https://superuser.com/questions/1167351/filezilla-reporting-gnutls-error-48-key-usage-violation-in-certificate-has-be</a></p>
<p>According to a post in the <a href="https://forums.iis.net/t/1234970.aspx">IIS forums</a>, you can generate the certificate with PowerShell instead until the issue is fixed by Microsoft:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">New-SelfSignedCertificate -CertStoreLocation cert:\LocalMachine\My -dnsname ftp.example.com
</span></span></code></pre></div><p>Replace <code>ftp.example.com</code> by your server&rsquo;s hostname.</p>
<p>You will get a fingerprint, copy that. Set a password for the private key:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">$password = ConvertTo-SecureString -String &#34;password goes here&#34; -Force -AsPlainText
</span></span></code></pre></div><p>Now export it (you can change <code>C:\cert.pfx</code> to the path you want to save it to, just make sure it ends in <code>.pfx</code>):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">Export-PfxCertificate -cert cert:\LocalMachine\My\FINGERPRINT -FilePath C:\cert.pfx -Password $password
</span></span></code></pre></div><p>Benutzer anlegen</p>
<p><a href="https://www.nickyreinert.de/files/ssl-zertifikat-auf-windows-korrekt-installieren/windows-server-ssl-zertifikat-zuweisen.png"><img src="/2015/2015-10-14-sftp-auf-microsoft-iis-korrekt-einrichten/images/windows-server-ssl-zertifikat-zuweisen-300x121.png" alt=""></a></p>
<p><strong>siehe auch:</strong></p>
<p><a href="https://www.visualsvn.com/support/topic/00056/">https://www.visualsvn.com/support/topic/00056/</a></p>
<p>[http://grantcurell.com/2013/12/31/failed-to-retrieve-directory-listing-filezilla-connecting-to-iis-behind-nat/ http://ekiwi-blog.de/?p=3465](<a href="http://grantcurell.com/2013/12/31/failed-to-retrieve-directory-listing-filezilla-connecting-to-iis-behind-nat/">http://grantcurell.com/2013/12/31/failed-to-retrieve-directory-listing-filezilla-connecting-to-iis-behind-nat/</a> <a href="http://ekiwi-blog.de/?p=3465">http://ekiwi-blog.de/?p=3465</a>)</p>

        
        
      ]]></content:encoded>
      
      
      
      <category>hosting</category>
      
      <category>anleitungen</category>
      
      
      
      
      <media:content url="http://localhost:1313/images/posts/placeholder.jpg" type="image/jpeg">
        <media:title>SFTP auf Microsoft IIS korrekt einrichten - Analysis</media:title>
      </media:content>
      
      
      
      
      
      
      
    </item>
  </channel>
</rss>